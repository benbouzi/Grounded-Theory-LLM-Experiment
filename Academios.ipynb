{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ACADEMIAOS - VERSION AM√âLIOR√âE COMPL√àTE\n",
        "========================================\n",
        "\n",
        "AM√âLIORATIONS INT√âGR√âES:\n",
        "1. Codage par unit√© Question-R√©ponse (pas phrase par phrase)\n",
        "2. D√©tection automatique des √©changes Q/R dans les transcripts\n",
        "3. Filtre de fr√©quence pour identifier patterns r√©currents\n",
        "4. Consolidation conceptuelle avec vocabulaire informant\n",
        "5. Prompts r√©vis√©s pour accepter usages/pratiques\n",
        "6. Architecture en 3 passes avec tra√ßabilit√© compl√®te\n",
        "7. Export enrichi avec mapping de consolidation\n",
        "\n",
        "WORKFLOW:\n",
        "‚îú‚îÄ √âtape 1a: Extraction par unit√© Q/R ‚Üí codes bruts (~500-1000)\n",
        "‚îú‚îÄ √âtape 1b: Filtre de fr√©quence ‚Üí codes r√©currents (~300-500)\n",
        "‚îú‚îÄ √âtape 1c: Consolidation conceptuelle ‚Üí codes finaux (~80-150)\n",
        "‚îú‚îÄ √âtape 2: Second-order coding ‚Üí th√®mes\n",
        "‚îú‚îÄ √âtape 3: Aggregate dimensions\n",
        "‚îî‚îÄ √âtapes 4a-e: D√©veloppement th√©orique\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# INSTALLATION & IMPORTS\n",
        "# ============================================================================\n",
        "\n",
        "!pip install -U -q google-generativeai python-docx PyPDF2 scikit-learn\n",
        "\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import hashlib\n",
        "from typing import List, Dict, Tuple, Set\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "import docx\n",
        "import PyPDF2\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION API\n",
        "# ============================================================================\n",
        "\n",
        "API_KEY = \"AIzaSyAYWlpkP2nQDOBCJrsVNO-wPubPTjlKkXk\"  # ‚Üê REMPLACEZ ICI\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "print(\"‚úì Configuration OK\")\n",
        "print(\"  - Mod√®le LLM: gemini-2.0-flash\")\n",
        "print(\"  - Mod√®le Embeddings: embedding-001\")\n",
        "\n",
        "# ============================================================================\n",
        "# FONCTIONS D'AFFICHAGE (inchang√©es)\n",
        "# ============================================================================\n",
        "\n",
        "def print_header(title: str, level: int = 1):\n",
        "    \"\"\"Affiche un header format√©.\"\"\"\n",
        "    if level == 1:\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(title.center(80))\n",
        "        print(\"=\"*80)\n",
        "    elif level == 2:\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(title)\n",
        "        print(\"-\"*80)\n",
        "    else:\n",
        "        print(f\"\\n{title}\")\n",
        "\n",
        "def print_box(content: str, title: str = \"\"):\n",
        "    \"\"\"Affiche contenu dans une bo√Æte.\"\"\"\n",
        "    width = 80\n",
        "    print(\"\\n‚îå\" + \"‚îÄ\" * (width - 2) + \"‚îê\")\n",
        "    if title:\n",
        "        print(\"‚îÇ \" + title.ljust(width - 4) + \" ‚îÇ\")\n",
        "        print(\"‚îú\" + \"‚îÄ\" * (width - 2) + \"‚î§\")\n",
        "\n",
        "    for line in content.split('\\n'):\n",
        "        while len(line) > width - 4:\n",
        "            print(\"‚îÇ \" + line[:width-4] + \" ‚îÇ\")\n",
        "            line = line[width-4:]\n",
        "        print(\"‚îÇ \" + line.ljust(width - 4) + \" ‚îÇ\")\n",
        "\n",
        "    print(\"‚îî\" + \"‚îÄ\" * (width - 2) + \"‚îò\")\n",
        "\n",
        "def display_prompt_pair(system_msg: str, user_prompt: str):\n",
        "    \"\"\"Affiche le system prompt et le user prompt.\"\"\"\n",
        "    print_header(\"üîß SYSTEM PROMPT UTILIS√â\", 2)\n",
        "    print_box(system_msg[:500] + \"...\" if len(system_msg) > 500 else system_msg,\n",
        "              \"System Message\")\n",
        "\n",
        "    print_header(\"üí¨ USER PROMPT ENVOY√â\", 2)\n",
        "    print_box(user_prompt[:800] + \"...\" if len(user_prompt) > 800 else user_prompt,\n",
        "              \"User Prompt\")\n",
        "\n",
        "def wait_for_user(message: str = \"‚è∏  Appuyez sur ENTR√âE pour continuer...\"):\n",
        "    \"\"\"Attend validation utilisateur.\"\"\"\n",
        "    input(f\"\\n{message}\\n\")\n",
        "\n",
        "def display_results(data, title: str):\n",
        "    \"\"\"Affiche r√©sultats format√©s.\"\"\"\n",
        "    print_header(f\"üìä R√âSULTATS: {title}\", 2)\n",
        "\n",
        "    if isinstance(data, list):\n",
        "        for i, item in enumerate(data[:30], 1):\n",
        "            print(f\"  {i:3d}. {item}\")\n",
        "        if len(data) > 30:\n",
        "            print(f\"  ... ({len(data) - 30} autres)\")\n",
        "\n",
        "    elif isinstance(data, dict):\n",
        "        for i, (key, value) in enumerate(data.items(), 1):\n",
        "            if isinstance(value, list):\n",
        "                print(f\"\\n  {i}. {key}\")\n",
        "                for item in value[:3]:\n",
        "                    print(f\"     ‚Ä¢ {item}\")\n",
        "                if len(value) > 3:\n",
        "                    print(f\"     ... ({len(value) - 3} autres)\")\n",
        "            else:\n",
        "                print(f\"  {i}. {key}: {value}\")\n",
        "    else:\n",
        "        print(data)\n",
        "\n",
        "# ============================================================================\n",
        "# CHARGEMENT DOCUMENTS (inchang√©)\n",
        "# ============================================================================\n",
        "\n",
        "def read_txt_file(filepath: str) -> str:\n",
        "    \"\"\"Lit un fichier .txt\"\"\"\n",
        "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            with open(filepath, 'r', encoding=encoding) as f:\n",
        "                return f.read()\n",
        "        except:\n",
        "            continue\n",
        "    return \"\"\n",
        "\n",
        "def read_docx_file(filepath: str) -> str:\n",
        "    \"\"\"Lit un fichier .docx\"\"\"\n",
        "    try:\n",
        "        doc = docx.Document(filepath)\n",
        "        return '\\n'.join([para.text for para in doc.paragraphs])\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def read_pdf_file(filepath: str) -> str:\n",
        "    \"\"\"Lit un fichier .pdf\"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            pdf = PyPDF2.PdfReader(f)\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def load_documents_from_folder(folder_path: str) -> Dict[str, str]:\n",
        "    \"\"\"Charge TOUS les documents.\"\"\"\n",
        "    documents = {}\n",
        "    folder = Path(folder_path)\n",
        "\n",
        "    if not folder.exists():\n",
        "        print(f\"‚úó Dossier introuvable: {folder_path}\")\n",
        "        return documents\n",
        "\n",
        "    print_header(\"üìÅ CHARGEMENT DES DOCUMENTS\", 1)\n",
        "    print(f\"Dossier: {folder_path}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    supported_extensions = {'.txt', '.docx', '.pdf'}\n",
        "    files_found = list(folder.glob('*'))\n",
        "\n",
        "    for filepath in files_found:\n",
        "        if filepath.is_file() and filepath.suffix.lower() in supported_extensions:\n",
        "            filename = filepath.name\n",
        "            print(f\"  üìÑ {filename}...\", end=\" \", flush=True)\n",
        "\n",
        "            if filepath.suffix.lower() == '.txt':\n",
        "                content = read_txt_file(str(filepath))\n",
        "            elif filepath.suffix.lower() == '.docx':\n",
        "                content = read_docx_file(str(filepath))\n",
        "            elif filepath.suffix.lower() == '.pdf':\n",
        "                content = read_pdf_file(str(filepath))\n",
        "            else:\n",
        "                content = \"\"\n",
        "\n",
        "            if content and len(content.strip()) > 100:\n",
        "                documents[filename] = content\n",
        "                print(f\"‚úì {len(content):,} caract√®res\")\n",
        "            else:\n",
        "                print(\"‚úó vide/erreur\")\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"‚úì {len(documents)} documents charg√©s\")\n",
        "\n",
        "    if documents:\n",
        "        print_header(\"üìã APER√áU DES DOCUMENTS\", 2)\n",
        "        for i, (name, content) in enumerate(documents.items(), 1):\n",
        "            preview = content[:200].replace('\\n', ' ')\n",
        "            print(f\"\\n{i}. {name} ({len(content):,} chars)\")\n",
        "            print(f\"   Aper√ßu: {preview}...\")\n",
        "\n",
        "    return documents\n",
        "\n",
        "# ============================================================================\n",
        "# CLASSE ANALYZER - VERSION AM√âLIOR√âE COMPL√àTE\n",
        "# ============================================================================\n",
        "\n",
        "class AcademiaOSGioiaAnalyzer:\n",
        "    \"\"\"\n",
        "    Version am√©lior√©e avec:\n",
        "    - D√©tection Q/R\n",
        "    - Filtre de fr√©quence\n",
        "    - Consolidation conceptuelle\n",
        "    - Tra√ßabilit√© compl√®te\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = genai.GenerativeModel('models/gemini-2.0-flash')\n",
        "\n",
        "        # Stockage codes par √©tape\n",
        "        self.raw_codes = []              # Codes bruts extraits\n",
        "        self.recurring_codes = []        # Codes apr√®s filtre fr√©quence\n",
        "        self.first_order_codes = []      # Codes consolid√©s finaux\n",
        "\n",
        "        # Mapping tra√ßabilit√©\n",
        "        self.code_to_chunks = {}         # code ‚Üí [(source, chunk_id), ...]\n",
        "        self.consolidation_mapping = {}   # consolidated ‚Üí [raw_codes]\n",
        "\n",
        "        # Autres √©tapes (inchang√©es)\n",
        "        self.second_order_themes = {}\n",
        "        self.aggregate_dimensions = {}\n",
        "        self.document_chunks = []\n",
        "        self.chunk_embeddings = []\n",
        "        self.applicable_theories = []\n",
        "        self.concept_tuples = []\n",
        "        self.interrelationships = {}\n",
        "\n",
        "        # üÜï Stockage unit√©s Q/R\n",
        "        self.qa_units = []  # [{source, question, answer, codes}, ...]\n",
        "\n",
        "        # üÜï Gestion cache embeddings\n",
        "        self.embeddings_cache_file = '/content/embeddings_cache.pkl'\n",
        "        self.documents_hash = None\n",
        "\n",
        "        print(\"‚úì Analyzer initialis√© (version am√©lior√©e)\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # M√âTHODES DE BASE (inchang√©es)\n",
        "    # ========================================================================\n",
        "\n",
        "    def call_api(self, system_message: str, prompt: str,\n",
        "                 json_mode: bool = True, temperature: float = 0,\n",
        "                 show_prompts: bool = True) -> str:\n",
        "        \"\"\"Appel API avec affichage optionnel.\"\"\"\n",
        "\n",
        "        if show_prompts:\n",
        "            display_prompt_pair(system_message, prompt)\n",
        "\n",
        "        try:\n",
        "            config = {\n",
        "                \"temperature\": temperature,\n",
        "                \"response_mime_type\": \"application/json\" if json_mode else \"text/plain\"\n",
        "            }\n",
        "            full_prompt = f\"{system_message}\\n\\n{prompt}\"\n",
        "\n",
        "            print(\"\\nüîÑ Envoi √† l'API...\", end=\" \", flush=True)\n",
        "            response = self.model.generate_content(full_prompt, generation_config=config)\n",
        "            print(\"‚úì\")\n",
        "\n",
        "            time.sleep(3)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚úó Erreur API: {str(e)[:150]}\")\n",
        "            return None\n",
        "\n",
        "    def chunk_text(self, text: str, max_chars: int = 10000, overlap: int = 50) -> List[str]:\n",
        "        \"\"\"D√©coupe texte en chunks.\"\"\"\n",
        "        chunks = []\n",
        "        start = 0\n",
        "        while start < len(text):\n",
        "            end = min(start + max_chars, len(text))\n",
        "            chunks.append(text[start:end])\n",
        "            start = end - overlap if end < len(text) else end\n",
        "        return chunks\n",
        "\n",
        "    def generate_embedding(self, text: str, task_type: str = \"retrieval_document\") -> np.ndarray:\n",
        "        \"\"\"G√©n√®re embedding.\"\"\"\n",
        "        try:\n",
        "            result = genai.embed_content(\n",
        "                model=\"models/embedding-001\",\n",
        "                content=text,\n",
        "                task_type=task_type\n",
        "            )\n",
        "            time.sleep(0.3)\n",
        "            return np.array(result['embedding'])\n",
        "        except Exception as e:\n",
        "            return np.zeros(768)\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï GESTION CACHE EMBEDDINGS\n",
        "    # ========================================================================\n",
        "\n",
        "    def compute_documents_hash(self) -> str:\n",
        "        \"\"\"\n",
        "        Calcule un hash unique des chunks pour d√©tecter changements.\n",
        "\n",
        "        Returns:\n",
        "            Hash MD5 des chunks (ordre + contenu)\n",
        "        \"\"\"\n",
        "        if not self.document_chunks:\n",
        "            return \"\"\n",
        "\n",
        "        # Cr√©er string repr√©sentative des chunks\n",
        "        chunks_signature = \"\"\n",
        "        for chunk in self.document_chunks:\n",
        "            chunks_signature += f\"{chunk['source']}:{chunk['chunk_id']}:{chunk['text'][:100]}\"\n",
        "\n",
        "        # Hash MD5\n",
        "        return hashlib.md5(chunks_signature.encode('utf-8')).hexdigest()\n",
        "\n",
        "    def save_embeddings_cache(self):\n",
        "        \"\"\"\n",
        "        Sauvegarde embeddings + m√©tadonn√©es dans fichier cache.\n",
        "        \"\"\"\n",
        "        if not self.chunk_embeddings or not self.document_chunks:\n",
        "            print(\"‚ö†Ô∏è  Rien √† sauvegarder (pas d'embeddings)\")\n",
        "            return\n",
        "\n",
        "        cache_data = {\n",
        "            'embeddings': self.chunk_embeddings,\n",
        "            'chunks': self.document_chunks,\n",
        "            'documents_hash': self.documents_hash,\n",
        "            'timestamp': time.time(),\n",
        "            'n_chunks': len(self.document_chunks),\n",
        "            'n_embeddings': len(self.chunk_embeddings)\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with open(self.embeddings_cache_file, 'wb') as f:\n",
        "                pickle.dump(cache_data, f)\n",
        "\n",
        "            file_size = os.path.getsize(self.embeddings_cache_file) / 1024  # KB\n",
        "            print(f\"\\n‚úì Embeddings sauvegard√©s: {self.embeddings_cache_file}\")\n",
        "            print(f\"  ‚Ä¢ {len(self.chunk_embeddings)} embeddings\")\n",
        "            print(f\"  ‚Ä¢ Taille fichier: {file_size:.1f} KB\")\n",
        "            print(f\"  ‚Ä¢ Hash documents: {self.documents_hash[:16]}...\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚úó Erreur sauvegarde embeddings: {str(e)[:100]}\")\n",
        "\n",
        "    def load_embeddings_cache(self) -> bool:\n",
        "        \"\"\"\n",
        "        Charge embeddings depuis cache si disponible et √† jour.\n",
        "\n",
        "        Returns:\n",
        "            True si chargement r√©ussi, False sinon\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.embeddings_cache_file):\n",
        "            print(\"‚ÑπÔ∏è  Pas de cache embeddings trouv√©\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            with open(self.embeddings_cache_file, 'rb') as f:\n",
        "                cache_data = pickle.load(f)\n",
        "\n",
        "            # V√©rifier validit√© du cache\n",
        "            cached_hash = cache_data.get('documents_hash', '')\n",
        "            current_hash = self.compute_documents_hash()\n",
        "\n",
        "            if cached_hash != current_hash:\n",
        "                print(\"‚ö†Ô∏è  Cache embeddings obsol√®te (documents modifi√©s)\")\n",
        "                return False\n",
        "\n",
        "            # Charger embeddings\n",
        "            self.chunk_embeddings = cache_data['embeddings']\n",
        "\n",
        "            # V√©rifier coh√©rence\n",
        "            if len(self.chunk_embeddings) != len(self.document_chunks):\n",
        "                print(\"‚ö†Ô∏è  Incoh√©rence taille cache/chunks\")\n",
        "                return False\n",
        "\n",
        "            # Infos\n",
        "            age_hours = (time.time() - cache_data.get('timestamp', 0)) / 3600\n",
        "            print(f\"\\n‚úì Embeddings charg√©s depuis cache\")\n",
        "            print(f\"  ‚Ä¢ {len(self.chunk_embeddings)} embeddings\")\n",
        "            print(f\"  ‚Ä¢ √Çge du cache: {age_hours:.1f}h\")\n",
        "            print(f\"  ‚Ä¢ Hash valid√©: {cached_hash[:16]}...\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚úó Erreur chargement cache: {str(e)[:100]}\")\n",
        "            return False\n",
        "\n",
        "    def cosine_similarity(self, emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
        "        \"\"\"Similarit√© cosinus.\"\"\"\n",
        "        dot = np.dot(emb1, emb2)\n",
        "        norm1, norm2 = np.linalg.norm(emb1), np.linalg.norm(emb2)\n",
        "        return float(dot / (norm1 * norm2)) if norm1 > 0 and norm2 > 0 else 0.0\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï D√âTECTION UNIT√âS QUESTION-R√âPONSE\n",
        "    # ========================================================================\n",
        "\n",
        "    def detect_qa_units(self, text: str, source_name: str) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        D√©tecte les unit√©s Question-R√©ponse dans le transcript.\n",
        "\n",
        "        Patterns reconnus:\n",
        "        - INTERVIEWER: ... RESPONDENT: ...\n",
        "        - Q: ... R: ...\n",
        "        - INT: ... ETU: ...\n",
        "        - Question X: ... [r√©ponse]\n",
        "\n",
        "        Returns:\n",
        "            Liste de {source, question, answer, qa_id}\n",
        "        \"\"\"\n",
        "        qa_units = []\n",
        "\n",
        "        # Patterns pour d√©tecter Q/R\n",
        "        patterns = [\n",
        "            # Pattern 1: INTERVIEWER/INT/Q suivi de RESPONDENT/R/INFORMANT\n",
        "            r'(?:INTERVIEWER|INT|INTERVIEWEUR|Q):\\s*(.*?)\\n+(?:RESPONDENT|R|√âTU(?:DIANT)?|INF(?:ORMANT)?|√âTUDIANT):\\s*(.*?)(?=\\n+(?:INTERVIEWER|INT|INTERVIEWEUR|Q):|$)',\n",
        "\n",
        "            # Pattern 2: Question num√©rot√©e\n",
        "            r'(?:Question|Q)\\s*(\\d+)\\s*:\\s*(.*?)\\n+(.*?)(?=\\n+(?:Question|Q)\\s*\\d+|$)',\n",
        "\n",
        "            # Pattern 3: Structure avec tirets\n",
        "            r'-\\s*Q\\s*:\\s*(.*?)\\n+-\\s*R\\s*:\\s*(.*?)(?=\\n+-\\s*Q\\s*:|$)',\n",
        "        ]\n",
        "\n",
        "        found = False\n",
        "\n",
        "        for pattern_idx, pattern in enumerate(patterns):\n",
        "            matches = list(re.finditer(pattern, text, re.DOTALL | re.IGNORECASE))\n",
        "\n",
        "            if matches:\n",
        "                found = True\n",
        "                print(f\"   ‚úì Pattern {pattern_idx + 1} d√©tect√©: {len(matches)} √©changes Q/R\")\n",
        "\n",
        "                for match_idx, match in enumerate(matches, 1):\n",
        "                    groups = match.groups()\n",
        "\n",
        "                    # Extraction selon le pattern\n",
        "                    if pattern_idx == 0:  # INTERVIEWER/RESPONDENT\n",
        "                        question = groups[0].strip() if len(groups) > 0 else \"\"\n",
        "                        answer = groups[1].strip() if len(groups) > 1 else \"\"\n",
        "                    elif pattern_idx == 1:  # Question num√©rot√©e\n",
        "                        q_num = groups[0].strip() if len(groups) > 0 else \"\"\n",
        "                        question = groups[1].strip() if len(groups) > 1 else \"\"\n",
        "                        answer = groups[2].strip() if len(groups) > 2 else \"\"\n",
        "                    elif pattern_idx == 2:  # Tirets\n",
        "                        question = groups[0].strip() if len(groups) > 0 else \"\"\n",
        "                        answer = groups[1].strip() if len(groups) > 1 else \"\"\n",
        "\n",
        "                    # Validation minimale\n",
        "                    if answer and len(answer) > 20:  # Au moins 20 caract√®res\n",
        "                        qa_units.append({\n",
        "                            'source': source_name,\n",
        "                            'qa_id': len(qa_units) + 1,\n",
        "                            'question': question,\n",
        "                            'answer': answer,\n",
        "                            'codes': []  # Sera rempli lors du coding\n",
        "                        })\n",
        "\n",
        "                break  # Un seul pattern suffit\n",
        "\n",
        "        if not found:\n",
        "            print(f\"   ‚ö† Aucune structure Q/R d√©tect√©e\")\n",
        "\n",
        "        return qa_units\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï √âTAPE 1a: EXTRACTION PAR UNIT√â Q/R\n",
        "    # ========================================================================\n",
        "\n",
        "    def first_order_coding(self, documents: Dict[str, str], question: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        √âTAPE 1a: Extraction des codes par unit√© Question-R√©ponse.\n",
        "\n",
        "        Nouveaut√©s:\n",
        "        - D√©tection automatique des √©changes Q/R\n",
        "        - Codage par R√âPONSE enti√®re (pas phrase par phrase)\n",
        "        - Fallback sur chunks si Q/R non d√©tect√©\n",
        "        - Tra√ßabilit√© code ‚Üí source\n",
        "        \"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 1a: EXTRACTION CODES PAR UNIT√â Q/R\", 1)\n",
        "        print(\"Objectif: Identifier concepts √©mergents au niveau des R√âPONSES\")\n",
        "        print(f\"Question de recherche: {question}\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  Appuyez sur ENTR√âE pour commencer l'extraction...\")\n",
        "\n",
        "        # Nouveau system message avec instruction Q/R\n",
        "        system_message = \"\"\"You are applying first-order coding in the Gioia method tradition.\n",
        "\n",
        "You are analyzing interviews about students' use of ChatGPT.\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "üéØ CRITICAL: CODE BY RESPONSE UNIT, NOT SENTENCE-BY-SENTENCE\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "An informant's COMPLETE RESPONSE to a question = ONE coding unit.\n",
        "\n",
        "WHY:\n",
        "‚úì A response forms a coherent narrative/explanation\n",
        "‚úó Sentence-by-sentence coding creates artificial fragmentation\n",
        "\n",
        "For each response, ask: \"What KEY PATTERN is being expressed HERE?\"\n",
        "Not: \"What are all the individual things mentioned?\"\n",
        "\n",
        "EXAMPLE:\n",
        "\n",
        "‚ùå WRONG (sentence-by-sentence):\n",
        "Response: \"Je commence par ChatGPT. Ensuite je modifie. √áa d√©pend du devoir.\"\n",
        "Codes: \"Commencer par ChatGPT\" + \"Modifier apr√®s\" + \"Variation selon devoir\"\n",
        "‚Üí 3 fragmented codes\n",
        "\n",
        "‚úì CORRECT (response-level):\n",
        "Code: \"Processus it√©ratif de consultation-adaptation modul√© par l'enjeu\"\n",
        "‚Üí 1 conceptual code capturing the complete pattern\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "WHAT TO CODE (all valid):\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "1. USAGE PATTERNS / PRACTICES\n",
        "   How they use ChatGPT - conceptualized, not micro-actions\n",
        "   ‚úì \"Consultation syst√©matique comme d√©clencheur de travail\"\n",
        "   ‚úó \"Demander √† ChatGPT\" (too descriptive)\n",
        "\n",
        "2. PERCEPTIONS / BELIEFS\n",
        "   How they view the tool\n",
        "   ‚úì \"Perception de l'IA comme ressource neutre disponible\"\n",
        "   ‚úó \"ChatGPT est neutre\" (too simple)\n",
        "\n",
        "3. TENSIONS / DILEMMAS\n",
        "   Contradictions they experience\n",
        "   ‚úì \"Ambigu√Øt√© morale entre efficacit√© et apprentissage authentique\"\n",
        "\n",
        "4. STRATEGIES / ADAPTATIONS\n",
        "   How they navigate situations\n",
        "   ‚úì \"Calibrage strat√©gique de l'appropriation selon l'enjeu\"\n",
        "\n",
        "5. CONSEQUENCES / EFFECTS\n",
        "   Impacts they perceive\n",
        "   ‚úì \"Normalisation progressive de la d√©pendance fonctionnelle\"\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "CONCEPTUALIZATION LEVEL:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "‚ùå TOO RAW (verbatim):\n",
        "\"je demande √† ChatGPT\", \"c'est plus rapide\"\n",
        "\n",
        "‚úì GOOD (informant vocabulary + conceptualized):\n",
        "\"R√©flexe de consultation automatis√©\", \"Gain de temps comme justification\"\n",
        "\n",
        "‚ùå TOO ACADEMIC (researcher jargon):\n",
        "\"Externalisation cognitive institutionnalis√©e\", \"Habitus technologique\"\n",
        "\n",
        "THE SWEET SPOT: Use their words, organize them conceptually.\n",
        "Think: \"Could the informant recognize this pattern if I named it?\"\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "EXAMPLES FROM YOUR CORPUS:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "Q: \"Comment utilisez-vous ChatGPT ?\"\n",
        "R: \"Alors c'est devenu automatique. D√®s que j'ai un devoir, je lui pose\n",
        "    la question, je regarde, et apr√®s je travaille dessus. Des fois je\n",
        "    redemande pour qu'il pr√©cise. √áa d√©pend du type de devoir.\"\n",
        "\n",
        "Response-level code:\n",
        "‚úì \"Consultation automatis√©e comme point de d√©part modul√© par l'enjeu\"\n",
        "\n",
        "(Captures: automation + starting point + modulation - in one concept)\n",
        "\n",
        "---\n",
        "\n",
        "Q: \"Est-ce que vous vous sentez d√©pendant ?\"\n",
        "R: \"Ouais, je peux plus faire sans maintenant. Mais bon c'est normal,\n",
        "    tout le monde utilise.\"\n",
        "\n",
        "Response-level code:\n",
        "‚úì \"D√©pendance normalis√©e et collectivement valid√©e\"\n",
        "\n",
        "---\n",
        "\n",
        "Q: \"Que pensent vos profs ?\"\n",
        "R: \"C'est le probl√®me, personne dit clairement. Y'en a qui interdisent,\n",
        "    d'autres qui s'en foutent. On sait jamais.\"\n",
        "\n",
        "Response-level code:\n",
        "‚úì \"Perception d'un flou institutionnel g√©n√©rant incertitude\"\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "IMPORTANT NOTES:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "‚Ä¢ One response ‚Üí typically ONE code (max 2 if clearly distinct topics)\n",
        "‚Ä¢ You're seeing limited context - can't judge if patterns recur across interviews\n",
        "‚Ä¢ That's OK - recurrence will be detected in later filtering stage\n",
        "‚Ä¢ Focus on capturing the ESSENCE of each response conceptually\n",
        "\n",
        "CODE QUALITY CHECKLIST:\n",
        "‚úì Uses informant vocabulary (not academic)?\n",
        "‚úì Conceptual (not micro-descriptive)?\n",
        "‚úì Self-explanatory (4-8 words)?\n",
        "‚úì Captures pattern/logic (not just lists actions)?\n",
        "\n",
        "Return ONLY valid JSON: {\"codes\": [\"code 1\", \"code 2\", ...]}\n",
        "\"\"\"\n",
        "\n",
        "        all_codes = []\n",
        "        code_metadata = []  # Pour tra√ßabilit√©\n",
        "\n",
        "        for doc_idx, (doc_name, text) in enumerate(documents.items(), 1):\n",
        "            print_header(f\"üìÑ Document {doc_idx}/{len(documents)}: {doc_name}\", 2)\n",
        "\n",
        "            # üÜï Essayer de d√©tecter unit√©s Q/R\n",
        "            qa_units = self.detect_qa_units(text, doc_name)\n",
        "\n",
        "            if qa_units:\n",
        "                # MODE Q/R: Coder par unit√©\n",
        "                print(f\"   ‚Üí Mode Q/R: {len(qa_units)} √©changes √† coder\")\n",
        "                self.qa_units.extend(qa_units)\n",
        "\n",
        "                for qa_idx, qa in enumerate(qa_units, 1):\n",
        "                    print(f\"\\n   √âchange Q/R {qa_idx}/{len(qa_units)}...\", end=\" \")\n",
        "\n",
        "                    # Prompt sp√©cifique Q/R\n",
        "                    prompt = f\"\"\"Research Question: {question}\n",
        "\n",
        "Interview Exchange #{qa_idx} from {doc_name}:\n",
        "\n",
        "QUESTION: {qa['question'][:300]}\n",
        "\n",
        "RESPONSE: {qa['answer']}\n",
        "\n",
        "Extract the KEY CONCEPT(S) from this response.\n",
        "Remember: Code the WHOLE response as a unit, not sentence-by-sentence.\n",
        "Maximum 1-2 codes per response.\n",
        "\n",
        "Return JSON.\"\"\"\n",
        "\n",
        "                    show_prompts = (doc_idx == 1 and qa_idx == 1)\n",
        "\n",
        "                    result = self.call_api(system_message, prompt,\n",
        "                                         json_mode=True, temperature=0,\n",
        "                                         show_prompts=show_prompts)\n",
        "\n",
        "                    if result:\n",
        "                        try:\n",
        "                            clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                            data = json.loads(clean)\n",
        "                            codes = data.get(\"codes\", [])\n",
        "\n",
        "                            # Limiter √† 2 codes max par r√©ponse\n",
        "                            codes = codes[:2]\n",
        "\n",
        "                            all_codes.extend(codes)\n",
        "                            qa['codes'] = codes\n",
        "\n",
        "                            # Tra√ßabilit√©\n",
        "                            for code in codes:\n",
        "                                code_metadata.append({\n",
        "                                    'code': code,\n",
        "                                    'source': doc_name,\n",
        "                                    'qa_id': qa['qa_id'],\n",
        "                                    'question': qa['question'][:100],\n",
        "                                    'answer': qa['answer'][:200]\n",
        "                                })\n",
        "\n",
        "                            print(f\"‚úì {len(codes)} code(s)\")\n",
        "                            if codes and qa_idx == 1:\n",
        "                                print(f\"      Exemples: {codes[0][:60]}...\")\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚úó Erreur JSON: {str(e)[:50]}\")\n",
        "                    else:\n",
        "                        print(\"‚úó √âchec API\")\n",
        "\n",
        "            else:\n",
        "                # FALLBACK: Mode chunks classiques\n",
        "                print(f\"   ‚Üí Mode chunks classiques (Q/R non d√©tect√©)\")\n",
        "\n",
        "                chunks = self.chunk_text(text, max_chars=10000, overlap=50)\n",
        "                print(f\"   ‚Üí {len(chunks)} chunks\")\n",
        "\n",
        "                for chunk_idx, chunk in enumerate(chunks, 1):\n",
        "                    print(f\"\\n   Chunk {chunk_idx}/{len(chunks)}...\", end=\" \")\n",
        "\n",
        "                    # Stocker chunk pour RAG\n",
        "                    self.document_chunks.append({\n",
        "                        'source': doc_name,\n",
        "                        'chunk_id': chunk_idx,\n",
        "                        'text': chunk\n",
        "                    })\n",
        "\n",
        "                    prompt = f\"\"\"Research Question: {question}\n",
        "\n",
        "Transcript chunk from {doc_name}:\n",
        "\n",
        "{chunk}\n",
        "\n",
        "Extract emergent concepts. Code at RESPONSE level when possible.\n",
        "If you see Q/R exchanges, code each response as ONE unit.\n",
        "\n",
        "Return 8-15 codes for this chunk.\"\"\"\n",
        "\n",
        "                    show_prompts = (doc_idx == 1 and chunk_idx == 1)\n",
        "\n",
        "                    result = self.call_api(system_message, prompt,\n",
        "                                         json_mode=True, temperature=0,\n",
        "                                         show_prompts=show_prompts)\n",
        "\n",
        "                    if result:\n",
        "                        try:\n",
        "                            clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                            data = json.loads(clean)\n",
        "                            codes = data.get(\"codes\", [])\n",
        "\n",
        "                            all_codes.extend(codes)\n",
        "\n",
        "                            # Tra√ßabilit√©\n",
        "                            for code in codes:\n",
        "                                code_metadata.append({\n",
        "                                    'code': code,\n",
        "                                    'source': doc_name,\n",
        "                                    'chunk_id': chunk_idx,\n",
        "                                    'chunk_text': chunk[:200]\n",
        "                                })\n",
        "\n",
        "                            print(f\"‚úì {len(codes)} codes\")\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚úó Erreur: {str(e)[:50]}\")\n",
        "                    else:\n",
        "                        print(\"‚úó √âchec\")\n",
        "\n",
        "        # Sauvegarder codes bruts et m√©tadonn√©es\n",
        "        self.raw_codes = all_codes\n",
        "        self._code_metadata = code_metadata\n",
        "\n",
        "        # Construire mapping code ‚Üí sources\n",
        "        for meta in code_metadata:\n",
        "            code = meta['code']\n",
        "            source = meta['source']\n",
        "            chunk_id = meta.get('chunk_id', meta.get('qa_id', 0))\n",
        "\n",
        "            if code not in self.code_to_chunks:\n",
        "                self.code_to_chunks[code] = []\n",
        "            self.code_to_chunks[code].append((source, chunk_id))\n",
        "\n",
        "        print_header(\"üìä R√âSULTATS √âTAPE 1a\", 1)\n",
        "        print(f\"‚úì TOTAL codes bruts: {len(all_codes)}\")\n",
        "        print(f\"‚úì Codes uniques: {len(set(all_codes))}\")\n",
        "        if self.qa_units:\n",
        "            print(f\"‚úì Unit√©s Q/R trait√©es: {len(self.qa_units)}\")\n",
        "        if self.document_chunks:\n",
        "            print(f\"‚úì Chunks pour RAG: {len(self.document_chunks)}\")\n",
        "\n",
        "        # Statistiques de longueur\n",
        "        lengths = [len(code.split()) for code in all_codes]\n",
        "        print(f\"\\nüìè Longueur des codes:\")\n",
        "        print(f\"   Moyenne: {np.mean(lengths):.1f} mots\")\n",
        "        print(f\"   Min/Max: {min(lengths)}/{max(lengths)} mots\")\n",
        "\n",
        "        display_results(list(set(all_codes))[:30], \"Codes uniques (√©chantillon)\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 1a termin√©e. ENTR√âE pour filtre de fr√©quence...\")\n",
        "\n",
        "        # Embeddings pour RAG (avec cache automatique)\n",
        "        if self.document_chunks:\n",
        "            self.embed_all_chunks()\n",
        "\n",
        "        return all_codes\n",
        "\n",
        "    def embed_all_chunks(self):\n",
        "        \"\"\"\n",
        "        G√©n√®re embeddings pour RAG avec syst√®me de cache.\n",
        "\n",
        "        Workflow:\n",
        "        1. Calcule hash des chunks actuels\n",
        "        2. Tente de charger cache si disponible\n",
        "        3. Si cache invalide/absent, g√©n√®re embeddings\n",
        "        4. Sauvegarde nouveau cache\n",
        "        \"\"\"\n",
        "        if not self.document_chunks:\n",
        "            return\n",
        "\n",
        "        print_header(\"üî¢ G√âN√âRATION EMBEDDINGS POUR RAG\", 2)\n",
        "        print(f\"Chunks √† embedder: {len(self.document_chunks)}\")\n",
        "\n",
        "        # Calculer hash des documents\n",
        "        self.documents_hash = self.compute_documents_hash()\n",
        "\n",
        "        # Essayer de charger cache\n",
        "        cache_loaded = self.load_embeddings_cache()\n",
        "\n",
        "        if cache_loaded:\n",
        "            print(\"‚úì Embeddings charg√©s depuis cache (gain de temps!)\")\n",
        "            return\n",
        "\n",
        "        # Sinon, g√©n√©rer les embeddings\n",
        "        print(\"\\nüîÑ G√©n√©ration des embeddings (ceci peut prendre 2-5 min)...\")\n",
        "        print(\"   (Les embeddings seront sauvegard√©s pour r√©utilisation)\")\n",
        "\n",
        "        self.chunk_embeddings = []\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, chunk_data in enumerate(self.document_chunks, 1):\n",
        "            if i % 10 == 0 or i == len(self.document_chunks):\n",
        "                elapsed = time.time() - start_time\n",
        "                progress = i / len(self.document_chunks) * 100\n",
        "                eta = (elapsed / i * len(self.document_chunks) - elapsed) if i > 0 else 0\n",
        "                print(f\"  {i}/{len(self.document_chunks)} ({progress:.0f}%) - \"\n",
        "                      f\"ETA: {eta:.0f}s\", end=\"\\r\", flush=True)\n",
        "\n",
        "            emb = self.generate_embedding(chunk_data['text'])\n",
        "            self.chunk_embeddings.append(emb)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"\\n‚úì {len(self.chunk_embeddings)} embeddings g√©n√©r√©s en {elapsed:.0f}s\")\n",
        "\n",
        "        # Sauvegarder cache pour prochaine fois\n",
        "        self.save_embeddings_cache()\n",
        "\n",
        "    def find_relevant_chunks(self, query: str, top_k: int = 4) -> List[Dict]:\n",
        "        \"\"\"RAG (inchang√©).\"\"\"\n",
        "        if not self.chunk_embeddings:\n",
        "            return []\n",
        "\n",
        "        query_emb = self.generate_embedding(query, \"retrieval_query\")\n",
        "        scored = []\n",
        "        for chunk, emb in zip(self.document_chunks, self.chunk_embeddings):\n",
        "            sim = self.cosine_similarity(query_emb, emb)\n",
        "            scored.append({**chunk, 'similarity': sim})\n",
        "\n",
        "        scored.sort(key=lambda x: x['similarity'], reverse=True)\n",
        "        return scored[:top_k]\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï √âTAPE 1b: FILTRE DE FR√âQUENCE\n",
        "    # ========================================================================\n",
        "\n",
        "    def filter_by_frequency(self, raw_codes: List[str], min_occurrences: int = 2) -> List[str]:\n",
        "        \"\"\"\n",
        "        √âTAPE 1b: Filtre les codes pour ne garder que ceux qui apparaissent\n",
        "        dans au moins N sources/chunks DIFF√âRENTS.\n",
        "\n",
        "        C'est ici qu'on d√©tecte structurellement la R√âCURRENCE.\n",
        "        Le LLM ne peut pas le faire au moment de l'extraction (vue limit√©e).\n",
        "\n",
        "        Args:\n",
        "            raw_codes: Liste des codes bruts extraits\n",
        "            min_occurrences: Nombre minimum d'occurrences dans diff√©rentes sources\n",
        "\n",
        "        Returns:\n",
        "            Liste des codes r√©currents\n",
        "        \"\"\"\n",
        "        print_header(\"√âTAPE 1b: FILTRE DE R√âCURRENCE\", 1)\n",
        "        print(f\"Objectif: Identifier les patterns qui apparaissent au moins {min_occurrences} fois\")\n",
        "        print(f\"dans diff√©rentes unit√©s (Q/R ou chunks)\\n\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  Appuyez sur ENTR√âE pour lancer le filtrage...\")\n",
        "\n",
        "        # Compter occurrences par code\n",
        "        code_counts = Counter(raw_codes)\n",
        "\n",
        "        # Compter nombre de sources diff√©rentes par code\n",
        "        code_sources = {}\n",
        "        for code, occurrences in self.code_to_chunks.items():\n",
        "            # Sources uniques\n",
        "            unique_sources = set(occ[0] for occ in occurrences)\n",
        "            # Unit√©s uniques (source, chunk/qa_id)\n",
        "            unique_units = set(occurrences)\n",
        "\n",
        "            code_sources[code] = {\n",
        "                'count': len(occurrences),\n",
        "                'sources': unique_sources,\n",
        "                'units': unique_units\n",
        "            }\n",
        "\n",
        "        # Filtrer: garder codes avec N+ occurrences dans unit√©s diff√©rentes\n",
        "        recurring_codes = []\n",
        "        for code in set(raw_codes):\n",
        "            if code in code_sources:\n",
        "                info = code_sources[code]\n",
        "                # Crit√®re: au moins N unit√©s DIFF√âRENTES\n",
        "                if len(info['units']) >= min_occurrences:\n",
        "                    recurring_codes.append(code)\n",
        "\n",
        "        # Statistiques\n",
        "        print(f\"üìä R√©sultats du filtrage:\")\n",
        "        print(f\"  ‚Ä¢ Codes bruts totaux: {len(raw_codes)}\")\n",
        "        print(f\"  ‚Ä¢ Codes uniques: {len(set(raw_codes))}\")\n",
        "        print(f\"  ‚Ä¢ Codes r√©currents (‚â•{min_occurrences} unit√©s): {len(recurring_codes)}\")\n",
        "        print(f\"  ‚Ä¢ Taux de r√©tention: {len(recurring_codes)/len(set(raw_codes))*100:.1f}%\")\n",
        "\n",
        "        # Exemples par fr√©quence d√©croissante\n",
        "        print(\"\\nüìà Top 15 codes par fr√©quence:\")\n",
        "        sorted_codes = sorted(\n",
        "            recurring_codes,\n",
        "            key=lambda c: len(code_sources.get(c, {}).get('units', [])),\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        for i, code in enumerate(sorted_codes[:15], 1):\n",
        "            info = code_sources.get(code, {})\n",
        "            count = len(info.get('units', []))\n",
        "            n_sources = len(info.get('sources', []))\n",
        "            print(f\"  {i:2d}. {code[:70]}\")\n",
        "            print(f\"      ‚Üí {count} occurrences dans {n_sources} documents\")\n",
        "\n",
        "        self.recurring_codes = recurring_codes\n",
        "\n",
        "        wait_for_user(f\"\\n‚è∏  Filtrage termin√©. {len(recurring_codes)} codes r√©currents identifi√©s. ENTR√âE pour consolidation...\")\n",
        "\n",
        "        return recurring_codes\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï √âTAPE 1c: CONSOLIDATION CONCEPTUELLE\n",
        "    # ========================================================================\n",
        "\n",
        "    def consolidate_codes(self, recurring_codes: List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        √âTAPE 1c: Consolidation des codes r√©currents en codes conceptuels finaux.\n",
        "\n",
        "        Objectifs:\n",
        "        - Regrouper variations s√©mantiques\n",
        "        - √âlever au niveau conceptuel\n",
        "        - Maintenir vocabulaire informant\n",
        "        - Tra√ßabilit√© compl√®te\n",
        "\n",
        "        R√©duction attendue: 300-500 codes ‚Üí 80-150 codes\n",
        "        \"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 1c: CONSOLIDATION CONCEPTUELLE\", 1)\n",
        "        print(\"Objectif: Regrouper codes redondants et √©lever au niveau conceptuel\")\n",
        "        print(f\"\\nüìä {len(recurring_codes)} codes r√©currents √† consolider\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  Appuyez sur ENTR√âE pour lancer la consolidation...\")\n",
        "\n",
        "        system_message = \"\"\"You are performing CODE CONSOLIDATION in the Gioia method.\n",
        "\n",
        "NOW you see ALL codes extracted from ALL interviews.\n",
        "Your task: Identify RECURRING PATTERNS and consolidate redundant codes.\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "CONSOLIDATION PRINCIPLES:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "1. MERGE semantic duplicates\n",
        "   \"R√©flexe de consultation\" + \"Consultation automatique\" + \"Demander syst√©matiquement\"\n",
        "   ‚Üí \"Automatisation du r√©flexe de consultation IA\"\n",
        "\n",
        "2. IDENTIFY recurring patterns\n",
        "   If similar concepts appear multiple times = RECURRING PATTERN\n",
        "   ‚Üí Consolidate into ONE conceptual code\n",
        "\n",
        "3. PRESERVE distinct phenomena\n",
        "   Don't merge genuinely different concepts just to reduce count\n",
        "   Keep: \"D√©pendance fonctionnelle\" vs \"Plaisir d'usage\" (different!)\n",
        "\n",
        "4. MAINTAIN informant vocabulary\n",
        "   ‚úì Stay in their language: \"r√©flexe\", \"habitude\", \"d√©pendance\"\n",
        "   ‚úó Avoid academic jargon: \"externalisation cognitive\", \"habitus\"\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "CRITERIA FOR CONSOLIDATED CODES:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "‚úì Groups multiple similar raw codes (semantic consolidation)\n",
        "‚úì Uses informant vocabulary (not researcher jargon)\n",
        "‚úì Conceptual level (not micro-descriptive)\n",
        "‚úì Self-explanatory (4-8 words)\n",
        "‚úì Distinct from other consolidated codes\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "TRANSFORMATION EXAMPLES:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "Example 1 - Usage patterns:\n",
        "Raw codes:\n",
        "‚Ä¢ \"Consultation automatis√©e de ChatGPT\"\n",
        "‚Ä¢ \"R√©flexe de demander √† l'IA\"\n",
        "‚Ä¢ \"Premier geste = ouvrir ChatGPT\"\n",
        "‚Ä¢ \"Automatisme de consultation\"\n",
        "\n",
        "Consolidated:\n",
        "‚úì \"Automatisation du r√©flexe de consultation IA\"\n",
        "\n",
        "Example 2 - Tensions:\n",
        "Raw codes:\n",
        "‚Ä¢ \"Sentiment de triche mais permis\"\n",
        "‚Ä¢ \"Culpabilit√© malgr√© autorisation\"\n",
        "‚Ä¢ \"Ambigu√Øt√© morale de l'usage\"\n",
        "‚Ä¢ \"Impression de malhonn√™tet√© l√©gitime\"\n",
        "\n",
        "Consolidated:\n",
        "‚úì \"Ambigu√Øt√© morale de l'usage l√©gitime mais culpabilisant\"\n",
        "\n",
        "Example 3 - Strategies:\n",
        "Raw codes:\n",
        "‚Ä¢ \"Modifier plus si devoir important\"\n",
        "‚Ä¢ \"Appropriation variable selon enjeu\"\n",
        "‚Ä¢ \"Calibrage de l'intervention\"\n",
        "‚Ä¢ \"Ajustement selon importance\"\n",
        "\n",
        "Consolidated:\n",
        "‚úì \"Calibrage strat√©gique de l'appropriation selon l'enjeu\"\n",
        "\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\n",
        "TARGET: Consolidate ~200 codes into 15-30 conceptual codes per batch\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "{\n",
        "  \"consolidated_codes\": [\n",
        "    \"code 1\",\n",
        "    \"code 2\",\n",
        "    ...\n",
        "  ],\n",
        "  \"merging_rationale\": {\n",
        "    \"code 1\": [\"raw_code_1\", \"raw_code_2\", ...],\n",
        "    \"code 2\": [\"raw_code_5\", \"raw_code_6\"],\n",
        "    ...\n",
        "  }\n",
        "}\n",
        "\n",
        "The rationale maintains audit trail for methodological transparency.\n",
        "\n",
        "Return ONLY valid JSON.\n",
        "\"\"\"\n",
        "\n",
        "        # Traiter par batch\n",
        "        batch_size = 200\n",
        "        all_consolidated = []\n",
        "        all_rationales = {}\n",
        "\n",
        "        for i in range(0, len(recurring_codes), batch_size):\n",
        "            batch = recurring_codes[i:i+batch_size]\n",
        "            batch_num = i//batch_size + 1\n",
        "            total_batches = (len(recurring_codes)-1)//batch_size + 1\n",
        "\n",
        "            print(f\"\\nüì¶ Batch {batch_num}/{total_batches}\")\n",
        "            print(f\"   {len(batch)} codes √† consolider...\")\n",
        "\n",
        "            prompt = f\"\"\"Codes to consolidate (from interviews about students' ChatGPT use):\n",
        "\n",
        "{json.dumps(batch, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Consolidate these codes following the principles above.\n",
        "- Group semantically similar codes\n",
        "- Elevate to conceptual level\n",
        "- Maintain informant vocabulary (French terms from interviews)\n",
        "\n",
        "Return JSON with consolidated codes and merging rationale.\"\"\"\n",
        "\n",
        "            show_prompts = (i == 0)\n",
        "\n",
        "            result = self.call_api(system_message, prompt,\n",
        "                                 json_mode=True, temperature=0,\n",
        "                                 show_prompts=show_prompts)\n",
        "\n",
        "            if result:\n",
        "                try:\n",
        "                    clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                    data = json.loads(clean)\n",
        "\n",
        "                    consolidated = data.get(\"consolidated_codes\", [])\n",
        "                    rationale = data.get(\"merging_rationale\", {})\n",
        "\n",
        "                    all_consolidated.extend(consolidated)\n",
        "                    all_rationales.update(rationale)\n",
        "\n",
        "                    print(f\"   ‚úì {len(batch)} codes ‚Üí {len(consolidated)} codes consolid√©s\")\n",
        "\n",
        "                    if i == 0 and consolidated:\n",
        "                        print(\"\\n   Exemples:\")\n",
        "                        for j, code in enumerate(consolidated[:3], 1):\n",
        "                            print(f\"      {j}. {code}\")\n",
        "                            originals = rationale.get(code, [])\n",
        "                            if originals:\n",
        "                                print(f\"         ‚Üê {len(originals)} codes: {originals[0][:50]}...\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚úó Erreur: {str(e)[:100]}\")\n",
        "            else:\n",
        "                print(\"   ‚úó √âchec API\")\n",
        "\n",
        "        # D√©duplication finale\n",
        "        final_codes = list(dict.fromkeys(all_consolidated))\n",
        "\n",
        "        print_header(\"üìä R√âSULTATS CONSOLIDATION\", 1)\n",
        "        print(f\"‚úì Codes r√©currents: {len(recurring_codes)}\")\n",
        "        print(f\"‚úì Codes consolid√©s: {len(final_codes)}\")\n",
        "        print(f\"‚úì Taux de r√©duction: {(1 - len(final_codes)/len(recurring_codes))*100:.1f}%\")\n",
        "\n",
        "        # Sauvegarder mapping\n",
        "        self.consolidation_mapping = all_rationales\n",
        "        self.first_order_codes = final_codes\n",
        "\n",
        "        display_results(final_codes[:30], \"Codes consolid√©s (√©chantillon)\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  Consolidation termin√©e. ENTR√âE pour passer √† l'√©tape 2...\")\n",
        "\n",
        "        return final_codes\n",
        "\n",
        "    # ========================================================================\n",
        "    # √âTAPE 2: SECOND-ORDER CODING (modifi√© pour codes consolid√©s)\n",
        "    # ========================================================================\n",
        "\n",
        "    def second_order_coding(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        √âTAPE 2: Second-order coding avec clustering des codes CONSOLID√âS.\n",
        "\n",
        "        D√©sormais on clusterise 80-150 codes (pas 6000!), donc plus g√©rable.\n",
        "        \"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 2: SECOND-ORDER CODING (CLUSTERING)\", 1)\n",
        "        print(\"Objectif: Regrouper codes consolid√©s en 10-15 th√®mes\")\n",
        "\n",
        "        if not self.first_order_codes:\n",
        "            print(\"‚úó Pas de codes consolid√©s\")\n",
        "            return {}\n",
        "\n",
        "        print(f\"\\nüìä {len(self.first_order_codes)} codes consolid√©s √† th√©matiser\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  Appuyez sur ENTR√âE pour lancer le clustering...\")\n",
        "\n",
        "        # Clustering en 12 groupes\n",
        "        print(\"\\nüîÑ G√©n√©ration embeddings pour clustering...\")\n",
        "        code_embeddings = []\n",
        "        for i, code in enumerate(self.first_order_codes, 1):\n",
        "            if i % 50 == 0 or i == len(self.first_order_codes):\n",
        "                print(f\"   ‚Üí {i}/{len(self.first_order_codes)} embeddings\")\n",
        "            emb = self.generate_embedding(code, \"clustering\")\n",
        "            code_embeddings.append(emb)\n",
        "\n",
        "        print(\"\\nüéØ Clustering en 12 groupes...\")\n",
        "        from sklearn.cluster import KMeans\n",
        "        kmeans = KMeans(n_clusters=12, random_state=42, n_init=10, max_iter=300)\n",
        "        cluster_labels = kmeans.fit_predict(code_embeddings)\n",
        "\n",
        "        print(\"\\nüè∑Ô∏è  Cr√©ation des noms de th√®mes...\")\n",
        "        themes = {}\n",
        "\n",
        "        for cluster_id in range(12):\n",
        "            cluster_codes = [\n",
        "                code for code, label in zip(self.first_order_codes, cluster_labels)\n",
        "                if label == cluster_id\n",
        "            ]\n",
        "\n",
        "            print(f\"\\n   Cluster {cluster_id + 1}/12 : {len(cluster_codes)} codes\")\n",
        "\n",
        "            # √âchantillon pour naming\n",
        "            sample = cluster_codes[:min(15, len(cluster_codes))]\n",
        "\n",
        "            theme_name = self.name_theme_from_codes(sample, cluster_id + 1)\n",
        "            themes[theme_name] = cluster_codes\n",
        "\n",
        "            print(f\"   ‚úì '{theme_name}'\")\n",
        "            print(f\"     ‚Üí {len(cluster_codes)} codes\")\n",
        "\n",
        "        self.second_order_themes = themes\n",
        "\n",
        "        print_header(\"üìä R√âSULTATS √âTAPE 2\", 1)\n",
        "        print(f\"‚úì {len(themes)} th√®mes cr√©√©s\")\n",
        "        total = sum(len(codes) for codes in themes.values())\n",
        "        print(f\"‚úì {total}/{len(self.first_order_codes)} codes assign√©s\")\n",
        "\n",
        "        display_results(self.second_order_themes, \"Second-Order Themes\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 2 termin√©e. ENTR√âE pour √©tape 3...\")\n",
        "\n",
        "        return self.second_order_themes\n",
        "\n",
        "    def name_theme_from_codes(self, codes_sample: List[str], cluster_num: int) -> str:\n",
        "        \"\"\"Nomme un th√®me (inchang√©).\"\"\"\n",
        "\n",
        "        system_message = \"\"\"You are applying 2nd Order Coding in the Gioia method.\n",
        "\n",
        "Given first-order codes (informant language), create ONE concise\n",
        "second-order theme name in academic language.\n",
        "\n",
        "The theme name should:\n",
        "- Be 3-8 words\n",
        "- Use abstract, academic language (unlike first-order codes)\n",
        "- Capture what all these codes have in common\n",
        "\n",
        "Return ONLY the theme name.\"\"\"\n",
        "\n",
        "        prompt = f\"\"\"First-order codes from cluster {cluster_num}:\n",
        "\n",
        "{json.dumps(codes_sample, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Create ONE second-order theme name (3-8 words, academic language).\n",
        "\n",
        "Return ONLY the theme name.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                              json_mode=False, temperature=0,\n",
        "                              show_prompts=(cluster_num == 1))\n",
        "\n",
        "        theme_name = result.strip().strip('\"').strip(\"'\") if result else f\"Theme {cluster_num}\"\n",
        "        return theme_name\n",
        "\n",
        "    # ========================================================================\n",
        "    # √âTAPES 3-4: INCHANG√âES (aggregate, theories, tuples, interrel, mod√®le)\n",
        "    # ========================================================================\n",
        "\n",
        "    def aggregate_dimensions_coding(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"√âTAPE 3: Aggregate dimensions (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 3: AGGREGATE DIMENSIONS\", 1)\n",
        "        print(\"Objectif: Regrouper th√®mes en 5-7 dimensions quantifiables\")\n",
        "\n",
        "        if not self.second_order_themes:\n",
        "            print(\"‚úó Pas de th√®mes\")\n",
        "            return {}\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour cr√©er les dimensions...\")\n",
        "\n",
        "        system_message = \"\"\"You are applying Aggregate Dimensions phase of Gioia method.\n",
        "\n",
        "Identify overarching theoretical dimensions (5-7) that aggregate the 2nd order themes.\n",
        "\n",
        "CRITICAL: Dimensions must be QUANTIFIABLE.\n",
        "\n",
        "Output: {\"Dimension 1\": [\"theme 1\", \"theme 2\"], ...}\n",
        "\n",
        "Return ONLY valid JSON.\"\"\"\n",
        "\n",
        "        theme_names = list(self.second_order_themes.keys())\n",
        "\n",
        "        prompt = f\"\"\"2nd order themes:\n",
        "\n",
        "{json.dumps(theme_names, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Create 5-7 aggregate dimensions that:\n",
        "1. Are quantifiable/measurable\n",
        "2. Aggregate related themes\n",
        "3. Serve as overarching constructs\n",
        "\n",
        "Return JSON.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=True, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            try:\n",
        "                clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                self.aggregate_dimensions = json.loads(clean)\n",
        "\n",
        "                print_header(\"üìä R√âSULTATS √âTAPE 3\", 1)\n",
        "                print(f\"‚úì {len(self.aggregate_dimensions)} dimensions cr√©√©es\")\n",
        "                display_results(self.aggregate_dimensions, \"Aggregate Dimensions\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚úó Erreur: {str(e)[:100]}\")\n",
        "                self.aggregate_dimensions = {}\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 3 termin√©e. ENTR√âE pour √©tape 4a...\")\n",
        "\n",
        "        return self.aggregate_dimensions\n",
        "\n",
        "    def brainstorm_theories(self) -> List[Dict]:\n",
        "        \"\"\"√âTAPE 4a: Brainstorm theories (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 4a: BRAINSTORM THEORIES\", 1)\n",
        "\n",
        "        if not self.aggregate_dimensions:\n",
        "            return []\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour brainstormer th√©ories...\")\n",
        "\n",
        "        system_message = \"\"\"Brainstorm theoretical models from literature applicable to research findings.\n",
        "\n",
        "Output:\n",
        "{\n",
        "  \"theories\": [\n",
        "    {\n",
        "      \"theory\": \"Name\",\n",
        "      \"description\": \"Brief description\",\n",
        "      \"relatedDimensions\": [\"Dim 1\"],\n",
        "      \"possibleResearchQuestions\": [\"Q1\"]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "Return ONLY JSON.\"\"\"\n",
        "\n",
        "        dims_detail = {dim: themes for dim, themes in self.aggregate_dimensions.items()}\n",
        "\n",
        "        prompt = f\"\"\"Aggregate dimensions:\n",
        "\n",
        "{json.dumps(dims_detail, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Brainstorm 5-8 theoretical models.\n",
        "\n",
        "Return JSON.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=True, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            try:\n",
        "                clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                data = json.loads(clean)\n",
        "                self.applicable_theories = data.get(\"theories\", [])\n",
        "\n",
        "                print_header(\"üìä R√âSULTATS √âTAPE 4a\", 1)\n",
        "                print(f\"‚úì {len(self.applicable_theories)} th√©ories\")\n",
        "\n",
        "                for i, theory in enumerate(self.applicable_theories, 1):\n",
        "                    print(f\"\\n{i}. {theory.get('theory', 'N/A')}\")\n",
        "                    print(f\"   {theory.get('description', '')[:200]}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚úó Erreur: {str(e)[:100]}\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 4a termin√©e. ENTR√âE pour 4b...\")\n",
        "\n",
        "        return self.applicable_theories\n",
        "\n",
        "    def develop_concept_tuples(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"√âTAPE 4b: Concept tuples (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 4b: CONCEPT TUPLES\", 1)\n",
        "\n",
        "        if not self.aggregate_dimensions:\n",
        "            return []\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour g√©n√©rer tuples...\")\n",
        "\n",
        "        system_message = \"\"\"Hypothesize which concepts could be related.\n",
        "\n",
        "Return: {\"tuples\": [[\"concept 1\", \"concept 2\"], ...]}\n",
        "\n",
        "ONLY JSON.\"\"\"\n",
        "\n",
        "        dims_detail = {dim: themes for dim, themes in self.aggregate_dimensions.items()}\n",
        "\n",
        "        prompt = f\"\"\"Dimensions:\n",
        "\n",
        "{json.dumps(dims_detail, ensure_ascii=False, indent=2)}\n",
        "\n",
        "Hypothesize 10-20 tuples of potential relationships.\n",
        "\n",
        "Return JSON.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=True, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            try:\n",
        "                clean = result.strip().replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "                data = json.loads(clean)\n",
        "                tuples_list = data.get(\"tuples\", [])\n",
        "                self.concept_tuples = [(t[0], t[1]) for t in tuples_list if len(t) == 2]\n",
        "\n",
        "                print_header(\"üìä R√âSULTATS √âTAPE 4b\", 1)\n",
        "                print(f\"‚úì {len(self.concept_tuples)} tuples\")\n",
        "\n",
        "                for i, (c1, c2) in enumerate(self.concept_tuples[:15], 1):\n",
        "                    print(f\"  {i:2d}. {c1} ‚Üî {c2}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚úó Erreur: {str(e)[:100]}\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 4b termin√©e. ENTR√âE pour 4c (RAG)...\")\n",
        "\n",
        "        return self.concept_tuples\n",
        "\n",
        "    def explore_interrelationships(self) -> Dict[Tuple[str, str], str]:\n",
        "        \"\"\"√âTAPE 4c: Interrelations RAG (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"√âTAPE 4c: INTERRELATIONSHIPS (RAG)\", 1)\n",
        "\n",
        "        if not self.concept_tuples or not self.chunk_embeddings:\n",
        "            return {}\n",
        "\n",
        "        wait_for_user(f\"‚è∏  ENTR√âE pour explorer {len(self.concept_tuples)} relations...\")\n",
        "\n",
        "        system_message = \"\"\"Summarize interrelationship between two concepts in one sentence.\n",
        "\n",
        "Based on evidence passages, explain how concepts relate.\n",
        "\n",
        "IMPORTANT: Passages may contain metadata. Focus ONLY on interview dialogue.\n",
        "\n",
        "Return ONLY one-sentence summary.\"\"\"\n",
        "\n",
        "        print(f\"\\nExploration...\")\n",
        "\n",
        "        for i, (c1, c2) in enumerate(self.concept_tuples, 1):\n",
        "            print(f\"{i:2d}/{len(self.concept_tuples)}: {c1} ‚Üî {c2}\")\n",
        "\n",
        "            query = f\"{c1} {c2}\"\n",
        "            relevant_chunks = self.find_relevant_chunks(query, top_k=4)\n",
        "\n",
        "            if not relevant_chunks:\n",
        "                self.interrelationships[(c1, c2)] = {\n",
        "                    'summary': \"No clear relationship in data.\",\n",
        "                    'evidence_chunks': []\n",
        "                }\n",
        "                continue\n",
        "\n",
        "            context = \"\\n\\n\".join([\n",
        "                f\"[Passage {j+1}]:\\n{chunk['text'][:500]}\"\n",
        "                for j, chunk in enumerate(relevant_chunks)\n",
        "            ])\n",
        "\n",
        "            prompt = f\"\"\"Passages:\n",
        "\n",
        "{context}\n",
        "\n",
        "Summarize relationship between \"{c1}\" and \"{c2}\" in one sentence.\n",
        "\n",
        "Return summary.\"\"\"\n",
        "\n",
        "            result = self.call_api(system_message, prompt,\n",
        "                                 json_mode=False, temperature=0,\n",
        "                                 show_prompts=(i==1))\n",
        "\n",
        "            if result:\n",
        "                self.interrelationships[(c1, c2)] = {\n",
        "                    'summary': result.strip(),\n",
        "                    'evidence_chunks': relevant_chunks\n",
        "                }\n",
        "                print(f\"     ‚úì {result.strip()[:60]}...\")\n",
        "            else:\n",
        "                self.interrelationships[(c1, c2)] = {\n",
        "                    'summary': \"Unable to determine.\",\n",
        "                    'evidence_chunks': []\n",
        "                }\n",
        "\n",
        "        print_header(\"üìä R√âSULTATS √âTAPE 4c\", 1)\n",
        "        print(f\"‚úì {len(self.interrelationships)} relations explor√©es\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  √âtape 4c termin√©e. ENTR√âE pour mod√®le (4d)...\")\n",
        "\n",
        "        return self.interrelationships\n",
        "\n",
        "    def construct_model(self, question: str, iteration: int = 1,\n",
        "                       previous_model: str = None, critique: str = None) -> str:\n",
        "        \"\"\"√âTAPE 4d: Mod√®le (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(f\"√âTAPE 4d: THEORETICAL MODEL (It√©ration {iteration})\", 1)\n",
        "\n",
        "        if not self.aggregate_dimensions:\n",
        "            return \"\"\n",
        "\n",
        "        wait_for_user(f\"‚è∏  ENTR√âE pour g√©n√©rer mod√®le (it. {iteration})...\")\n",
        "\n",
        "        system_message = \"\"\"Construct a theoretical model.\n",
        "\n",
        "The model should be:\n",
        "1. Well-defined and novel\n",
        "2. Related to aggregate dimensions\n",
        "3. Original\n",
        "\n",
        "Emphasize relationships between dimensions.\n",
        "\n",
        "Give distinctive name to model.\n",
        "\n",
        "Write in clear academic style.\"\"\"\n",
        "\n",
        "        theories_text = \"\\n\".join([\n",
        "            f\"- {t['theory']}: {t['description']}\"\n",
        "            for t in self.applicable_theories\n",
        "        ]) if self.applicable_theories else \"No theories.\"\n",
        "\n",
        "        dims_text = json.dumps(self.aggregate_dimensions, indent=2, ensure_ascii=False)\n",
        "\n",
        "        interrel_text = \"\\n\".join([\n",
        "            f\"- {c1} ‚Üî {c2}: {rel_data['summary']}\"\n",
        "            for (c1, c2), rel_data in list(self.interrelationships.items())[:15]\n",
        "        ]) if self.interrelationships else \"No interrelationships.\"\n",
        "\n",
        "        if iteration == 1:\n",
        "            prompt = f\"\"\"Research Question: {question}\n",
        "\n",
        "Dimensions:\n",
        "{dims_text}\n",
        "\n",
        "Theories:\n",
        "{theories_text}\n",
        "\n",
        "Interrelationships:\n",
        "{interrel_text}\n",
        "\n",
        "Construct comprehensive, novel theoretical model.\"\"\"\n",
        "        else:\n",
        "            prompt = f\"\"\"Research Question: {question}\n",
        "\n",
        "PREVIOUS MODEL:\n",
        "{previous_model}\n",
        "\n",
        "CRITIQUE:\n",
        "{critique}\n",
        "\n",
        "Dimensions:\n",
        "{dims_text}\n",
        "\n",
        "Construct REVISED model addressing critique.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=False, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            print_header(f\"üìä MOD√àLE (It√©ration {iteration})\", 1)\n",
        "            print_box(result, f\"Model - Iteration {iteration}\")\n",
        "            return result\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def critique_model(self, model_text: str, iteration: int) -> str:\n",
        "        \"\"\"√âTAPE 4e: Critique (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(f\"√âTAPE 4e: CRITIQUE (It√©ration {iteration})\", 1)\n",
        "\n",
        "        if not model_text:\n",
        "            return \"\"\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour critique...\")\n",
        "\n",
        "        system_message = \"\"\"Critique a theoretical model.\n",
        "\n",
        "Comment on:\n",
        "1. Novelty\n",
        "2. Conciseness\n",
        "3. Clarity\n",
        "4. Theoretical insight\n",
        "\n",
        "Suggest improvements.\"\"\"\n",
        "\n",
        "        codes_sample = self.first_order_codes[:20]\n",
        "        interrel_sample = list(self.interrelationships.items())[:10]\n",
        "\n",
        "        interrel_text = \"\\n\".join([\n",
        "            f\"- {c1} ‚Üî {c2}: {rel_data['summary']}\"\n",
        "            for (c1, c2), rel_data in interrel_sample\n",
        "        ])\n",
        "\n",
        "        prompt = f\"\"\"Codes sample:\n",
        "{json.dumps(codes_sample, ensure_ascii=False)}\n",
        "\n",
        "Interrelationships:\n",
        "{interrel_text}\n",
        "\n",
        "Model:\n",
        "{model_text}\n",
        "\n",
        "Provide critique.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=False, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            print_header(f\"üìä CRITIQUE (It√©ration {iteration})\", 1)\n",
        "            print_box(result, f\"Critique - Iteration {iteration}\")\n",
        "            return result\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def generate_mermaid_diagram(self) -> str:\n",
        "        \"\"\"G√©n√®re diagramme Mermaid (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"G√âN√âRATION DIAGRAMME MERMAID\", 1)\n",
        "\n",
        "        if not self.aggregate_dimensions or not self.interrelationships:\n",
        "            return \"\"\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour diagramme...\")\n",
        "\n",
        "        system_message = \"\"\"Create Mermaid flowchart showing relationships.\n",
        "\n",
        "Syntax:\n",
        "graph TD\n",
        "    A[Dimension] -->|relationship| B[Dimension]\n",
        "\n",
        "Return ONLY valid Mermaid code.\"\"\"\n",
        "\n",
        "        dims_list = list(self.aggregate_dimensions.keys())\n",
        "        interrel_text = \"\\n\".join([\n",
        "            f\"{c1} ‚Üî {c2}: {rel_data['summary']}\"\n",
        "            for (c1, c2), rel_data in self.interrelationships.items()\n",
        "        ])\n",
        "\n",
        "        prompt = f\"\"\"Dimensions:\n",
        "{json.dumps(dims_list, ensure_ascii=False)}\n",
        "\n",
        "Relationships:\n",
        "{interrel_text}\n",
        "\n",
        "Create Mermaid flowchart.\"\"\"\n",
        "\n",
        "        result = self.call_api(system_message, prompt,\n",
        "                             json_mode=False, temperature=0,\n",
        "                             show_prompts=True)\n",
        "\n",
        "        if result:\n",
        "            clean = result.strip()\n",
        "            if \"```mermaid\" in clean:\n",
        "                clean = clean.split(\"```mermaid\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in clean:\n",
        "                clean = clean.replace(\"```\", \"\").strip()\n",
        "\n",
        "            print_header(\"üìä DIAGRAMME MERMAID\", 1)\n",
        "            print_box(clean, \"Mermaid Code\")\n",
        "            return clean\n",
        "\n",
        "        return \"\"\n",
        "\n",
        "    def develop_theory_with_iterations(self, question: str, max_iterations: int = 2) -> Dict:\n",
        "        \"\"\"Pipeline avec it√©rations (inchang√©).\"\"\"\n",
        "\n",
        "        print_header(\"D√âVELOPPEMENT TH√âORIQUE IT√âRATIF\", 1)\n",
        "\n",
        "        results = {\n",
        "            'theories': self.applicable_theories,\n",
        "            'tuples': self.concept_tuples,\n",
        "            'interrelationships': self.interrelationships,\n",
        "            'models': [],\n",
        "            'critiques': [],\n",
        "            'mermaid': \"\"\n",
        "        }\n",
        "\n",
        "        for iteration in range(1, max_iterations + 1):\n",
        "            print_header(f\"üîÑ IT√âRATION {iteration}/{max_iterations}\", 1)\n",
        "\n",
        "            if iteration == 1:\n",
        "                model = self.construct_model(question, iteration=iteration)\n",
        "            else:\n",
        "                previous_model = results['models'][-1]\n",
        "                previous_critique = results['critiques'][-1]\n",
        "                model = self.construct_model(question, iteration=iteration,\n",
        "                                            previous_model=previous_model,\n",
        "                                            critique=previous_critique)\n",
        "\n",
        "            results['models'].append(model)\n",
        "\n",
        "            if model:\n",
        "                critique = self.critique_model(model, iteration)\n",
        "                results['critiques'].append(critique)\n",
        "\n",
        "                if iteration < max_iterations:\n",
        "                    wait_for_user(f\"‚è∏  It√©ration {iteration} termin√©e. ENTR√âE pour it. {iteration+1}...\")\n",
        "\n",
        "        wait_for_user(\"‚è∏  It√©rations termin√©es. ENTR√âE pour diagramme...\")\n",
        "\n",
        "        mermaid = self.generate_mermaid_diagram()\n",
        "        results['mermaid'] = mermaid\n",
        "\n",
        "        return results\n",
        "\n",
        "    # ========================================================================\n",
        "    # üÜï EXPORT ENRICHI AVEC TRA√áABILIT√â\n",
        "    # ========================================================================\n",
        "\n",
        "    def export_results(self, theory_results: Dict):\n",
        "        \"\"\"\n",
        "        Export enrichi avec:\n",
        "        - Codes consolid√©s\n",
        "        - Mapping consolidation (tra√ßabilit√©)\n",
        "        - Mapping fr√©quence (occurrence par source)\n",
        "        - Evidence chunks\n",
        "        \"\"\"\n",
        "\n",
        "        print_header(\"üíæ EXPORT DES R√âSULTATS\", 1)\n",
        "\n",
        "        wait_for_user(\"‚è∏  ENTR√âE pour g√©n√©rer fichiers...\")\n",
        "\n",
        "        # ---- Excel principal ----\n",
        "\n",
        "        # 1. Codes consolid√©s finaux\n",
        "        codes_df = pd.DataFrame({'First-Order Codes (Consolidated)': self.first_order_codes})\n",
        "\n",
        "        # 2. üÜï Mapping consolidation\n",
        "        if self.consolidation_mapping:\n",
        "            mapping_data = []\n",
        "            for consolidated, originals in self.consolidation_mapping.items():\n",
        "                for original in originals:\n",
        "                    mapping_data.append({\n",
        "                        'Consolidated Code': consolidated,\n",
        "                        'Original Raw Code': original\n",
        "                    })\n",
        "            mapping_df = pd.DataFrame(mapping_data)\n",
        "        else:\n",
        "            mapping_df = pd.DataFrame()\n",
        "\n",
        "        # 3. üÜï Fr√©quence des codes\n",
        "        if self.code_to_chunks:\n",
        "            freq_data = []\n",
        "            for code, occurrences in self.code_to_chunks.items():\n",
        "                sources = set(occ[0] for occ in occurrences)\n",
        "                freq_data.append({\n",
        "                    'Code': code,\n",
        "                    'Total Occurrences': len(occurrences),\n",
        "                    'Number of Documents': len(sources),\n",
        "                    'Documents': ', '.join(sources)\n",
        "                })\n",
        "            freq_df = pd.DataFrame(freq_data)\n",
        "            freq_df = freq_df.sort_values('Total Occurrences', ascending=False)\n",
        "        else:\n",
        "            freq_df = pd.DataFrame()\n",
        "\n",
        "        # 4. Second-order themes\n",
        "        themes_data = []\n",
        "        for theme, codes in self.second_order_themes.items():\n",
        "            for code in codes:\n",
        "                themes_data.append({\n",
        "                    'Second-Order Theme': theme,\n",
        "                    'First-Order Code': code\n",
        "                })\n",
        "        themes_df = pd.DataFrame(themes_data) if themes_data else pd.DataFrame()\n",
        "\n",
        "        # 5. Aggregate dimensions\n",
        "        dims_data = []\n",
        "        for dim, themes in self.aggregate_dimensions.items():\n",
        "            for theme in themes:\n",
        "                dims_data.append({\n",
        "                    'Aggregate Dimension': dim,\n",
        "                    'Second-Order Theme': theme\n",
        "                })\n",
        "        dims_df = pd.DataFrame(dims_data) if dims_data else pd.DataFrame()\n",
        "\n",
        "        # 6. Theories\n",
        "        theories_df = pd.DataFrame(self.applicable_theories) if self.applicable_theories else pd.DataFrame()\n",
        "\n",
        "        # 7. Interrelationships\n",
        "        interrel_data = []\n",
        "        for (c1, c2), rel_data in self.interrelationships.items():\n",
        "            summary = rel_data['summary'] if isinstance(rel_data, dict) else rel_data\n",
        "            interrel_data.append({\n",
        "                'Concept 1': c1,\n",
        "                'Concept 2': c2,\n",
        "                'Relationship': summary\n",
        "            })\n",
        "        interrel_df = pd.DataFrame(interrel_data) if interrel_data else pd.DataFrame()\n",
        "\n",
        "        # Export Excel\n",
        "        filename = 'ACADEMIAOS_IMPROVED_RESULTS.xlsx'\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            codes_df.to_excel(writer, sheet_name='1_Codes_Consolidated', index=False)\n",
        "\n",
        "            if not mapping_df.empty:\n",
        "                mapping_df.to_excel(writer, sheet_name='1b_Consolidation_Mapping', index=False)\n",
        "\n",
        "            if not freq_df.empty:\n",
        "                freq_df.to_excel(writer, sheet_name='1c_Code_Frequency', index=False)\n",
        "\n",
        "            if not themes_df.empty:\n",
        "                themes_df.to_excel(writer, sheet_name='2_Themes', index=False)\n",
        "\n",
        "            if not dims_df.empty:\n",
        "                dims_df.to_excel(writer, sheet_name='3_Dimensions', index=False)\n",
        "\n",
        "            if not theories_df.empty:\n",
        "                theories_df.to_excel(writer, sheet_name='4_Theories', index=False)\n",
        "\n",
        "            if not interrel_df.empty:\n",
        "                interrel_df.to_excel(writer, sheet_name='5_Interrelationships', index=False)\n",
        "\n",
        "        print(f\"‚úì Excel: {filename}\")\n",
        "        files.download(filename)\n",
        "\n",
        "        # ---- Evidence chunks ----\n",
        "        evidence_file = 'EVIDENCE_CHUNKS_TUPLES.txt'\n",
        "        with open(evidence_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\" * 80 + \"\\n\")\n",
        "            f.write(\"EVIDENCE CHUNKS POUR CHAQUE RELATION\\n\")\n",
        "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "            for i, ((c1, c2), rel_data) in enumerate(self.interrelationships.items(), 1):\n",
        "                summary = rel_data['summary'] if isinstance(rel_data, dict) else rel_data\n",
        "                chunks = rel_data.get('evidence_chunks', []) if isinstance(rel_data, dict) else []\n",
        "\n",
        "                f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
        "                f.write(f\"RELATION #{i}\\n\")\n",
        "                f.write(\"=\" * 80 + \"\\n\")\n",
        "                f.write(f\"Th√®me 1: {c1}\\n\")\n",
        "                f.write(f\"Th√®me 2: {c2}\\n\")\n",
        "                f.write(f\"\\nRelation: {summary}\\n\")\n",
        "                f.write(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "                f.write(\"PASSAGES SOURCES:\\n\" + \"-\" * 80 + \"\\n\\n\")\n",
        "\n",
        "                if chunks:\n",
        "                    for j, chunk in enumerate(chunks, 1):\n",
        "                        f.write(f\"[CHUNK {j}/4]\\n\")\n",
        "                        f.write(f\"Source: {chunk['source']}\\n\")\n",
        "                        f.write(f\"Score: {chunk['similarity']:.4f}\\n\")\n",
        "                        f.write(f\"\\n{chunk['text']}\\n\")\n",
        "                        f.write(\"\\n\" + \".\" * 40 + \"\\n\\n\")\n",
        "\n",
        "        print(f\"‚úì Evidence: {evidence_file}\")\n",
        "        files.download(evidence_file)\n",
        "\n",
        "        # ---- Mod√®les th√©oriques ----\n",
        "        for i, model in enumerate(theory_results['models'], 1):\n",
        "            model_file = f'MODELE_ITERATION_{i}.txt'\n",
        "            with open(model_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(f\"MOD√àLE TH√âORIQUE - IT√âRATION {i}\\n\")\n",
        "                f.write(\"=\"*70 + \"\\n\\n\")\n",
        "                f.write(model)\n",
        "\n",
        "                if i <= len(theory_results['critiques']):\n",
        "                    f.write(\"\\n\\n\" + \"=\"*70 + \"\\n\")\n",
        "                    f.write(\"CRITIQUE\\n\")\n",
        "                    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "                    f.write(theory_results['critiques'][i-1])\n",
        "\n",
        "            print(f\"‚úì Mod√®le {i}: {model_file}\")\n",
        "            files.download(model_file)\n",
        "\n",
        "        # ---- Diagramme Mermaid ----\n",
        "        if theory_results.get('mermaid'):\n",
        "            mermaid_file = 'DIAGRAM_MERMAID.mmd'\n",
        "            with open(mermaid_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(theory_results['mermaid'])\n",
        "            print(f\"‚úì Diagramme: {mermaid_file}\")\n",
        "            files.download(mermaid_file)\n",
        "\n",
        "        # ---- üÜï Statistiques r√©capitulatives ----\n",
        "        stats_file = 'STATISTIQUES_ANALYSIS.txt'\n",
        "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\" * 80 + \"\\n\")\n",
        "            f.write(\"STATISTIQUES R√âCAPITULATIVES DE L'ANALYSE\\n\")\n",
        "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
        "\n",
        "            f.write(\"PHASE 1 - EXTRACTION\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "            f.write(f\"Codes bruts extraits: {len(self.raw_codes)}\\n\")\n",
        "            f.write(f\"Codes uniques: {len(set(self.raw_codes))}\\n\")\n",
        "            if self.qa_units:\n",
        "                f.write(f\"Unit√©s Q/R trait√©es: {len(self.qa_units)}\\n\")\n",
        "\n",
        "            f.write(\"\\nPHASE 1b - FILTRE DE FR√âQUENCE\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "            f.write(f\"Codes r√©currents identifi√©s: {len(self.recurring_codes)}\\n\")\n",
        "            if self.raw_codes:\n",
        "                reduction_1b = (1 - len(self.recurring_codes)/len(set(self.raw_codes))) * 100\n",
        "                f.write(f\"R√©duction: {reduction_1b:.1f}%\\n\")\n",
        "\n",
        "            f.write(\"\\nPHASE 1c - CONSOLIDATION\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "            f.write(f\"Codes consolid√©s finaux: {len(self.first_order_codes)}\\n\")\n",
        "            if self.recurring_codes:\n",
        "                reduction_1c = (1 - len(self.first_order_codes)/len(self.recurring_codes)) * 100\n",
        "                f.write(f\"R√©duction: {reduction_1c:.1f}%\\n\")\n",
        "\n",
        "            f.write(\"\\nPHASE 2 - SECOND-ORDER CODING\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "            f.write(f\"Th√®mes cr√©√©s: {len(self.second_order_themes)}\\n\")\n",
        "\n",
        "            f.write(\"\\nPHASE 3 - AGGREGATE DIMENSIONS\\n\")\n",
        "            f.write(\"-\" * 80 + \"\\n\")\n",
        "            f.write(f\"Dimensions agr√©g√©es: {len(self.aggregate_dimensions)}\\n\")\n",
        "\n",
        "            f.write(\"\\nR√âSUM√â GLOBAL\\n\")\n",
        "            f.write(\"=\" * 80 + \"\\n\")\n",
        "            f.write(f\"Codes bruts ‚Üí Consolid√©s: {len(set(self.raw_codes))} ‚Üí {len(self.first_order_codes)}\\n\")\n",
        "            if self.raw_codes:\n",
        "                reduction_total = (1 - len(self.first_order_codes)/len(set(self.raw_codes))) * 100\n",
        "                f.write(f\"R√©duction totale: {reduction_total:.1f}%\\n\")\n",
        "\n",
        "        print(f\"‚úì Statistiques: {stats_file}\")\n",
        "        files.download(stats_file)\n",
        "\n",
        "        # ---- üÜï Export cache embeddings (optionnel) ----\n",
        "        if os.path.exists(self.embeddings_cache_file):\n",
        "            print(\"\\nüíæ Cache embeddings disponible\")\n",
        "            download_cache = input(\"   T√©l√©charger cache embeddings pour r√©utilisation? (o/N): \").strip().lower()\n",
        "\n",
        "            if download_cache == 'o':\n",
        "                # Copier avec nom explicite\n",
        "                cache_export = 'EMBEDDINGS_CACHE.pkl'\n",
        "                import shutil\n",
        "                shutil.copy(self.embeddings_cache_file, cache_export)\n",
        "\n",
        "                file_size = os.path.getsize(cache_export) / 1024\n",
        "                print(f\"‚úì Cache embeddings: {cache_export} ({file_size:.1f} KB)\")\n",
        "                print(\"  (Placer ce fichier dans /content/ pour r√©utilisation)\")\n",
        "                files.download(cache_export)\n",
        "\n",
        "        print_header(\"‚úÖ EXPORT TERMIN√â\", 1)\n",
        "\n",
        "# ============================================================================\n",
        "# EX√âCUTION PRINCIPALE - VERSION AM√âLIOR√âE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print_header(\"üìÇ SOURCE DES FICHIERS\", 1)\n",
        "    print(\"\\n1. Charger depuis Google Drive\")\n",
        "    print(\"2. Upload direct\")\n",
        "\n",
        "    source_choice = input(\"\\nChoix (1 ou 2): \").strip()\n",
        "\n",
        "    if source_choice == \"1\":\n",
        "        print_header(\"üîå MONTAGE GOOGLE DRIVE\", 1)\n",
        "        try:\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "\n",
        "            print_header(\"üìÇ CONFIGURATION\", 1)\n",
        "            default_path = \"/content/drive/MyDrive/Amsterdam2026/entretienpourLLM\"\n",
        "            print(f\"\\nChemin par d√©faut: {default_path}\")\n",
        "            use_default = input(\"\\nUtiliser ce chemin? (o/n): \").strip().lower()\n",
        "\n",
        "            if use_default == 'o':\n",
        "                FOLDER_PATH = default_path\n",
        "            else:\n",
        "                FOLDER_PATH = input(\"\\nChemin complet: \").strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚úó Erreur Drive: {e}\")\n",
        "            FOLDER_PATH = None\n",
        "    else:\n",
        "        print_header(\"üì§ UPLOAD DES FICHIERS\", 1)\n",
        "        print(\"\\nUploadez fichiers d'entretien (.docx, .pdf, .txt)\\n\")\n",
        "\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            FOLDER_PATH = None\n",
        "        else:\n",
        "            import os, shutil\n",
        "            FOLDER_PATH = \"/content/uploaded_interviews\"\n",
        "            os.makedirs(FOLDER_PATH, exist_ok=True)\n",
        "\n",
        "            for filename in uploaded.keys():\n",
        "                shutil.move(f\"/content/{filename}\", f\"{FOLDER_PATH}/{filename}\")\n",
        "\n",
        "            print(f\"\\n‚úì {len(uploaded)} fichier(s) upload√©(s)\")\n",
        "\n",
        "    print_header(\"‚ùì QUESTION DE RECHERCHE\", 1)\n",
        "    QUESTION = input(\"\\nVotre question:\\n> \").strip()\n",
        "\n",
        "    if not QUESTION:\n",
        "        QUESTION = \"Comment les √©tudiants utilisent-ils et per√ßoivent-ils ChatGPT ?\"\n",
        "        print(f\"\\nQuestion par d√©faut: {QUESTION}\")\n",
        "\n",
        "    # üÜï Option embeddings\n",
        "    print_header(\"üî¢ CONFIGURATION EMBEDDINGS\", 1)\n",
        "    print(\"\\nLes embeddings (n√©cessaires pour RAG) peuvent √™tre:\")\n",
        "    print(\"1. Charg√©s depuis cache si disponible (rapide)\")\n",
        "    print(\"2. R√©g√©n√©r√©s (2-5 min, utile si documents modifi√©s)\")\n",
        "\n",
        "    force_regen = input(\"\\nForcer r√©g√©n√©ration embeddings? (o/N): \").strip().lower()\n",
        "    FORCE_EMBEDDINGS = (force_regen == 'o')\n",
        "\n",
        "    if FORCE_EMBEDDINGS:\n",
        "        print(\"‚úì Embeddings seront r√©g√©n√©r√©s\")\n",
        "        # Supprimer cache existant\n",
        "        cache_file = '/content/embeddings_cache.pkl'\n",
        "        if os.path.exists(cache_file):\n",
        "            os.remove(cache_file)\n",
        "            print(\"  (Cache existant supprim√©)\")\n",
        "    else:\n",
        "        print(\"‚úì Cache embeddings sera utilis√© si disponible\")\n",
        "\n",
        "    if FOLDER_PATH is None:\n",
        "        print(\"\\n‚úó ERREUR: Aucun dossier source\")\n",
        "    else:\n",
        "        # üÜï OPTION: Limiter nombre d'entretiens pour test rapide\n",
        "        print_header(\"üìä NOMBRE D'ENTRETIENS √Ä ANALYSER\", 1)\n",
        "        print(\"\\nPour tester rapidement, vous pouvez limiter le nombre d'entretiens.\")\n",
        "        print(\"(Recommand√©: 3-5 pour test, 'tous' pour analyse finale)\")\n",
        "\n",
        "        nb_docs = input(\"\\nNombre d'entretiens √† analyser (ou 'tous'): \").strip().lower()\n",
        "\n",
        "        if nb_docs == '' or nb_docs == 'tous' or nb_docs == 'all':\n",
        "            MAX_DOCUMENTS = None\n",
        "            print(\"‚úì Tous les entretiens seront analys√©s\")\n",
        "        else:\n",
        "            try:\n",
        "                MAX_DOCUMENTS = int(nb_docs)\n",
        "                print(f\"‚úì Limite: {MAX_DOCUMENTS} premiers entretiens\")\n",
        "            except:\n",
        "                MAX_DOCUMENTS = 3\n",
        "                print(f\"‚ö†Ô∏è  Valeur invalide, limite √† {MAX_DOCUMENTS} entretiens\")\n",
        "\n",
        "        print_header(\"üìã R√âCAPITULATIF\", 1)\n",
        "        print(f\"Dossier: {FOLDER_PATH}\")\n",
        "        print(f\"Question: {QUESTION}\")\n",
        "        if MAX_DOCUMENTS:\n",
        "            print(f\"Limite: {MAX_DOCUMENTS} entretiens\")\n",
        "        else:\n",
        "            print(\"Limite: Aucune (tous les entretiens)\")\n",
        "\n",
        "        wait_for_user(\"\\n‚è∏  ENTR√âE pour commencer...\")\n",
        "\n",
        "        # Charger tous les documents\n",
        "        all_documents = load_documents_from_folder(FOLDER_PATH)\n",
        "\n",
        "        # üÜï Limiter nombre de documents si demand√©\n",
        "        if MAX_DOCUMENTS and len(all_documents) > MAX_DOCUMENTS:\n",
        "            doc_names = list(all_documents.keys())[:MAX_DOCUMENTS]\n",
        "            documents = {name: all_documents[name] for name in doc_names}\n",
        "            print(f\"\\n‚úì Analyse limit√©e √† {len(documents)} entretiens (sur {len(all_documents)} disponibles)\")\n",
        "            wait_for_user(\"‚è∏  ENTR√âE pour continuer...\")\n",
        "        else:\n",
        "            documents = all_documents\n",
        "\n",
        "        if not documents:\n",
        "            print(\"\\n‚úó Aucun document\")\n",
        "        else:\n",
        "            wait_for_user(f\"\\n‚è∏  {len(documents)} documents. ENTR√âE pour analyse...\")\n",
        "\n",
        "            analyzer = AcademiaOSGioiaAnalyzer()\n",
        "\n",
        "            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "            # üÜï WORKFLOW AM√âLIOR√â EN 3 PASSES\n",
        "            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
        "\n",
        "            # PASSE 1a: Extraction par unit√© Q/R\n",
        "            raw_codes = analyzer.first_order_coding(documents, QUESTION)\n",
        "\n",
        "            if raw_codes:\n",
        "                # PASSE 1b: Filtre de fr√©quence\n",
        "                # Adaptation automatique du seuil selon taille corpus\n",
        "                n_docs = len(documents)\n",
        "\n",
        "                if n_docs <= 3:\n",
        "                    # Tr√®s petit corpus : pas de filtre (garde tous les codes)\n",
        "                    min_occ = 1\n",
        "                    print(f\"\\n‚ö†Ô∏è  Corpus petit ({n_docs} entretiens) ‚Üí Seuil minimal = 1\")\n",
        "                    print(\"   (Tous les codes seront gard√©s pour la consolidation)\")\n",
        "                elif n_docs <= 10:\n",
        "                    # Petit/moyen corpus : filtre l√©ger\n",
        "                    min_occ = 2\n",
        "                    print(f\"\\n‚úì Corpus moyen ({n_docs} entretiens) ‚Üí Seuil = 2 occurrences\")\n",
        "                else:\n",
        "                    # Grand corpus : filtre standard\n",
        "                    min_occ = 2\n",
        "                    print(f\"\\n‚úì Grand corpus ({n_docs} entretiens) ‚Üí Seuil = 2 occurrences\")\n",
        "\n",
        "                recurring_codes = analyzer.filter_by_frequency(raw_codes, min_occurrences=min_occ)\n",
        "\n",
        "                # Protection : si aucun code r√©current, garder tous les codes bruts uniques\n",
        "                if not recurring_codes:\n",
        "                    print(\"\\n‚ö†Ô∏è  Aucun code r√©current d√©tect√©\")\n",
        "                    print(\"   ‚Üí Passage direct √† la consolidation avec tous les codes uniques\")\n",
        "                    recurring_codes = list(set(raw_codes))\n",
        "                    print(f\"   ‚Üí {len(recurring_codes)} codes uniques seront consolid√©s\")\n",
        "\n",
        "                if recurring_codes:\n",
        "                    # PASSE 1c: Consolidation conceptuelle\n",
        "                    consolidated_codes = analyzer.consolidate_codes(recurring_codes)\n",
        "\n",
        "                    if consolidated_codes:\n",
        "                        # PASSE 2: Second-order coding\n",
        "                        second = analyzer.second_order_coding()\n",
        "\n",
        "                        if second:\n",
        "                            # PASSE 3: Aggregate dimensions\n",
        "                            dims = analyzer.aggregate_dimensions_coding()\n",
        "\n",
        "                            if dims:\n",
        "                                # PASSES 4a-e: D√©veloppement th√©orique\n",
        "                                theories = analyzer.brainstorm_theories()\n",
        "                                tuples = analyzer.develop_concept_tuples()\n",
        "\n",
        "                                if tuples:\n",
        "                                    interrel = analyzer.explore_interrelationships()\n",
        "\n",
        "                                    theory_results = analyzer.develop_theory_with_iterations(\n",
        "                                        QUESTION,\n",
        "                                        max_iterations=2\n",
        "                                    )\n",
        "\n",
        "                                    analyzer.export_results(theory_results)\n",
        "\n",
        "                                    print_header(\"üéâ ANALYSE TERMIN√âE\", 1)\n",
        "                                    print(\"\\nTous les fichiers ont √©t√© g√©n√©r√©s.\")\n",
        "                                    print(\"\\nFichiers export√©s:\")\n",
        "                                    print(\"  ‚Ä¢ ACADEMIAOS_IMPROVED_RESULTS.xlsx\")\n",
        "                                    print(\"  ‚Ä¢ EVIDENCE_CHUNKS_TUPLES.txt\")\n",
        "                                    print(\"  ‚Ä¢ MODELE_ITERATION_1.txt\")\n",
        "                                    print(\"  ‚Ä¢ MODELE_ITERATION_2.txt\")\n",
        "                                    print(\"  ‚Ä¢ DIAGRAM_MERMAID.mmd\")\n",
        "                                    print(\"  ‚Ä¢ STATISTIQUES_ANALYSIS.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oPQyFQmgJsTz",
        "outputId": "c3733efb-8e39-40ce-bc4e-abf826e7ca49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/155.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.1/155.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Configuration OK\n",
            "  - Mod√®le LLM: gemini-2.0-flash\n",
            "  - Mod√®le Embeddings: embedding-001\n",
            "\n",
            "================================================================================\n",
            "                             üìÇ SOURCE DES FICHIERS                              \n",
            "================================================================================\n",
            "\n",
            "1. Charger depuis Google Drive\n",
            "2. Upload direct\n",
            "\n",
            "Choix (1 ou 2): 1\n",
            "\n",
            "================================================================================\n",
            "                             üîå MONTAGE GOOGLE DRIVE                             \n",
            "================================================================================\n",
            "Mounted at /content/drive\n",
            "\n",
            "================================================================================\n",
            "                                üìÇ CONFIGURATION                                 \n",
            "================================================================================\n",
            "\n",
            "Chemin par d√©faut: /content/drive/MyDrive/Amsterdam2026/entretienpourLLM\n",
            "\n",
            "Utiliser ce chemin? (o/n): o\n",
            "\n",
            "================================================================================\n",
            "                            ‚ùì QUESTION DE RECHERCHE                             \n",
            "================================================================================\n",
            "\n",
            "Votre question:\n",
            "> L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n√©ratives par les √©tudiants se structurent selon deux configurations distinctes. La premi√®re configuration correspond √† des usages qui prolongent des pratiques scolaires classiques (quiz, organisation de notes, corrections) sans modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. La seconde configuration concerne des √©tudiants qui se livrent intimement √† ces machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, demander des conseils personnalis√©s, ou co-produire des contenus en interaction √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans friction sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'exposer ses limites), mais elle g√©n√®re √©galement une hybridation √©tudiant-machine qui pose la question de la tra√ßabilit√© du raisonnement et de la capacit√© √† rendre compte de son travail intellectuel. Comment ces deux configurations se manifestent concr√®tement dans les pratiques des √©tudiants. Qui adopte l'une ou l'autre configuration, et pourquoi ? Quels sont les gains et les co√ªts per√ßus pour chaque configuration ? Comment les √©tudiants qui adoptent l'usage intime d√©finissent-ils et maintiennent-ils (ou non) une ¬´ bonne distance ¬ª avec ces outils ? Et finalement, ChatGPT constitue-t-il une aide ou une entrave √† l'exercice du m√©tier d'√©tudiant ?\n",
            "\n",
            "================================================================================\n",
            "                           üî¢ CONFIGURATION EMBEDDINGS                           \n",
            "================================================================================\n",
            "\n",
            "Les embeddings (n√©cessaires pour RAG) peuvent √™tre:\n",
            "1. Charg√©s depuis cache si disponible (rapide)\n",
            "2. R√©g√©n√©r√©s (2-5 min, utile si documents modifi√©s)\n",
            "\n",
            "Forcer r√©g√©n√©ration embeddings? (o/N): o\n",
            "‚úì Embeddings seront r√©g√©n√©r√©s\n",
            "\n",
            "================================================================================\n",
            "                        üìä NOMBRE D'ENTRETIENS √Ä ANALYSER                        \n",
            "================================================================================\n",
            "\n",
            "Pour tester rapidement, vous pouvez limiter le nombre d'entretiens.\n",
            "(Recommand√©: 3-5 pour test, 'tous' pour analyse finale)\n",
            "\n",
            "Nombre d'entretiens √† analyser (ou 'tous'): 2\n",
            "‚úì Limite: 2 premiers entretiens\n",
            "\n",
            "================================================================================\n",
            "                                üìã R√âCAPITULATIF                                 \n",
            "================================================================================\n",
            "Dossier: /content/drive/MyDrive/Amsterdam2026/entretienpourLLM\n",
            "Question: L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n√©ratives par les √©tudiants se structurent selon deux configurations distinctes. La premi√®re configuration correspond √† des usages qui prolongent des pratiques scolaires classiques (quiz, organisation de notes, corrections) sans modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. La seconde configuration concerne des √©tudiants qui se livrent intimement √† ces machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, demander des conseils personnalis√©s, ou co-produire des contenus en interaction √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans friction sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'exposer ses limites), mais elle g√©n√®re √©galement une hybridation √©tudiant-machine qui pose la question de la tra√ßabilit√© du raisonnement et de la capacit√© √† rendre compte de son travail intellectuel. Comment ces deux configurations se manifestent concr√®tement dans les pratiques des √©tudiants. Qui adopte l'une ou l'autre configuration, et pourquoi ? Quels sont les gains et les co√ªts per√ßus pour chaque configuration ? Comment les √©tudiants qui adoptent l'usage intime d√©finissent-ils et maintiennent-ils (ou non) une ¬´ bonne distance ¬ª avec ces outils ? Et finalement, ChatGPT constitue-t-il une aide ou une entrave √† l'exercice du m√©tier d'√©tudiant ?\n",
            "Limite: 2 entretiens\n",
            "\n",
            "\n",
            "‚è∏  ENTR√âE pour commencer...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                           üìÅ CHARGEMENT DES DOCUMENTS                           \n",
            "================================================================================\n",
            "Dossier: /content/drive/MyDrive/Amsterdam2026/entretienpourLLM\n",
            "--------------------------------------------------------------------------------\n",
            "  üìÑ Template Contexte et retranscription Ainoa Le Mouel.pdf... ‚úì 72,360 caract√®res\n",
            "  üìÑ Ait Ali Wassil.docx... ‚úì 38,266 caract√®res\n",
            "  üìÑ entretien gpt.pdf... ‚úì 45,338 caract√®res\n",
            "  üìÑ restrancription + eÃÅleÃÅments de contexte  bettioui melina .pdf... ‚úì 53,710 caract√®res\n",
            "  üìÑ Retranscription entretien JeÃÅreÃÅmy.docx.pdf... ‚úì 108,644 caract√®res\n",
            "  üìÑ Retranscription entretien Liam Cintract Camille pdf.pdf... ‚úì 75,856 caract√®res\n",
            "  üìÑ Edwin Haguy Amor Retranscription+ contexte+ point fort.pdf... ‚úì 48,541 caract√®res\n",
            "  üìÑ Retranscription et prompt  Gemini.docx... ‚úì 60,045 caract√®res\n",
            "  üìÑ Entretien retranscrit Eloise Foussard Lehnertz.docx... ‚úì 154,917 caract√®res\n",
            "  üìÑ Retranscription de l_entretien sur chatgpt_Gabriel Maugis.pdf... ‚úì 142,300 caract√®res\n",
            "  üìÑ retranscription entretien.pdf... ‚úì 40,614 caract√®res\n",
            "  üìÑ retranscription numeÃÅrique  - copie.pdf... ‚úì 105,710 caract√®res\n",
            "  üìÑ Entretien Cassandra.docx... ‚úì 93,025 caract√®res\n",
            "  üìÑ Retranscription entretien Besnard Margaux.docx.pdf... ‚úì 96,117 caract√®res\n",
            "  üìÑ Entretien Marszalek Stella  (1).pdf... ‚úì 98,085 caract√®res\n",
            "  üìÑ Entretien socio du numeÃÅrique .pdf... ‚úì 72,382 caract√®res\n",
            "  üìÑ Entretien Ethan IA (pdf) .pdf... ‚úì 95,646 caract√®res\n",
            "  üìÑ Rendu Final entretien Ilana (2).pdf... ‚úì 194,403 caract√®res\n",
            "  üìÑ contexte-prompt-retranscription Lucia Monteiro.pdf... ‚úì 42,331 caract√®res\n",
            "  üìÑ Retranscription entretien Adja (Word).docx... ‚úì 177,940 caract√®res\n",
            "  üìÑ Thomas PARIS Retranscription Entretien v2.pdf... ‚úì 77,316 caract√®res\n",
            "  üìÑ Retranscription jade pouilly.pdf... ‚úì 50,988 caract√®res\n",
            "  üìÑ Retranscription Lisa.pdf... ‚úì 71,361 caract√®res\n",
            "  üìÑ Retranscription Entretien socio numeÃÅrique.docx.pdf... ‚úì 87,157 caract√®res\n",
            "  üìÑ Retranscription Entretien Tina.pdf... ‚úì 69,066 caract√®res\n",
            "  üìÑ RETRANSCRIPTION VIDAL.pdf... ‚úì 115,716 caract√®res\n",
            "  üìÑ Rendu entretien-VithusiKALIRASA.pdf... ‚úì 85,008 caract√®res\n",
            "  üìÑ Assia Belarbi Entretient.docx... ‚úì 39,414 caract√®res\n",
            "  üìÑ Retranscription Sarah AGUIAR.pdf... ‚úì 93,274 caract√®res\n",
            "  üìÑ Retranscription entretien.docx... ‚úì 77,381 caract√®res\n",
            "  üìÑ Retranscription entretien sociologie du numeÃÅrique .pdf... ‚úì 59,579 caract√®res\n",
            "  üìÑ Retranscription entretien sociologie du num Anis BEN HAMOUDA.pdf... ‚úì 70,495 caract√®res\n",
            "  üìÑ Entretien retranscription CARRETO Rouann.pdf... ‚úì 131,454 caract√®res\n",
            "  üìÑ Retranscription Chelha Younes V1.docx... ‚úì 73,359 caract√®res\n",
            "  üìÑ Retranscription entretien Sarah.pdf... ‚úì 93,350 caract√®res\n",
            "  üìÑ Retranscription Entretien Charbel.pdf... ‚úì 60,800 caract√®res\n",
            "  üìÑ RETRANSCRIPTION DELOUMEAUX MARINE.pdf... ‚úì 90,235 caract√®res\n",
            "  üìÑ Retranscription entretien IA Adame DIALLO.pdf... ‚úì 25,290 caract√®res\n",
            "  üìÑ Retranscription_ entretien_ socionum_ Ergun Fatma L3  (1) (1) (1).pdf... ‚úì 82,004 caract√®res\n",
            "  üìÑ retranscription entretien_GARCIA_Elise.pdf... ‚úì 70,287 caract√®res\n",
            "  üìÑ Retranscription de l_entretien (2).pdf... ‚úì 78,673 caract√®res\n",
            "  üìÑ entretien Lucas.pdf... ‚úì 40,827 caract√®res\n",
            "  üìÑ Retranscription sociologie du numeÃÅrique LALLEMENT Quentin (1).pdf... ‚úì 137,816 caract√®res\n",
            "  üìÑ Retranscription - LOURME Mattea.pdf... ‚úì 76,610 caract√®res\n",
            "  üìÑ entretient et profil.pdf.pdf... ‚úì 70,845 caract√®res\n",
            "  üìÑ Entretien_MAROU-SERPETTE Lisa.pdf... ‚úì 126,015 caract√®res\n",
            "  üìÑ Entretien socio .pdf... ‚úì 142,589 caract√®res\n",
            "  üìÑ retranscription MIGNAN Lisa.docx... ‚úì 89,734 caract√®res\n",
            "  üìÑ Entretien numeÃÅrique.pdf... ‚úì 40,912 caract√®res\n",
            "  üìÑ Retranscription .pdf... ‚úì 94,725 caract√®res\n",
            "  üìÑ Transcription d_entretien - Vedha Prakash (1).pdf... ‚úì 116,065 caract√®res\n",
            "  üìÑ Entretien Ecrit RIBOT Valentin.pdf... ‚úì 132,991 caract√®res\n",
            "  üìÑ Retranscription entretien L3 socionum.pdf... ‚úì 66,996 caract√®res\n",
            "  üìÑ Entretien_SIVASAMBOO_Gobika.pdf... ‚úì 86,708 caract√®res\n",
            "  üìÑ Retranscription Entretien TEIXEIRA CloeÃÅ.pdf... ‚úì 156,298 caract√®res\n",
            "  üìÑ Retranscription Entretien CHATGPT.docx... ‚úì 130,498 caract√®res\n",
            "  üìÑ RETRANSCRIPTION ENTRETIEN ELISE.pdf... ‚úì 69,131 caract√®res\n",
            "--------------------------------------------------------------------------------\n",
            "‚úì 57 documents charg√©s\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìã APER√áU DES DOCUMENTS\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "1. Template Contexte et retranscription Ainoa Le Mouel.pdf (72,360 chars)\n",
            "   Aper√ßu:    Retranscription entretien Ainoa      Etablissement : Universit√© Gustave Eiffel    Dur√©e : 1h05   Date de l‚Äôentretien : 6 novembre 2025     CONTEXTE  :    Au sein de l'universit√© Gustave Eiffel, du ...\n",
            "\n",
            "2. Ait Ali Wassil.docx (38,266 chars)\n",
            "   Aper√ßu: Ait Ali Wassil         contexte  Le contexte de l‚Äôentretien m√©rite d‚Äô√™tre pr√©cis√©. Nous avions initialement des difficult√©s √† trouver un cr√©neau et surtout un lieu calme pour nous voir, en raison de n...\n",
            "\n",
            "3. entretien gpt.pdf (45,338 chars)\n",
            "   Aper√ßu: üë®üéì Synth√®se Analytique de l'Entretien avec Lucas (Lucas en L2 G√©ographie)INFORMATIONS DE BASE R√âSUM√â DES POINTS FORTS DE L'ENTRETIENA. Rapport √† l'outil (ChatGPT/IA g√©n√©rative)‚Ä¢‚Ä®Fr√©quence et contextes...\n",
            "\n",
            "4. restrancription + eÃÅleÃÅments de contexte  bettioui melina .pdf (53,710 chars)\n",
            "   Aper√ßu: ENTRETIEN AVEC NADHIR:- Etablissement : Universit√© Gustave Eiffel  - Dur√©e: 1 heure.  -Date de l‚Äôentretien : 10 novembre 2025  CONTEXTE: √Ä Champs sur Marne, il est 12h et je suis assise dans ma voitur...\n",
            "\n",
            "5. Retranscription entretien JeÃÅreÃÅmy.docx.pdf (108,644 chars)\n",
            "   Aper√ßu: Birsinger   Charlotte   L3   Sociologie       Retranscription   entretien   J√©r√©my     Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   1h07   Date   de   l‚Äôentretien   :   04/11/2025   ...\n",
            "\n",
            "6. Retranscription entretien Liam Cintract Camille pdf.pdf (75,856 chars)\n",
            "   Aper√ßu: Cintract Camille  L3 RETRANSCRIPTION DE L‚ÄôENTRETIEN DE LIAM √âtablissement : Universit√© Gustave Eiffel  Dur√©e : 1h14 Date de l‚Äôentretien : 5 novembre 2025 CONTEXTE  √âtudiant en deuxi√®me ann√©e de Licenc...\n",
            "\n",
            "7. Edwin Haguy Amor Retranscription+ contexte+ point fort.pdf (48,541 chars)\n",
            "   Aper√ßu:  Edwin   Haguy Amor      Contexte :   L‚Äôentretien a eu lieu chez moi, √† Livry -Gargan, avec quelqu‚Äôun que je connais quand m√™me  depuis longtemps, m√™me si on ne se voit pas tr√®s souvent. Il est en l2 ...\n",
            "\n",
            "8. Retranscription et prompt  Gemini.docx (60,045 chars)\n",
            "   Aper√ßu: Retranscription entretien Jamel  Etablissement : Universit√© Gustave Eiffel¬† Dur√©e: 52 min Date de l‚Äôentretien : 8 octobre 2025¬†  Contexte :   A 20 ans, Jamel est √©tudiant en troisi√®me ann√©e de sociolo...\n",
            "\n",
            "9. Entretien retranscrit Eloise Foussard Lehnertz.docx (154,917 chars)\n",
            "   Aper√ßu: Retranscription brute Foussard-Lehnertz  Eloise L3 Sociologie    Retranscription entretien Louise   Etablissement: Universit√© Gustave Eiffel  Dur√©e: 2h21 Date de l‚Äôentretien: 09/11/2025  CONTEXTE   L‚Äô...\n",
            "\n",
            "10. Retranscription de l_entretien sur chatgpt_Gabriel Maugis.pdf (142,300 chars)\n",
            "   Aper√ßu:     Retranscription   entretien   Bilal      Etablissement   :   Universit√©   Gustave   Eiffel    Dur√©e   :   2h09   Date   de   l‚Äôentretien   :   7   novembre   2025        Contexte   C‚Äôest   √†   10h...\n",
            "\n",
            "11. retranscription entretien.pdf (40,614 chars)\n",
            "   Aper√ßu: RETRANSCRIPTION   ENTRETIEN   JADE     Etablissement   :   ASSAS   Paris   2   Dur√©e:   40   minutes     Date   de   l‚Äôentretien   :   6   novembre   2025       INFORMATIONS   DE   BASE   Parcours   e...\n",
            "\n",
            "12. retranscription numeÃÅrique  - copie.pdf (105,710 chars)\n",
            "   Aper√ßu: LAOUBI                                             SOCIO DU LYNA                                             NUM√âRIQUE          RETRANSCRIPTION D‚ÄôENTRETIEN        ‚Äúdes usages des IA g√©n√©ratives par le...\n",
            "\n",
            "13. Entretien Cassandra.docx (93,025 chars)\n",
            "   Aper√ßu: Retranscription Int√©grale Cit√©e Partie 1 : Extraits de \"Enregistrement.m4a\" INTERVIEWER : Alors, bonjour mademoiselle. CASSANDRA : Bonjour. INTERVIEWER : Alors, est-ce que d√©j√† je peux vous enregistre...\n",
            "\n",
            "14. Retranscription entretien Besnard Margaux.docx.pdf (96,117 chars)\n",
            "   Aper√ßu: Retranscription   entretien   Sara     Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   1h15   Date   de   l‚Äôentretien   :   6   novembre   2025     Contexte     Le   jeudi   6   novembr...\n",
            "\n",
            "15. Entretien Marszalek Stella  (1).pdf (98,085 chars)\n",
            "   Aper√ßu: MARSZALEK   Stella   L3   Sociologie     Retranscription   entretien   Ethan     Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   1h23   Date   de   l‚Äôentretien   :   6   Novembre   2025...\n",
            "\n",
            "16. Entretien socio du numeÃÅrique .pdf (72,382 chars)\n",
            "   Aper√ßu: HELLAL MAYSSA Retranscription d‚Äôentretien: ¬´¬†Les usages des IA g√©n√©ratives par les √©tudiants en SHS¬†¬ª  sur 126 √âtablissement:  Universit√© Gustave Eiffel Dur√©e de l‚Äôentretien: 1 heure et 6 minutes Date...\n",
            "\n",
            "17. Entretien Ethan IA (pdf) .pdf (95,646 chars)\n",
            "   Aper√ßu: MELLOUK Lyna  L3 - SHS  Entretien sur les IA g√©n√©ratives.  I-  CONTEXTE.  Un mercredi apr√®s-midi, juste apr√®s les cours, je retrouve Eliot dans les couloirs encore anim√©s du b√¢timent. Nous nous connai...\n",
            "\n",
            "18. Rendu Final entretien Ilana (2).pdf (194,403 chars)\n",
            "   Aper√ßu:   Na√©lya Monrose     Retranscription entretien Ilana   Etablissement : Universit√© Gustave Eiffel    Dur√©e: 2h53   Date de l‚Äôentretien : 4 novembre  2025                                   Contexte     ...\n",
            "\n",
            "19. contexte-prompt-retranscription Lucia Monteiro.pdf (42,331 chars)\n",
            "   Aper√ßu: MONTE IRO PAREDES LUCIA   ETABLISEMENT : Universit√© Gustave Eiffel   Dur√©e de l ‚Äôentretien : 40 minutes   Retranscription de l ‚Äôentretien de R abia.       Contexte entretien :     L'entretien s'est d√©...\n",
            "\n",
            "20. Retranscription entretien Adja (Word).docx (177,940 chars)\n",
            "   Aper√ßu:  Retranscription entretien Adja  √âtablissement : Universit√© Gustave Eiffel  Dur√©e de l‚Äôentretien : 2heures 45 Date de l‚Äôentretien : 7 novembre 2025    Contexte :     En banlieue parisienne, du c√¥t√© de...\n",
            "\n",
            "21. Thomas PARIS Retranscription Entretien v2.pdf (77,316 chars)\n",
            "   Aper√ßu: Retranscription de l‚Äôentretien de Ben.  Thomas PARIS L3 SHS √âtablissement¬†: Universit√© Gustave Eiffel Dur√©e¬†: 1h07 Date de l‚Äôentretien¬†: 07/11/2025 Contexte ¬†: L‚Äôentretien a √©t√© r√©alis√© avec Ben, un j...\n",
            "\n",
            "22. Retranscription jade pouilly.pdf (50,988 chars)\n",
            "   Aper√ßu: RETRANSCRIPTION   Jade Pouilly     [Enqu√™trice]  Ok, avant de commencer, ceci n'est pas une √©valuation. Ta participation est  volontaire. Tu peux passer une question, faire une pause ou arr√™ter √† tout...\n",
            "\n",
            "23. Retranscription Lisa.pdf (71,361 chars)\n",
            "   Aper√ßu:   Diaby     Sembelou     L3   sociologie         ‚óè   √âtablissement :   Universit√©   Gustave   Eiffel     ‚óè   Dur√©e :   1h05   ‚óè   Date   de   l'entretien :   8   novembre   2025     CONTEXTE   :     L...\n",
            "\n",
            "24. Retranscription Entretien socio numeÃÅrique.docx.pdf (87,157 chars)\n",
            "   Aper√ßu: TALL   Calista   Retranscription   entretien   Le√Øla         Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   1h22   Date   de   l‚Äôentretien   :   5   novembre   2025       Contexte   : ...\n",
            "\n",
            "25. Retranscription Entretien Tina.pdf (69,066 chars)\n",
            "   Aper√ßu: VERNHES Ma√´lle L3       Retranscription Entretien Tina   ‚Ä¢ Etablissement :  Universit√© Gustave Eiffel    ‚Ä¢ Dur√©e de l‚Äôentretien : 51min35  ‚Ä¢ Date de l‚Äôentretien :  7 octobre 2025     Mise en contexte ...\n",
            "\n",
            "26. RETRANSCRIPTION VIDAL.pdf (115,716 chars)\n",
            "   Aper√ßu:         VIDAL   Layana                                   RETRANSCRIPTION   ENTRETIEN:     l‚Äôaccomplissement   en   pratique   du   m√©tier   d'√©tudiant   √†   l'√®re   des   IAG                          ...\n",
            "\n",
            "27. Rendu entretien-VithusiKALIRASA.pdf (85,008 chars)\n",
            "   Aper√ßu: 1   KALIRASA   Vithusi   L3 Sociologie   Sociologie du num√©rique     Louise , √©tudiante en troisi√®me ann√©e de socio logie   (Non usag√®re de Chat GPT)   Dur√©e de l‚Äôentretien  : 1h12     Contexte  :  Le...\n",
            "\n",
            "28. Assia Belarbi Entretient.docx (39,414 chars)\n",
            "   Aper√ßu:   CONTEXTE DE L‚ÄôENTRETIEN   L‚Äôentretien a √©t√© r√©alis√© avec un √©tudiant inscrit en licence 2 d‚Äôhistoire √† l‚Äôuniversit√© Gustave Eiffel. L‚Äô√©change s‚Äôinscrit dans un travail universitaire portant sur les ...\n",
            "\n",
            "29. Retranscription Sarah AGUIAR.pdf (93,274 chars)\n",
            "   Aper√ßu: AGUIAR Sarah   Entretien     Etablissement : Universit√© Gu stave Eiffel   Dur√©e : 1h 52min  Date d e l'entretien : 5 novembre 2025    Contexte     Mon enqu√™t√© s'appelle M√©lanie , elle a 21 ans. Ayant ...\n",
            "\n",
            "30. Retranscription entretien.docx (77,381 chars)\n",
            "   Aper√ßu: Retranscription entretien √âtablissement : Universit√© Gustave Eiffel Dur√©e : 1h28 Date de l'entretien : 08/11/2025  INFORMATIONS DE BASE  √Çge : 20 ans  Ann√©e d'√©tudes : 3e ann√©e de licence  Formation a...\n",
            "\n",
            "31. Retranscription entretien sociologie du numeÃÅrique .pdf (59,579 chars)\n",
            "   Aper√ßu: Retranscription entretien  Adam Etablissement : Universit√© Gustave Eiffel` Dur√©e : 1h07 Date de l'entretien : 16 novembre 2025 INFORMATIONS DE BASE ‚Ä¢ Parcours et situation actuelle : ‚Ä¢ √Çge : 20 ans ‚Ä¢ ...\n",
            "\n",
            "32. Retranscription entretien sociologie du num Anis BEN HAMOUDA.pdf (70,495 chars)\n",
            "   Aper√ßu: BEN HAMOUDA Anis Retranscription entretien Harley √âtablissement: Universit√© Gustave Eiffel Dur√©e: 1h25 Date de l‚Äôentretien : Mardi 04 Novembre 2025 INFORMATIONS DE BASE Parcours et situation actuelle ...\n",
            "\n",
            "33. Entretien retranscription CARRETO Rouann.pdf (131,454 chars)\n",
            "   Aper√ßu: CARRETO ROUANN       Page 1 sur 70     -Temps total  : 1h 45 min 56 seconde     INFORMATIONS DE BASE   Cat√©gorie  Information extraite de la transcription  Source  (Transcription)   Parcours et  situa...\n",
            "\n",
            "34. Retranscription Chelha Younes V1.docx (73,359 chars)\n",
            "   Aper√ßu: Retranscription d‚Äôentretien   Enqu√™teur: Younes  Enqu√™t√©: Alex Etablissement : Universit√© Gustave Eiffel¬† Dur√©e: 1h05 Date de l‚Äôentretien : 7 novembre 2025   Introduction de l‚Äôenqu√™t√© / Contexte:  L‚Äôe...\n",
            "\n",
            "35. Retranscription entretien Sarah.pdf (93,350 chars)\n",
            "   Aper√ßu: Retranscription entretien Sarah  Universit√© Gustave EiÔ¨Äel  Dur√©e : 1h54 33 Date de l‚Äôentretien : Le 7 novembre 2025  Contexte  Sarah est une √©tudiante en troisi√®me ann√©e de g√©ographie √† l‚Äôuniversit√© G...\n",
            "\n",
            "36. Retranscription Entretien Charbel.pdf (60,800 chars)\n",
            "   Aper√ßu:   Charbel   DEGUENON       INFORMATIONS   DE   BASE   √âtablissement   :   Universit√©   Gustave   Eiffel   Dur√©e   :   38:41   Date   de   l‚Äôentretien   :   Samedi   08   Novembre   2025   Parcours   e...\n",
            "\n",
            "37. RETRANSCRIPTION DELOUMEAUX MARINE.pdf (90,235 chars)\n",
            "   Aper√ßu: Deloumeaux Marine L3    RETRANSCRIPTION ENTRETIEN JULIETTE  L‚Äôentretien s‚Äôest d√©roul√© un mardi √† 14h dans une salle insonoris√©e de la B iblioth√®que  Universitaire . Mon enqu√™t√©e  est une camarade de l...\n",
            "\n",
            "38. Retranscription entretien IA Adame DIALLO.pdf (25,290 chars)\n",
            "   Aper√ßu: Adame DIALLORetranscription entretien RobinINFORMATIONS DE BASEParcours et situation actuelle :‚Ä¢√Çge : 19 ans ‚Ä¢Ann√©e d'√©tudes : 2e ann√©e (L2) ‚Ä¢Formation actuelle (intitul√© pr√©cis) : Sociologie ‚Ä¢Ancienn...\n",
            "\n",
            "39. Retranscription_ entretien_ socionum_ Ergun Fatma L3  (1) (1) (1).pdf (82,004 chars)\n",
            "   Aper√ßu: Retranscription   entretien   Armin     Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   1h07     Date   de   l‚Äôentretien   :   14   octobre   2025     Contexte     L'entretien   a   √©t√©...\n",
            "\n",
            "40. retranscription entretien_GARCIA_Elise.pdf (70,287 chars)\n",
            "   Aper√ßu: GARCIA Elise L3 SHSENTRETIEN A VEC AnnaEtablissement : Universit√© Gustave EiffelDur√©e : 59min et 28 secDate de l‚Äôentretien : 9 novembre 2025CONTEXTE : Ana a 20 ans et elle est actuellement en 3√®me ann...\n",
            "\n",
            "41. Retranscription de l_entretien (2).pdf (78,673 chars)\n",
            "   Aper√ßu: Retranscription   avec   Mara   Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   47   min   Date   de   l‚Äôentretien   :   Mercredi   29   octobre   2025   Contexte:   L'entretien   s'est...\n",
            "\n",
            "42. entretien Lucas.pdf (40,827 chars)\n",
            "   Aper√ßu: Ange GOHOUROU                                                                                                       Universit√© Gustave Eiffel‚Ä®L3 Sociologie‚Ä®‚Ä®DATE de l‚Äôentretien : 7/11/2025‚Ä®‚Ä®  Enqu√™teu...\n",
            "\n",
            "43. Retranscription sociologie du numeÃÅrique LALLEMENT Quentin (1).pdf (137,816 chars)\n",
            "   Aper√ßu: Sociologie   du   num√©rique                        LALLEMENT   Quentin   Retranscription   entretien   Younes     ‚óè   Etablissement   :   Universit√©   Gustave   Eiffel    ‚óè   Dur√©e:   1h14   ‚óè   Date ...\n",
            "\n",
            "44. Retranscription - LOURME Mattea.pdf (76,610 chars)\n",
            "   Aper√ßu: LOURME Mattea Etablissement : Universit√© Gustave Eiffel Dur√©e de l'entretien : 1h13 Date de l'entretien : 12 novembre 2025 Contexte Dans le cadre de mon TD de sociologie du num√©rique, je devais r√©alis...\n",
            "\n",
            "45. entretient et profil.pdf.pdf (70,845 chars)\n",
            "   Aper√ßu: Th√©ana MAGNI L3 G√©ographie Num√©rique Retranscription entretien L√©o   Etablissement : Universit√© Gustave Eiffel  Dur√©e : 1h09 Date de l‚Äôentretien : 7 novembre 2025   Informations de bases Parcours et s...\n",
            "\n",
            "46. Entretien_MAROU-SERPETTE Lisa.pdf (126,015 chars)\n",
            "   Aper√ßu: MAROU-SERPETTE   Lisa                                 Universit√©   Gustave   Eiffel   Licence   3   en   Sociologie                      05/11/2025         Pr√©sentation   du   d√©but   d‚Äôenqu√™te       ...\n",
            "\n",
            "47. Entretien socio .pdf (142,589 chars)\n",
            "   Aper√ßu: MIALON   Ana√Øs     L3   Histoire         √âtablissement   :   Universit√©   Gustave   Eiffel   Dur√©e   :   1h33   Date   de   l'entretien   :   7   novembre   2025   INFORMATIONS   DE   BASE   Parcours ...\n",
            "\n",
            "48. retranscription MIGNAN Lisa.docx (89,734 chars)\n",
            "   Aper√ßu: RETRANSCRIPTION ENTRETIEN NATHALIE    Etablissement : Universit√© Gustave Eiffel¬† Dur√©e: 1h29 Date de l‚Äôentretien : 3 octobre 2025  J‚Äôai d√©cid√© d‚Äôinterroger une amie √† moi nomm√©e Nathalie. Nous avons c...\n",
            "\n",
            "49. Entretien numeÃÅrique.pdf (40,912 chars)\n",
            "   Aper√ßu: Mostefaoui   Sarah     TD   14-16h       RETRANSCRIPTION   ENTRETIEN   ADAM     Etablissement   :   Universit√©   Gustave   Eiffel     Dur√©e:   58   minutes     Date   de   l‚Äôentretien   :   7   novemb...\n",
            "\n",
            "50. Retranscription .pdf (94,725 chars)\n",
            "   Aper√ßu: Retranscription entretien Nolan    √âtablissement : Universit√© Gustave Eiffel  Dur√©e : 1h10 Date de l‚Äôentretien : 8 novembre 2025   Contexte  Cet entretien s‚Äôest d√©roul√© √† la biblioth√®que universitaire...\n",
            "\n",
            "51. Transcription d_entretien - Vedha Prakash (1).pdf (116,065 chars)\n",
            "   Aper√ßu: Retranscription   entretien   √âtablissement   :   Universit√©   Gustave   Eiffel   √†   la   BU   George   Perec   Dur√©e   :   1h34   Date   de   l'entretien   :   7   novembre   2025   Contexte   Entre...\n",
            "\n",
            "52. Entretien Ecrit RIBOT Valentin.pdf (132,991 chars)\n",
            "   Aper√ßu: Entretien Sociologie du Num√©rique, Valentin RIBOT Universit√© Gustave Eiffel Dur√©e de l‚Äôentretien 1h45min, r√©alis√© le 6/11/2025  L‚Äôentretien s‚Äôest d√©roul√© √† la biblioth√®que Georges Perec de l‚Äôuniversit...\n",
            "\n",
            "53. Retranscription entretien L3 socionum.pdf (66,996 chars)\n",
            "   Aper√ßu: SAM   Myrasy     Entretien   socio   num√©rique     Retranscription   avec   Louis   Etablissement   Universit√©   Gustave   eiffel   Dur√©e   :   1h24   Date   de   l‚Äôentretien   :   Jeudi   6   novembr...\n",
            "\n",
            "54. Entretien_SIVASAMBOO_Gobika.pdf (86,708 chars)\n",
            "   Aper√ßu: SIVASAMBOO  Gobika  L3 Sociologie SOCIOLOGIE DU NUMERIQUE   Retranscription entretien Lina   Etablissement : Universit√© Gustave Eiffel   Dur√©e: 1h26 Date de l‚Äôentretien : 7 novembre 2025   CONTEXTE L‚Äô...\n",
            "\n",
            "55. Retranscription Entretien TEIXEIRA CloeÃÅ.pdf (156,298 chars)\n",
            "   Aper√ßu: TEIXEIRA   Clo√©                                                                                                 Universit√©   Gustave   Eiffel     L3   Sociologie     RETRANSCRIPTION   ENTRETIEN   LUCI...\n",
            "\n",
            "56. Retranscription Entretien CHATGPT.docx (130,498 chars)\n",
            "   Aper√ßu: Entretien en Sociologie du Num√©rique, Vathonne Axel Universit√© Gustave Eiffel                                                                                       Dur√©e de l‚Äôentretien 1h45min, r√©alis...\n",
            "\n",
            "57. RETRANSCRIPTION ENTRETIEN ELISE.pdf (69,131 chars)\n",
            "   Aper√ßu: VELOARISOAStella SociologieduNum√©rique L3-G√©ographie/Soci√©t√©setCulturesNum√©riques RETRANSCRIPTIONENTRETIENELISE √âtablissement:Universit√©GustaveEiffel Dur√©e:1h18 Datedel‚Äôentretien:10Novembre2025 CONTEX...\n",
            "\n",
            "‚úì Analyse limit√©e √† 2 entretiens (sur 57 disponibles)\n",
            "\n",
            "‚è∏  ENTR√âE pour continuer...\n",
            "\n",
            "\n",
            "\n",
            "‚è∏  2 documents. ENTR√âE pour analyse...\n",
            "\n",
            "‚úì Analyzer initialis√© (version am√©lior√©e)\n",
            "\n",
            "================================================================================\n",
            "                    √âTAPE 1a: EXTRACTION CODES PAR UNIT√â Q/R                    \n",
            "================================================================================\n",
            "Objectif: Identifier concepts √©mergents au niveau des R√âPONSES\n",
            "Question de recherche: L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n√©ratives par les √©tudiants se structurent selon deux configurations distinctes. La premi√®re configuration correspond √† des usages qui prolongent des pratiques scolaires classiques (quiz, organisation de notes, corrections) sans modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. La seconde configuration concerne des √©tudiants qui se livrent intimement √† ces machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, demander des conseils personnalis√©s, ou co-produire des contenus en interaction √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans friction sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'exposer ses limites), mais elle g√©n√®re √©galement une hybridation √©tudiant-machine qui pose la question de la tra√ßabilit√© du raisonnement et de la capacit√© √† rendre compte de son travail intellectuel. Comment ces deux configurations se manifestent concr√®tement dans les pratiques des √©tudiants. Qui adopte l'une ou l'autre configuration, et pourquoi ? Quels sont les gains et les co√ªts per√ßus pour chaque configuration ? Comment les √©tudiants qui adoptent l'usage intime d√©finissent-ils et maintiennent-ils (ou non) une ¬´ bonne distance ¬ª avec ces outils ? Et finalement, ChatGPT constitue-t-il une aide ou une entrave √† l'exercice du m√©tier d'√©tudiant ?\n",
            "\n",
            "‚è∏  Appuyez sur ENTR√âE pour commencer l'extraction...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìÑ Document 1/2: Template Contexte et retranscription Ainoa Le Mouel.pdf\n",
            "--------------------------------------------------------------------------------\n",
            "   ‚ö† Aucune structure Q/R d√©tect√©e\n",
            "   ‚Üí Mode chunks classiques (Q/R non d√©tect√©)\n",
            "   ‚Üí 8 chunks\n",
            "\n",
            "   Chunk 1/8... \n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ You are applying first-order coding in the Gioia method tradition.           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ You are analyzing interviews about students' use of ChatGPT.                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   ‚îÇ\n",
            "‚îÇ üéØ CRITICAL: CODE BY RESPONSE UNIT, NOT SENTENCE-BY-SENTENCE                  ‚îÇ\n",
            "‚îÇ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ An informant's COMPLETE RESPONSE to a question = ONE coding unit.            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ WHY:                                                                         ‚îÇ\n",
            "‚îÇ ‚úì A response forms a coherent narrative/explanation                          ‚îÇ\n",
            "‚îÇ ‚úó Sentence-by-sentence coding creat...                                       ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Research Question: L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n ‚îÇ\n",
            "‚îÇ √©ratives par les √©tudiants se structurent selon deux configurations distinct ‚îÇ\n",
            "‚îÇ es. La premi√®re configuration correspond √† des usages qui prolongent des pra ‚îÇ\n",
            "‚îÇ tiques scolaires classiques (quiz, organisation de notes, corrections) sans  ‚îÇ\n",
            "‚îÇ modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. L ‚îÇ\n",
            "‚îÇ a seconde configuration concerne des √©tudiants qui se livrent intimement √† c ‚îÇ\n",
            "‚îÇ es machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, dem ‚îÇ\n",
            "‚îÇ ander des conseils personnalis√©s, ou co-produire des contenus en interaction ‚îÇ\n",
            "‚îÇ  √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans frict ‚îÇ\n",
            "‚îÇ ion sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'expo ‚îÇ\n",
            "‚îÇ ser ses limites), mais elle g√©n√®re √©gale...                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 13 codes\n",
            "\n",
            "   Chunk 2/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 13 codes\n",
            "\n",
            "   Chunk 3/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 13 codes\n",
            "\n",
            "   Chunk 4/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 14 codes\n",
            "\n",
            "   Chunk 5/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 13 codes\n",
            "\n",
            "   Chunk 6/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 15 codes\n",
            "\n",
            "   Chunk 7/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 15 codes\n",
            "\n",
            "   Chunk 8/8... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 10 codes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìÑ Document 2/2: Ait Ali Wassil.docx\n",
            "--------------------------------------------------------------------------------\n",
            "   ‚ö† Aucune structure Q/R d√©tect√©e\n",
            "   ‚Üí Mode chunks classiques (Q/R non d√©tect√©)\n",
            "   ‚Üí 4 chunks\n",
            "\n",
            "   Chunk 1/4... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 10 codes\n",
            "\n",
            "   Chunk 2/4... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 15 codes\n",
            "\n",
            "   Chunk 3/4... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 14 codes\n",
            "\n",
            "   Chunk 4/4... \n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "‚úì 18 codes\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 1a                              \n",
            "================================================================================\n",
            "‚úì TOTAL codes bruts: 163\n",
            "‚úì Codes uniques: 163\n",
            "‚úì Chunks pour RAG: 12\n",
            "\n",
            "üìè Longueur des codes:\n",
            "   Moyenne: 9.3 mots\n",
            "   Min/Max: 5/17 mots\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìä R√âSULTATS: Codes uniques (√©chantillon)\n",
            "--------------------------------------------------------------------------------\n",
            "    1. It√©ration et reformulation des requ√™tes pour obtenir des r√©sultats plus complexes\n",
            "    2. Effort accru de reformulation pour les √©valuations importantes\n",
            "    3. Valorisation de l'efficacit√© de l'IA pour la m√©morisation\n",
            "    4. Interaction avec ChatGPT per√ßue comme purement fonctionnelle\n",
            "    5. Partage de ressources de cours limit√© au sein de la promotion\n",
            "    6. Reconnaissance de l'IA comme outil bas√© sur des donn√©es internet\n",
            "    7. √âquilibre per√ßu entre gain de temps et charge de travail de reformulation\n",
            "    8. Utilisation de ChatGPT pour am√©liorer la formulation de documents professionnels\n",
            "    9. Rejet de ChatGPT pour les math√©matiques\n",
            "   10. IA comme outil pratique pour pallier la procrastination\n",
            "   11. Comparaison favorable de l'ambiance universitaire actuelle\n",
            "   12. Utilisation de l'IA pour la synth√®se de documents en suivant un plan pr√©cis\n",
            "   13. Identification √† un parcours 'classique' malgr√© la r√©orientation\n",
            "   14. M√©fiance envers la fiabilit√© de l'IA dans certains domaines\n",
            "   15. Limitation de l'usage de l'IA pour des conseils psychologiques en raison du manque d'humanit√©\n",
            "   16. Modulation de l'usage de l'IA selon l'enjeu de la t√¢che\n",
            "   17. Refus d'attribuer √† l'IA des r√¥les inappropri√©s (ex: psychologie)\n",
            "   18. Prise de conscience de l'absence de r√©flexion quotidienne sur l'IA\n",
            "   19. Usage de l'IA pour la pr√©paration d'examens\n",
            "   20. Respect des choix individuels concernant l'utilisation de l'IA\n",
            "   21. Adaptation de l'usage de l'IA selon l'importance de l'√©valuation\n",
            "   22. Familiarit√© pragmatique avec l'IA sans attachement √©motionnel\n",
            "   23. Demande de fiches de r√©vision personnalis√©es en fonction du niveau d'√©tude et de l'examen\n",
            "   24. Conscience de l'impact √©cologique de l'utilisation de l'IA\n",
            "   25. Description factuelle du parcours sans d√©tails subjectifs\n",
            "   26. Distinction claire entre usages acceptables et interdits de l'IA\n",
            "   27. Conscience des limites de l'IA en mati√®re de suivi personnalis√©\n",
            "   28. Conscience de l'apprentissage accru en faisant soi-m√™me\n",
            "   29. Utilisation de ChatGPT en dernier recours par manque de temps\n",
            "   30. Recours √† l'IA pour la cr√©ation de fiches de r√©vision √† partir de cours existants\n",
            "\n",
            "‚è∏  √âtape 1a termin√©e. ENTR√âE pour filtre de fr√©quence...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üî¢ G√âN√âRATION EMBEDDINGS POUR RAG\n",
            "--------------------------------------------------------------------------------\n",
            "Chunks √† embedder: 12\n",
            "‚ÑπÔ∏è  Pas de cache embeddings trouv√©\n",
            "\n",
            "üîÑ G√©n√©ration des embeddings (ceci peut prendre 2-5 min)...\n",
            "   (Les embeddings seront sauvegard√©s pour r√©utilisation)\n",
            "\n",
            "‚úì 12 embeddings g√©n√©r√©s en 16s\n",
            "\n",
            "‚úì Embeddings sauvegard√©s: /content/embeddings_cache.pkl\n",
            "  ‚Ä¢ 12 embeddings\n",
            "  ‚Ä¢ Taille fichier: 184.9 KB\n",
            "  ‚Ä¢ Hash documents: dbb41356e93c33c5...\n",
            "\n",
            "‚ö†Ô∏è  Corpus petit (2 entretiens) ‚Üí Seuil minimal = 1\n",
            "   (Tous les codes seront gard√©s pour la consolidation)\n",
            "\n",
            "================================================================================\n",
            "                         √âTAPE 1b: FILTRE DE R√âCURRENCE                         \n",
            "================================================================================\n",
            "Objectif: Identifier les patterns qui apparaissent au moins 1 fois\n",
            "dans diff√©rentes unit√©s (Q/R ou chunks)\n",
            "\n",
            "\n",
            "‚è∏  Appuyez sur ENTR√âE pour lancer le filtrage...\n",
            "\n",
            "üìä R√©sultats du filtrage:\n",
            "  ‚Ä¢ Codes bruts totaux: 163\n",
            "  ‚Ä¢ Codes uniques: 163\n",
            "  ‚Ä¢ Codes r√©currents (‚â•1 unit√©s): 163\n",
            "  ‚Ä¢ Taux de r√©tention: 100.0%\n",
            "\n",
            "üìà Top 15 codes par fr√©quence:\n",
            "   1. It√©ration et reformulation des requ√™tes pour obtenir des r√©sultats plu\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   2. Effort accru de reformulation pour les √©valuations importantes\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   3. Valorisation de l'efficacit√© de l'IA pour la m√©morisation\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   4. Interaction avec ChatGPT per√ßue comme purement fonctionnelle\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   5. Partage de ressources de cours limit√© au sein de la promotion\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   6. Reconnaissance de l'IA comme outil bas√© sur des donn√©es internet\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   7. √âquilibre per√ßu entre gain de temps et charge de travail de reformulat\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   8. Utilisation de ChatGPT pour am√©liorer la formulation de documents prof\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "   9. Rejet de ChatGPT pour les math√©matiques\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  10. IA comme outil pratique pour pallier la procrastination\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  11. Comparaison favorable de l'ambiance universitaire actuelle\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  12. Utilisation de l'IA pour la synth√®se de documents en suivant un plan p\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  13. Identification √† un parcours 'classique' malgr√© la r√©orientation\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  14. M√©fiance envers la fiabilit√© de l'IA dans certains domaines\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "  15. Limitation de l'usage de l'IA pour des conseils psychologiques en rais\n",
            "      ‚Üí 1 occurrences dans 1 documents\n",
            "\n",
            "\n",
            "‚è∏  Filtrage termin√©. 163 codes r√©currents identifi√©s. ENTR√âE pour consolidation...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                      √âTAPE 1c: CONSOLIDATION CONCEPTUELLE                      \n",
            "================================================================================\n",
            "Objectif: Regrouper codes redondants et √©lever au niveau conceptuel\n",
            "\n",
            "üìä 163 codes r√©currents √† consolider\n",
            "\n",
            "‚è∏  Appuyez sur ENTR√âE pour lancer la consolidation...\n",
            "\n",
            "\n",
            "üì¶ Batch 1/1\n",
            "   163 codes √† consolider...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ You are performing CODE CONSOLIDATION in the Gioia method.                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ NOW you see ALL codes extracted from ALL interviews.                         ‚îÇ\n",
            "‚îÇ Your task: Identify RECURRING PATTERNS and consolidate redundant codes.      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   ‚îÇ\n",
            "‚îÇ CONSOLIDATION PRINCIPLES:                                                    ‚îÇ\n",
            "‚îÇ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1. MERGE semantic duplicates                                                 ‚îÇ\n",
            "‚îÇ    \"R√©flexe de consultation\" + \"Consultation automatique\" + \"Demander syst√©m ‚îÇ\n",
            "‚îÇ atiquement\"                                                                  ‚îÇ\n",
            "‚îÇ    ‚Üí \"Automatisation...                                                      ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Codes to consolidate (from interviews about students' ChatGPT use):          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ [                                                                            ‚îÇ\n",
            "‚îÇ   \"It√©ration et reformulation des requ√™tes pour obtenir des r√©sultats plus c ‚îÇ\n",
            "‚îÇ omplexes\",                                                                   ‚îÇ\n",
            "‚îÇ   \"Effort accru de reformulation pour les √©valuations importantes\",          ‚îÇ\n",
            "‚îÇ   \"Valorisation de l'efficacit√© de l'IA pour la m√©morisation\",               ‚îÇ\n",
            "‚îÇ   \"Interaction avec ChatGPT per√ßue comme purement fonctionnelle\",            ‚îÇ\n",
            "‚îÇ   \"Partage de ressources de cours limit√© au sein de la promotion\",           ‚îÇ\n",
            "‚îÇ   \"Reconnaissance de l'IA comme outil bas√© sur des donn√©es internet\",        ‚îÇ\n",
            "‚îÇ   \"√âquilibre per√ßu entre gain de temps et charge de travail de reformulation ‚îÇ\n",
            "‚îÇ \",                                                                           ‚îÇ\n",
            "‚îÇ   \"Utilisation de ChatGPT pour am√©liorer la formulation de documents profess ‚îÇ\n",
            "‚îÇ ionnels\",                                                                    ‚îÇ\n",
            "‚îÇ   \"Rejet de ChatGPT pour les math√©matiques\",                                 ‚îÇ\n",
            "‚îÇ   \"IA comme outil pratique pour pallier la procrastination\",                 ‚îÇ\n",
            "‚îÇ   \"Comparaison favorable de l'ambianc...                                     ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 163 codes ‚Üí 15 codes consolid√©s\n",
            "\n",
            "   Exemples:\n",
            "      1. It√©ration et ajustement des requ√™tes √† l'IA\n",
            "         ‚Üê 5 codes: It√©ration et reformulation des requ√™tes pour obten...\n",
            "      2. Usage strat√©gique de l'IA selon l'enjeu\n",
            "         ‚Üê 4 codes: Modulation de l'usage de l'IA selon l'enjeu de la ...\n",
            "      3. IA : outil d'optimisation et de gain de temps\n",
            "         ‚Üê 6 codes: Valorisation de l'efficacit√© de l'IA pour la m√©mor...\n",
            "\n",
            "================================================================================\n",
            "                           üìä R√âSULTATS CONSOLIDATION                            \n",
            "================================================================================\n",
            "‚úì Codes r√©currents: 163\n",
            "‚úì Codes consolid√©s: 15\n",
            "‚úì Taux de r√©duction: 90.8%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìä R√âSULTATS: Codes consolid√©s (√©chantillon)\n",
            "--------------------------------------------------------------------------------\n",
            "    1. It√©ration et ajustement des requ√™tes √† l'IA\n",
            "    2. Usage strat√©gique de l'IA selon l'enjeu\n",
            "    3. IA : outil d'optimisation et de gain de temps\n",
            "    4. M√©fiance et limites per√ßues de l'IA\n",
            "    5. Cr√©ation et am√©lioration de supports de r√©vision via IA\n",
            "    6. IA comme palliatif √† la procrastination et au blocage\n",
            "    7. Adaptation et appropriation du contenu g√©n√©r√© par l'IA\n",
            "    8. R√©flexe de consultation automatis√©e de l'IA\n",
            "    9. Conscience des enjeux et limites de l'IA\n",
            "   10. Influence de l'IA sur les dynamiques d'apprentissage\n",
            "   11. Dissimulation de l'usage de l'IA par crainte\n",
            "   12. V√©rification et validation des r√©ponses de l'IA\n",
            "   13. IA : outil pragmatique sans attachement √©motionnel\n",
            "   14. Impact de l'IA sur l'enseignement et l'√©valuation\n",
            "   15. Adaptation et int√©gration de l'IA dans le parcours universitaire\n",
            "\n",
            "‚è∏  Consolidation termin√©e. ENTR√âE pour passer √† l'√©tape 2...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                   √âTAPE 2: SECOND-ORDER CODING (CLUSTERING)                    \n",
            "================================================================================\n",
            "Objectif: Regrouper codes consolid√©s en 10-15 th√®mes\n",
            "\n",
            "üìä 15 codes consolid√©s √† th√©matiser\n",
            "\n",
            "‚è∏  Appuyez sur ENTR√âE pour lancer le clustering...\n",
            "\n",
            "\n",
            "üîÑ G√©n√©ration embeddings pour clustering...\n",
            "   ‚Üí 15/15 embeddings\n",
            "\n",
            "üéØ Clustering en 12 groupes...\n",
            "\n",
            "üè∑Ô∏è  Cr√©ation des noms de th√®mes...\n",
            "\n",
            "   Cluster 1/12 : 2 codes\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ You are applying 2nd Order Coding in the Gioia method.                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Given first-order codes (informant language), create ONE concise             ‚îÇ\n",
            "‚îÇ second-order theme name in academic language.                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The theme name should:                                                       ‚îÇ\n",
            "‚îÇ - Be 3-8 words                                                               ‚îÇ\n",
            "‚îÇ - Use abstract, academic language (unlike first-order codes)                 ‚îÇ\n",
            "‚îÇ - Capture what all these codes have in common                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY the theme name.                                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ First-order codes from cluster 1:                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ [                                                                            ‚îÇ\n",
            "‚îÇ   \"Influence de l'IA sur les dynamiques d'apprentissage\",                    ‚îÇ\n",
            "‚îÇ   \"Impact de l'IA sur l'enseignement et l'√©valuation\"                        ‚îÇ\n",
            "‚îÇ ]                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Create ONE second-order theme name (3-8 words, academic language).           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY the theme name.                                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Artificial intelligence reshaping educational paradigms'\n",
            "     ‚Üí 2 codes\n",
            "\n",
            "   Cluster 2/12 : 2 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Perceived Constraints and Limitations of Artificial Intelligence'\n",
            "     ‚Üí 2 codes\n",
            "\n",
            "   Cluster 3/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI Response Validation and Verification Processes'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 4/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI as a Productivity and Efficiency Enhancer'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 5/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI-Augmented Learning Material Development and Enhancement'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 6/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI-Generated Content Adaptation and Appropriation'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 7/12 : 2 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Recursive Engagement with Artificial Intelligence Systems'\n",
            "     ‚Üí 2 codes\n",
            "\n",
            "   Cluster 8/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Instrumental and Detached AI Adoption'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 9/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Strategic Concealment of AI Application'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 10/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'Strategic AI Deployment Aligned with Stakes'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 11/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI as a Procrastination and Blockage Mitigation Tool'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "   Cluster 12/12 : 1 codes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "   ‚úì 'AI Integration in Higher Education Trajectories'\n",
            "     ‚Üí 1 codes\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 2                               \n",
            "================================================================================\n",
            "‚úì 12 th√®mes cr√©√©s\n",
            "‚úì 15/15 codes assign√©s\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìä R√âSULTATS: Second-Order Themes\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  1. Artificial intelligence reshaping educational paradigms\n",
            "     ‚Ä¢ Influence de l'IA sur les dynamiques d'apprentissage\n",
            "     ‚Ä¢ Impact de l'IA sur l'enseignement et l'√©valuation\n",
            "\n",
            "  2. Perceived Constraints and Limitations of Artificial Intelligence\n",
            "     ‚Ä¢ M√©fiance et limites per√ßues de l'IA\n",
            "     ‚Ä¢ Conscience des enjeux et limites de l'IA\n",
            "\n",
            "  3. AI Response Validation and Verification Processes\n",
            "     ‚Ä¢ V√©rification et validation des r√©ponses de l'IA\n",
            "\n",
            "  4. AI as a Productivity and Efficiency Enhancer\n",
            "     ‚Ä¢ IA : outil d'optimisation et de gain de temps\n",
            "\n",
            "  5. AI-Augmented Learning Material Development and Enhancement\n",
            "     ‚Ä¢ Cr√©ation et am√©lioration de supports de r√©vision via IA\n",
            "\n",
            "  6. AI-Generated Content Adaptation and Appropriation\n",
            "     ‚Ä¢ Adaptation et appropriation du contenu g√©n√©r√© par l'IA\n",
            "\n",
            "  7. Recursive Engagement with Artificial Intelligence Systems\n",
            "     ‚Ä¢ It√©ration et ajustement des requ√™tes √† l'IA\n",
            "     ‚Ä¢ R√©flexe de consultation automatis√©e de l'IA\n",
            "\n",
            "  8. Instrumental and Detached AI Adoption\n",
            "     ‚Ä¢ IA : outil pragmatique sans attachement √©motionnel\n",
            "\n",
            "  9. Strategic Concealment of AI Application\n",
            "     ‚Ä¢ Dissimulation de l'usage de l'IA par crainte\n",
            "\n",
            "  10. Strategic AI Deployment Aligned with Stakes\n",
            "     ‚Ä¢ Usage strat√©gique de l'IA selon l'enjeu\n",
            "\n",
            "  11. AI as a Procrastination and Blockage Mitigation Tool\n",
            "     ‚Ä¢ IA comme palliatif √† la procrastination et au blocage\n",
            "\n",
            "  12. AI Integration in Higher Education Trajectories\n",
            "     ‚Ä¢ Adaptation et int√©gration de l'IA dans le parcours universitaire\n",
            "\n",
            "‚è∏  √âtape 2 termin√©e. ENTR√âE pour √©tape 3...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                         √âTAPE 3: AGGREGATE DIMENSIONS                          \n",
            "================================================================================\n",
            "Objectif: Regrouper th√®mes en 5-7 dimensions quantifiables\n",
            "\n",
            "‚è∏  ENTR√âE pour cr√©er les dimensions...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ You are applying Aggregate Dimensions phase of Gioia method.                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Identify overarching theoretical dimensions (5-7) that aggregate the 2nd ord ‚îÇ\n",
            "‚îÇ er themes.                                                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ CRITICAL: Dimensions must be QUANTIFIABLE.                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Output: {\"Dimension 1\": [\"theme 1\", \"theme 2\"], ...}                         ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY valid JSON.                                                      ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ 2nd order themes:                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ [                                                                            ‚îÇ\n",
            "‚îÇ   \"Artificial intelligence reshaping educational paradigms\",                 ‚îÇ\n",
            "‚îÇ   \"Perceived Constraints and Limitations of Artificial Intelligence\",        ‚îÇ\n",
            "‚îÇ   \"AI Response Validation and Verification Processes\",                       ‚îÇ\n",
            "‚îÇ   \"AI as a Productivity and Efficiency Enhancer\",                            ‚îÇ\n",
            "‚îÇ   \"AI-Augmented Learning Material Development and Enhancement\",              ‚îÇ\n",
            "‚îÇ   \"AI-Generated Content Adaptation and Appropriation\",                       ‚îÇ\n",
            "‚îÇ   \"Recursive Engagement with Artificial Intelligence Systems\",               ‚îÇ\n",
            "‚îÇ   \"Instrumental and Detached AI Adoption\",                                   ‚îÇ\n",
            "‚îÇ   \"Strategic Concealment of AI Application\",                                 ‚îÇ\n",
            "‚îÇ   \"Strategic AI Deployment Aligned with Stakes\",                             ‚îÇ\n",
            "‚îÇ   \"AI as a Procrastination and Blockage Mitigation Tool\",                    ‚îÇ\n",
            "‚îÇ   \"AI Integration in Higher Education Trajectories\"                          ‚îÇ\n",
            "‚îÇ ]                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Create 5-7 aggregate dimensions that:                                        ‚îÇ\n",
            "‚îÇ 1. Are quantifiable/measurable                                               ‚îÇ\n",
            "‚îÇ 2. Aggregate related themes                                                  ‚îÇ\n",
            "‚îÇ 3. Serve as ov...                                                            ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 3                               \n",
            "================================================================================\n",
            "‚úì 6 dimensions cr√©√©es\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìä R√âSULTATS: Aggregate Dimensions\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  1. AI Impact on Pedagogy\n",
            "     ‚Ä¢ Artificial intelligence reshaping educational paradigms\n",
            "     ‚Ä¢ AI-Augmented Learning Material Development and Enhancement\n",
            "     ‚Ä¢ AI Integration in Higher Education Trajectories\n",
            "\n",
            "  2. AI Limitations and Challenges\n",
            "     ‚Ä¢ Perceived Constraints and Limitations of Artificial Intelligence\n",
            "     ‚Ä¢ AI Response Validation and Verification Processes\n",
            "\n",
            "  3. AI as Productivity Tool\n",
            "     ‚Ä¢ AI as a Productivity and Efficiency Enhancer\n",
            "     ‚Ä¢ AI as a Procrastination and Blockage Mitigation Tool\n",
            "\n",
            "  4. Strategic AI Implementation\n",
            "     ‚Ä¢ Strategic Concealment of AI Application\n",
            "     ‚Ä¢ Strategic AI Deployment Aligned with Stakes\n",
            "\n",
            "  5. User Engagement with AI\n",
            "     ‚Ä¢ Recursive Engagement with Artificial Intelligence Systems\n",
            "     ‚Ä¢ Instrumental and Detached AI Adoption\n",
            "\n",
            "  6. Content Adaptation with AI\n",
            "     ‚Ä¢ AI-Generated Content Adaptation and Appropriation\n",
            "\n",
            "‚è∏  √âtape 3 termin√©e. ENTR√âE pour √©tape 4a...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                         √âTAPE 4a: BRAINSTORM THEORIES                          \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour brainstormer th√©ories...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Brainstorm theoretical models from literature applicable to research finding ‚îÇ\n",
            "‚îÇ s.                                                                           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Output:                                                                      ‚îÇ\n",
            "‚îÇ {                                                                            ‚îÇ\n",
            "‚îÇ   \"theories\": [                                                              ‚îÇ\n",
            "‚îÇ     {                                                                        ‚îÇ\n",
            "‚îÇ       \"theory\": \"Name\",                                                      ‚îÇ\n",
            "‚îÇ       \"description\": \"Brief description\",                                    ‚îÇ\n",
            "‚îÇ       \"relatedDimensions\": [\"Dim 1\"],                                        ‚îÇ\n",
            "‚îÇ       \"possibleResearchQuestions\": [\"Q1\"]                                    ‚îÇ\n",
            "‚îÇ     }                                                                        ‚îÇ\n",
            "‚îÇ   ]                                                                          ‚îÇ\n",
            "‚îÇ }                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY JSON.                                                            ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Aggregate dimensions:                                                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ {                                                                            ‚îÇ\n",
            "‚îÇ   \"AI Impact on Pedagogy\": [                                                 ‚îÇ\n",
            "‚îÇ     \"Artificial intelligence reshaping educational paradigms\",               ‚îÇ\n",
            "‚îÇ     \"AI-Augmented Learning Material Development and Enhancement\",            ‚îÇ\n",
            "‚îÇ     \"AI Integration in Higher Education Trajectories\"                        ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"AI Limitations and Challenges\": [                                         ‚îÇ\n",
            "‚îÇ     \"Perceived Constraints and Limitations of Artificial Intelligence\",      ‚îÇ\n",
            "‚îÇ     \"AI Response Validation and Verification Processes\"                      ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"AI as Productivity Tool\": [                                               ‚îÇ\n",
            "‚îÇ     \"AI as a Productivity and Efficiency Enhancer\",                          ‚îÇ\n",
            "‚îÇ     \"AI as a Procrastination and Blockage Mitigation Tool\"                   ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"Strategic AI Implementation\": [                                           ‚îÇ\n",
            "‚îÇ     \"Strategic Concealment of AI Application\",                               ‚îÇ\n",
            "‚îÇ     \"Strategic AI Deployment Aligned with Stakes\"                            ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"User Engagement with AI\": [                                               ‚îÇ\n",
            "‚îÇ     \"Recursive Engagement with Artificial Intelligence Systems\",             ‚îÇ\n",
            "‚îÇ     \"Ins...                                                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 4a                              \n",
            "================================================================================\n",
            "‚úì 7 th√©ories\n",
            "\n",
            "1. Technology Acceptance Model (TAM)\n",
            "   TAM suggests that perceived usefulness and perceived ease of use are key determinants of technology acceptance. It posits that if users believe a technology is useful and easy to use, they are more li\n",
            "\n",
            "2. Unified Theory of Acceptance and Use of Technology (UTAUT)\n",
            "   UTAUT builds upon TAM and other models to include performance expectancy, effort expectancy, social influence, and facilitating conditions as key factors influencing technology acceptance and use. It \n",
            "\n",
            "3. Cognitive Load Theory (CLT)\n",
            "   CLT focuses on the amount of mental effort required to process information. It distinguishes between intrinsic, extraneous, and germane cognitive load and suggests instructional designs should minimiz\n",
            "\n",
            "4. Self-Determination Theory (SDT)\n",
            "   SDT emphasizes the importance of autonomy, competence, and relatedness in motivating behavior. It suggests that individuals are more likely to engage in activities when they feel a sense of control, m\n",
            "\n",
            "5. Social Cognitive Theory (SCT)\n",
            "   SCT posits that learning occurs through observation, imitation, and modeling. It emphasizes the role of self-efficacy, outcome expectancies, and social influences in shaping behavior.\n",
            "\n",
            "6. Activity Theory\n",
            "   Activity Theory focuses on the interaction between a subject (learner), an object (learning material), and mediating artifacts (AI tools) within a social context. It emphasizes the importance of under\n",
            "\n",
            "7. Constructivism\n",
            "   Constructivism emphasizes that learners actively construct their own knowledge and understanding through experience. It suggests that learning is a process of building upon prior knowledge and making \n",
            "\n",
            "‚è∏  √âtape 4a termin√©e. ENTR√âE pour 4b...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                            √âTAPE 4b: CONCEPT TUPLES                            \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour g√©n√©rer tuples...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Hypothesize which concepts could be related.                                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return: {\"tuples\": [[\"concept 1\", \"concept 2\"], ...]}                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ ONLY JSON.                                                                   ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Dimensions:                                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ {                                                                            ‚îÇ\n",
            "‚îÇ   \"AI Impact on Pedagogy\": [                                                 ‚îÇ\n",
            "‚îÇ     \"Artificial intelligence reshaping educational paradigms\",               ‚îÇ\n",
            "‚îÇ     \"AI-Augmented Learning Material Development and Enhancement\",            ‚îÇ\n",
            "‚îÇ     \"AI Integration in Higher Education Trajectories\"                        ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"AI Limitations and Challenges\": [                                         ‚îÇ\n",
            "‚îÇ     \"Perceived Constraints and Limitations of Artificial Intelligence\",      ‚îÇ\n",
            "‚îÇ     \"AI Response Validation and Verification Processes\"                      ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"AI as Productivity Tool\": [                                               ‚îÇ\n",
            "‚îÇ     \"AI as a Productivity and Efficiency Enhancer\",                          ‚îÇ\n",
            "‚îÇ     \"AI as a Procrastination and Blockage Mitigation Tool\"                   ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"Strategic AI Implementation\": [                                           ‚îÇ\n",
            "‚îÇ     \"Strategic Concealment of AI Application\",                               ‚îÇ\n",
            "‚îÇ     \"Strategic AI Deployment Aligned with Stakes\"                            ‚îÇ\n",
            "‚îÇ   ],                                                                         ‚îÇ\n",
            "‚îÇ   \"User Engagement with AI\": [                                               ‚îÇ\n",
            "‚îÇ     \"Recursive Engagement with Artificial Intelligence Systems\",             ‚îÇ\n",
            "‚îÇ     \"Instrumental ...                                                        ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 4b                              \n",
            "================================================================================\n",
            "‚úì 15 tuples\n",
            "   1. Artificial intelligence reshaping educational paradigms ‚Üî Perceived Constraints and Limitations of Artificial Intelligence\n",
            "   2. AI-Augmented Learning Material Development and Enhancement ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "   3. AI Integration in Higher Education Trajectories ‚Üî Strategic AI Deployment Aligned with Stakes\n",
            "   4. AI as a Productivity and Efficiency Enhancer ‚Üî AI as a Procrastination and Blockage Mitigation Tool\n",
            "   5. Recursive Engagement with Artificial Intelligence Systems ‚Üî Instrumental and Detached AI Adoption\n",
            "   6. AI Response Validation and Verification Processes ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "   7. Strategic Concealment of AI Application ‚Üî Instrumental and Detached AI Adoption\n",
            "   8. Artificial intelligence reshaping educational paradigms ‚Üî AI-Augmented Learning Material Development and Enhancement\n",
            "   9. AI as a Productivity and Efficiency Enhancer ‚Üî Strategic AI Deployment Aligned with Stakes\n",
            "  10. Recursive Engagement with Artificial Intelligence Systems ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "  11. AI Integration in Higher Education Trajectories ‚Üî Perceived Constraints and Limitations of Artificial Intelligence\n",
            "  12. AI as a Procrastination and Blockage Mitigation Tool ‚Üî Strategic Concealment of AI Application\n",
            "  13. AI-Augmented Learning Material Development and Enhancement ‚Üî AI Response Validation and Verification Processes\n",
            "  14. Artificial intelligence reshaping educational paradigms ‚Üî Recursive Engagement with Artificial Intelligence Systems\n",
            "  15. AI Integration in Higher Education Trajectories ‚Üî AI as a Productivity and Efficiency Enhancer\n",
            "\n",
            "‚è∏  √âtape 4b termin√©e. ENTR√âE pour 4c (RAG)...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                       √âTAPE 4c: INTERRELATIONSHIPS (RAG)                       \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour explorer 15 relations...\n",
            "\n",
            "\n",
            "Exploration...\n",
            " 1/15: Artificial intelligence reshaping educational paradigms ‚Üî Perceived Constraints and Limitations of Artificial Intelligence\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Summarize interrelationship between two concepts in one sentence.            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Based on evidence passages, explain how concepts relate.                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ IMPORTANT: Passages may contain metadata. Focus ONLY on interview dialogue.  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY one-sentence summary.                                            ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Passages:                                                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ [Passage 1]:                                                                 ‚îÇ\n",
            "‚îÇ Ait Ali Wassil                                                               ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ contexte                                                                     ‚îÇ\n",
            "‚îÇ Le contexte de l‚Äôentretien m√©rite d‚Äô√™tre pr√©cis√©. Nous avions initialement d ‚îÇ\n",
            "‚îÇ es difficult√©s √† trouver un cr√©neau et surtout un lieu calme pour nous voir, ‚îÇ\n",
            "‚îÇ  en raison de nos emplois du temps respectifs. C‚Äôest pour cette raison que j ‚îÇ\n",
            "‚îÇ ‚Äôai finalement propos√© √† l‚Äôenqu√™t√© de venir directement chez moi. √Ä son arri ‚îÇ\n",
            "‚îÇ v√©e, toutes les conditions n√©cessaires √† la r√©alisation de l‚Äôentretien √©taie ‚îÇ\n",
            "‚îÇ nt r√©unies : mon t√©l√©phone a fait office d‚Äôappareil d‚Äôenregistrement, j'avai ‚îÇ\n",
            "‚îÇ s pr√©par√© d                                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ [Passage 2]:                                                                 ‚îÇ\n",
            "‚îÇ  gens nous interdisent de l'utiliser. Enfin, ils nous disent \"Oui, par       ‚îÇ\n",
            "‚îÇ exemple, √ßa sert √† rien de l'utiliser. \" Mais je sais que c'est d√©j√† arriv√©  ‚îÇ\n",
            "‚îÇ qu'on conseille de                                                           ‚îÇ\n",
            "‚îÇ l'utiliser pour l'orthographe. Moi, on m'a dit que chat GPT pour tout ce qui ‚îÇ\n",
            "‚îÇ  va √™tre                                                                     ‚îÇ\n",
            "‚îÇ r√©ponse...                                                                   ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì While AI is recognized as a potentially useful tool for task...\n",
            " 2/15: AI-Augmented Learning Material Development and Enhancement ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the provided passages, AI is used to generate summa...\n",
            " 3/15: AI Integration in Higher Education Trajectories ‚Üî Strategic AI Deployment Aligned with Stakes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI is strategically deployed in higher education, aligning i...\n",
            " 4/15: AI as a Productivity and Efficiency Enhancer ‚Üî AI as a Procrastination and Blockage Mitigation Tool\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI serves as both a tool to boost productivity and efficienc...\n",
            " 5/15: Recursive Engagement with Artificial Intelligence Systems ‚Üî Instrumental and Detached AI Adoption\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the passages, recursive engagement with AI involves...\n",
            " 6/15: AI Response Validation and Verification Processes ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI-generated content is adapted and appropriated by users wh...\n",
            " 7/15: Strategic Concealment of AI Application ‚Üî Instrumental and Detached AI Adoption\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the provided passages, there is no explicit mention...\n",
            " 8/15: Artificial intelligence reshaping educational paradigms ‚Üî AI-Augmented Learning Material Development and Enhancement\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the provided passages, there is no explicit discuss...\n",
            " 9/15: AI as a Productivity and Efficiency Enhancer ‚Üî Strategic AI Deployment Aligned with Stakes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the passages, AI, like GPT, is used in a varied man...\n",
            "10/15: Recursive Engagement with Artificial Intelligence Systems ‚Üî AI-Generated Content Adaptation and Appropriation\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the provided passages, AI-generated content is adap...\n",
            "11/15: AI Integration in Higher Education Trajectories ‚Üî Perceived Constraints and Limitations of Artificial Intelligence\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI is perceived as having limited usefulness for complex tas...\n",
            "12/15: AI as a Procrastination and Blockage Mitigation Tool ‚Üî Strategic Concealment of AI Application\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI is used to overcome academic hurdles, but students strate...\n",
            "13/15: AI-Augmented Learning Material Development and Enhancement ‚Üî AI Response Validation and Verification Processes\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the interviews, students use AI to summarize and si...\n",
            "14/15: Artificial intelligence reshaping educational paradigms ‚Üî Recursive Engagement with Artificial Intelligence Systems\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì Based on the provided interview snippets, the relationship b...\n",
            "15/15: AI Integration in Higher Education Trajectories ‚Üî AI as a Productivity and Efficiency Enhancer\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "     ‚úì AI serves as a tool to boost productivity and efficiency for...\n",
            "\n",
            "================================================================================\n",
            "                              üìä R√âSULTATS √âTAPE 4c                              \n",
            "================================================================================\n",
            "‚úì 15 relations explor√©es\n",
            "\n",
            "‚è∏  √âtape 4c termin√©e. ENTR√âE pour mod√®le (4d)...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                        D√âVELOPPEMENT TH√âORIQUE IT√âRATIF                        \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                                üîÑ IT√âRATION 1/2                                 \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                   √âTAPE 4d: THEORETICAL MODEL (It√©ration 1)                    \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour g√©n√©rer mod√®le (it. 1)...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Construct a theoretical model.                                               ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The model should be:                                                         ‚îÇ\n",
            "‚îÇ 1. Well-defined and novel                                                    ‚îÇ\n",
            "‚îÇ 2. Related to aggregate dimensions                                           ‚îÇ\n",
            "‚îÇ 3. Original                                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Emphasize relationships between dimensions.                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Give distinctive name to model.                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Write in clear academic style.                                               ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Research Question: L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n ‚îÇ\n",
            "‚îÇ √©ratives par les √©tudiants se structurent selon deux configurations distinct ‚îÇ\n",
            "‚îÇ es. La premi√®re configuration correspond √† des usages qui prolongent des pra ‚îÇ\n",
            "‚îÇ tiques scolaires classiques (quiz, organisation de notes, corrections) sans  ‚îÇ\n",
            "‚îÇ modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. L ‚îÇ\n",
            "‚îÇ a seconde configuration concerne des √©tudiants qui se livrent intimement √† c ‚îÇ\n",
            "‚îÇ es machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, dem ‚îÇ\n",
            "‚îÇ ander des conseils personnalis√©s, ou co-produire des contenus en interaction ‚îÇ\n",
            "‚îÇ  √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans frict ‚îÇ\n",
            "‚îÇ ion sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'expo ‚îÇ\n",
            "‚îÇ ser ses limites), mais elle g√©n√®re √©gale...                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                             üìä MOD√àLE (It√©ration 1)                             \n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Model - Iteration 1                                                          ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ ## The \"Cognitive Symbiosis and Academic Agency\" (CSAA) Model                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ This model, termed the \"Cognitive Symbiosis and Academic Agency\" (CSAA) mode ‚îÇ\n",
            "‚îÇ l, aims to explain the diverse ways students engage with generative AI tools ‚îÇ\n",
            "‚îÇ  and the implications for their learning and academic performance. It builds ‚îÇ\n",
            "‚îÇ  upon existing theories like TAM, UTAUT, CLT, SDT, and Activity Theory, but  ‚îÇ\n",
            "‚îÇ integrates them within a novel framework that emphasizes the dynamic interpl ‚îÇ\n",
            "‚îÇ ay between cognitive load, perceived autonomy, and the evolving relationship ‚îÇ\n",
            "‚îÇ  between student and AI.                                                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Core Tenets:**                                                             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The CSAA model posits that student engagement with generative AI tools exist ‚îÇ\n",
            "‚îÇ s on a spectrum defined by two primary axes:                                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  **Cognitive Symbiosis:** This axis represents the degree to which the st ‚îÇ\n",
            "‚îÇ udent's cognitive processes are intertwined with the AI. At one end, we have ‚îÇ\n",
            "‚îÇ  *Minimal Symbiosis*, where AI is used as a simple tool for discrete tasks ( ‚îÇ\n",
            "‚îÇ e.g., grammar checking) with minimal impact on the student's underlying unde ‚îÇ\n",
            "‚îÇ rstanding or reasoning. At the other end, we have *Deep Symbiosis*, where th ‚îÇ\n",
            "‚îÇ e AI becomes an integral part of the student's cognitive process, co-creatin ‚îÇ\n",
            "‚îÇ g content, providing personalized guidance, and potentially shaping the stud ‚îÇ\n",
            "‚îÇ ent's understanding of the subject matter.                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  **Academic Agency:** This axis reflects the student's perceived control  ‚îÇ\n",
            "‚îÇ and ownership over their learning process. *High Agency* is characterized by ‚îÇ\n",
            "‚îÇ  a strong sense of autonomy, self-efficacy, and a proactive approach to lear ‚îÇ\n",
            "‚îÇ ning. Students with high agency use AI strategically to enhance their unders ‚îÇ\n",
            "‚îÇ tanding and performance, while maintaining critical oversight and ensuring t ‚îÇ\n",
            "‚îÇ he AI's output aligns with their own intellectual goals. *Low Agency*, conve ‚îÇ\n",
            "‚îÇ rsely, is marked by a reliance on AI to complete tasks, a diminished sense o ‚îÇ\n",
            "‚îÇ f ownership over the learning process, and a potential for passive acceptanc ‚îÇ\n",
            "‚îÇ e of AI-generated content without critical evaluation.                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Model Components and Relationships:**                                      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The CSAA model integrates the following key components:                      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Perceived Usefulness and Ease of Use (TAM):** These factors, as define ‚îÇ\n",
            "‚îÇ d by TAM, influence the initial adoption of AI tools. However, the CSAA mode ‚îÇ\n",
            "‚îÇ l extends this by arguing that perceived usefulness is not static but evolve ‚îÇ\n",
            "‚îÇ s based on the student's experience and the degree of cognitive symbiosis th ‚îÇ\n",
            "‚îÇ ey develop. High perceived usefulness in a *Deep Symbiosis* context might be ‚îÇ\n",
            "‚îÇ  associated with increased reliance on AI, potentially impacting academic ag ‚îÇ\n",
            "‚îÇ ency.                                                                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Cognitive Load (CLT):** The CSAA model incorporates CLT by suggesting  ‚îÇ\n",
            "‚îÇ that AI can both reduce and increase cognitive load. In *Minimal Symbiosis*, ‚îÇ\n",
            "‚îÇ  AI can reduce extraneous cognitive load by automating tedious tasks, freein ‚îÇ\n",
            "‚îÇ g up cognitive resources for deeper learning. However, in *Deep Symbiosis*,  ‚îÇ\n",
            "‚îÇ the need to constantly evaluate and integrate AI-generated content can incre ‚îÇ\n",
            "‚îÇ ase cognitive load, especially if the student lacks the necessary critical t ‚îÇ\n",
            "‚îÇ hinking skills. Furthermore, over-reliance on AI can reduce the development  ‚îÇ\n",
            "‚îÇ of intrinsic cognitive load, which is necessary for deep learning.           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Self-Determination (SDT):** The CSAA model emphasizes the importance o ‚îÇ\n",
            "‚îÇ f autonomy, competence, and relatedness in shaping student engagement with A ‚îÇ\n",
            "‚îÇ I. Students with high academic agency are more likely to use AI in ways that ‚îÇ\n",
            "‚îÇ  support their autonomy and competence, while students with low agency may f ‚îÇ\n",
            "‚îÇ eel pressured to rely on AI, undermining their sense of control and mastery. ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Activity System (Activity Theory):** The CSAA model views the student- ‚îÇ\n",
            "‚îÇ AI interaction as an activity system, with the student as the subject, the l ‚îÇ\n",
            "‚îÇ earning material as the object, and the AI tool as the mediating artifact. T ‚îÇ\n",
            "‚îÇ he model emphasizes the importance of understanding the social context (e.g. ‚îÇ\n",
            "‚îÇ , institutional policies, peer norms) in shaping the student's engagement wi ‚îÇ\n",
            "‚îÇ th AI.                                                                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Hypotheses:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Based on the CSAA model, we can formulate the following hypotheses:          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  Students who adopt a *Deep Symbiosis* approach with low academic agency  ‚îÇ\n",
            "‚îÇ are more likely to experience a decline in critical thinking skills and a di ‚îÇ\n",
            "‚îÇ minished sense of ownership over their learning.                             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  Students who adopt a *Minimal Symbiosis* approach with high academic age ‚îÇ\n",
            "‚îÇ ncy are more likely to use AI strategically to enhance their learning and im ‚îÇ\n",
            "‚îÇ prove their academic performance.                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 3.  The perceived usefulness of AI is positively correlated with the degree  ‚îÇ\n",
            "‚îÇ of cognitive symbiosis, but this relationship is moderated by academic agenc ‚îÇ\n",
            "‚îÇ y. Students with high agency are more likely to critically evaluate the usef ‚îÇ\n",
            "‚îÇ ulness of AI, even in a *Deep Symbiosis* context.                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 4.  The social context (e.g., institutional policies, peer norms) significan ‚îÇ\n",
            "‚îÇ tly influences the degree of cognitive symbiosis and academic agency.        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Implications:**                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The CSAA model has several implications for educators and policymakers:      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   It highlights the need for educational interventions that promote critic ‚îÇ\n",
            "‚îÇ al thinking skills and academic agency in the age of AI.                     ‚îÇ\n",
            "‚îÇ *   It suggests that institutions should develop clear policies and guidelin ‚îÇ\n",
            "‚îÇ es regarding the use of AI in education, emphasizing the importance of ethic ‚îÇ\n",
            "‚îÇ al and responsible use.                                                      ‚îÇ\n",
            "‚îÇ *   It underscores the need for ongoing research to understand the long-term ‚îÇ\n",
            "‚îÇ  impact of AI on student learning and academic performance.                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Novelty:**                                                                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The CSAA model is novel in its emphasis on the dynamic interplay between cog ‚îÇ\n",
            "‚îÇ nitive symbiosis and academic agency. It moves beyond simple acceptance or r ‚îÇ\n",
            "‚îÇ ejection of AI to explore the nuanced ways students integrate these tools in ‚îÇ\n",
            "‚îÇ to their learning processes and the implications for their cognitive develop ‚îÇ\n",
            "‚îÇ ment and academic identity. By integrating established theories within a nov ‚îÇ\n",
            "‚îÇ el framework, the CSAA model provides a more comprehensive understanding of  ‚îÇ\n",
            "‚îÇ the complex relationship between students and generative AI.                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "================================================================================\n",
            "                        √âTAPE 4e: CRITIQUE (It√©ration 1)                        \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour critique...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Critique a theoretical model.                                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Comment on:                                                                  ‚îÇ\n",
            "‚îÇ 1. Novelty                                                                   ‚îÇ\n",
            "‚îÇ 2. Conciseness                                                               ‚îÇ\n",
            "‚îÇ 3. Clarity                                                                   ‚îÇ\n",
            "‚îÇ 4. Theoretical insight                                                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Suggest improvements.                                                        ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Codes sample:                                                                ‚îÇ\n",
            "‚îÇ [\"It√©ration et ajustement des requ√™tes √† l'IA\", \"Usage strat√©gique de l'IA s ‚îÇ\n",
            "‚îÇ elon l'enjeu\", \"IA : outil d'optimisation et de gain de temps\", \"M√©fiance et ‚îÇ\n",
            "‚îÇ  limites per√ßues de l'IA\", \"Cr√©ation et am√©lioration de supports de r√©vision ‚îÇ\n",
            "‚îÇ  via IA\", \"IA comme palliatif √† la procrastination et au blocage\", \"Adaptati ‚îÇ\n",
            "‚îÇ on et appropriation du contenu g√©n√©r√© par l'IA\", \"R√©flexe de consultation au ‚îÇ\n",
            "‚îÇ tomatis√©e de l'IA\", \"Conscience des enjeux et limites de l'IA\", \"Influence d ‚îÇ\n",
            "‚îÇ e l'IA sur les dynamiques d'apprentissage\", \"Dissimulation de l'usage de l'I ‚îÇ\n",
            "‚îÇ A par crainte\", \"V√©rification et validation des r√©ponses de l'IA\", \"IA : out ‚îÇ\n",
            "‚îÇ il pragmatique sans attachement √©motionnel\", \"Impact de l'IA sur l'enseignem ‚îÇ\n",
            "‚îÇ ent et l'√©valuation\", \"Adaptation et int√©gration de l'IA dans le parcours un ‚îÇ\n",
            "‚îÇ iversitaire\"]                                                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Interrelati...                                                               ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                            üìä CRITIQUE (It√©ration 1)                            \n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Critique - Iteration 1                                                       ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Okay, here's a critique of the \"Cognitive Symbiosis and Academic Agency\" (CS ‚îÇ\n",
            "‚îÇ AA) model, addressing novelty, conciseness, clarity, theoretical insight, an ‚îÇ\n",
            "‚îÇ d suggesting improvements based on the provided codes and interrelationships ‚îÇ\n",
            "‚îÇ .                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **1. Novelty:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The model's novelty lies in its attempt to synthesize exi ‚îÇ\n",
            "‚îÇ sting theories (TAM, UTAUT, CLT, SDT, Activity Theory) into a single framewo ‚îÇ\n",
            "‚îÇ rk specifically focused on the student-AI interaction. The concepts of \"Cogn ‚îÇ\n",
            "‚îÇ itive Symbiosis\" and \"Academic Agency\" as axes defining a spectrum of engage ‚îÇ\n",
            "‚îÇ ment are potentially novel and provide a useful lens for analysis. The empha ‚îÇ\n",
            "‚îÇ sis on the *dynamic* interplay between these factors is also a strength.     ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** While the combination is novel, the individual component ‚îÇ\n",
            "‚îÇ s are not. The model needs to clearly articulate *how* the synthesis creates ‚îÇ\n",
            "‚îÇ  something genuinely new and not just a re-packaging of existing ideas.  The ‚îÇ\n",
            "‚îÇ  novelty of \"Cognitive Symbiosis\" needs further justification. Is this a tru ‚îÇ\n",
            "‚îÇ ly new concept, or is it a re-framing of existing ideas about cognitive offl ‚îÇ\n",
            "‚îÇ oading or distributed cognition?  The model needs to differentiate itself fr ‚îÇ\n",
            "‚îÇ om existing work on human-computer interaction and cognitive augmentation.   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **2. Conciseness:**                                                          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The model is relatively concise in its core tenets and co ‚îÇ\n",
            "‚îÇ mponent descriptions. The use of two axes to define the spectrum of engageme ‚îÇ\n",
            "‚îÇ nt is a good way to simplify the complexity.                                 ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** The model could be more concise by streamlining the desc ‚îÇ\n",
            "‚îÇ riptions of the established theories (TAM, CLT, SDT, Activity Theory).  Inst ‚îÇ\n",
            "‚îÇ ead of re-explaining them, focus on *how* they are specifically adapted and  ‚îÇ\n",
            "‚îÇ integrated into the CSAA framework.  The \"Implications\" section could be mor ‚îÇ\n",
            "‚îÇ e focused and actionable.                                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **3. Clarity:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The definitions of \"Cognitive Symbiosis\" and \"Academic Ag ‚îÇ\n",
            "‚îÇ ency\" are relatively clear, and the use of examples (e.g., grammar checking  ‚îÇ\n",
            "‚îÇ for Minimal Symbiosis) helps to illustrate the concepts. The hypotheses are  ‚îÇ\n",
            "‚îÇ clearly stated and testable.                                                 ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** The model could benefit from a visual representation (e. ‚îÇ\n",
            "‚îÇ g., a 2x2 matrix with the axes) to further clarify the relationship between  ‚îÇ\n",
            "‚îÇ the two dimensions. The descriptions of the different levels within each axi ‚îÇ\n",
            "‚îÇ s (e.g., what *exactly* constitutes \"Deep Symbiosis\" vs. \"Minimal Symbiosis\" ‚îÇ\n",
            "‚îÇ ) could be more granular and operationalized.  The connection between the co ‚îÇ\n",
            "‚îÇ des provided and the model is not explicit enough. How would specific codes  ‚îÇ\n",
            "‚îÇ map onto the axes?                                                           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **4. Theoretical Insight:**                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The model offers a potentially valuable framework for und ‚îÇ\n",
            "‚îÇ erstanding the diverse ways students are using AI and the potential conseque ‚îÇ\n",
            "‚îÇ nces for their learning. The emphasis on academic agency is particularly ins ‚îÇ\n",
            "‚îÇ ightful, as it highlights the importance of student autonomy and critical th ‚îÇ\n",
            "‚îÇ inking in the age of AI. The model acknowledges both the potential benefits  ‚îÇ\n",
            "‚îÇ and risks of AI in education.                                                ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** The model needs to provide more specific theoretical ins ‚îÇ\n",
            "‚îÇ ights. What *new* predictions or explanations does the CSAA model offer that ‚îÇ\n",
            "‚îÇ  existing theories cannot?  The model needs to address the potential for *ne ‚îÇ\n",
            "‚îÇ gative* cognitive symbiosis ‚Äì situations where the AI actually hinders learn ‚îÇ\n",
            "‚îÇ ing or promotes dependence.  The model could benefit from exploring the ethi ‚îÇ\n",
            "‚îÇ cal implications of different positions on the spectrum.                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Improvements & Integration of Codes/Relationships:**                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Here's how to improve the model, specifically addressing the provided codes  ‚îÇ\n",
            "‚îÇ and interrelationships:                                                      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  **Mapping Codes to the Model:** Explicitly map the provided codes onto t ‚îÇ\n",
            "‚îÇ he CSAA model.  For example:                                                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ     *   **Minimal Symbiosis/High Agency:** \"V√©rification et validation des r ‚îÇ\n",
            "‚îÇ √©ponses de l'IA,\" \"IA : outil pragmatique sans attachement √©motionnel\"       ‚îÇ\n",
            "‚îÇ     *   **Minimal Symbiosis/Low Agency:** \"R√©flexe de consultation automatis ‚îÇ\n",
            "‚îÇ √©e de l'IA\" (if done without critical thought)                               ‚îÇ\n",
            "‚îÇ     *   **Deep Symbiosis/High Agency:** \"Adaptation et appropriation du cont ‚îÇ\n",
            "‚îÇ enu g√©n√©r√© par l'IA,\" \"Cr√©ation et am√©lioration de supports de r√©vision via  ‚îÇ\n",
            "‚îÇ IA\" (when used critically and creatively)                                    ‚îÇ\n",
            "‚îÇ     *   **Deep Symbiosis/Low Agency:** \"IA comme palliatif √† la procrastinat ‚îÇ\n",
            "‚îÇ ion et au blocage,\" \"Dissimulation de l'usage de l'IA par crainte\" (suggests ‚îÇ\n",
            "‚îÇ  a lack of ownership and reliance on AI)                                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ     This mapping will make the model more concrete and demonstrate its appli ‚îÇ\n",
            "‚îÇ cability to real-world student behaviors.                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  **Incorporating Interrelationships:** Use the provided interrelationship ‚îÇ\n",
            "‚îÇ s to refine the model's components and hypotheses.  For example:             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ     *   **\"Artificial intelligence reshaping educational paradigms ‚Üî Perceiv ‚îÇ\n",
            "‚îÇ ed Constraints and Limitations of Artificial Intelligence\":**  This suggests ‚îÇ\n",
            "‚îÇ  that the *perceived* limitations of AI can influence a student's position o ‚îÇ\n",
            "‚îÇ n the Cognitive Symbiosis axis.  If a student believes AI is unreliable, the ‚îÇ\n",
            "‚îÇ y are less likely to engage in Deep Symbiosis, regardless of their agency.   ‚îÇ\n",
            "‚îÇ This could be added as a moderating factor.                                  ‚îÇ\n",
            "‚îÇ     *   **\"AI-Augmented Learning Material Development and Enhancement ‚Üî AI-G ‚îÇ\n",
            "‚îÇ enerated Content Adaptation and Appropriation\":** This highlights the import ‚îÇ\n",
            "‚îÇ ance of adaptation and appropriation.  The model should emphasize that *how* ‚îÇ\n",
            "‚îÇ  students adapt and appropriate AI-generated content is crucial.  Are they s ‚îÇ\n",
            "‚îÇ imply copying and pasting, or are they critically evaluating and integrating ‚îÇ\n",
            "‚îÇ  the information into their own understanding? This relates directly to Acad ‚îÇ\n",
            "‚îÇ emic Agency.                                                                 ‚îÇ\n",
            "‚îÇ     *   **\"AI Integration in Higher Education Trajectories ‚Üî Strategic AI De ‚îÇ\n",
            "‚îÇ ployment Aligned with Stakes\":** This suggests that the *context* of AI use  ‚îÇ\n",
            "‚îÇ is important.  The model should consider how institutional policies and cour ‚îÇ\n",
            "‚îÇ se requirements influence student engagement with AI.  Are students encourag ‚îÇ\n",
            "‚îÇ ed to use AI strategically, or is it discouraged altogether?                 ‚îÇ\n",
            "‚îÇ     *   **\"AI as a Productivity and Efficiency Enhancer ‚Üî AI as a Procrastin ‚îÇ\n",
            "‚îÇ ation and Blockage Mitigation Tool\":** This highlights the dual nature of AI ‚îÇ\n",
            "‚îÇ .  The model should address the potential for AI to be used both productivel ‚îÇ\n",
            "‚îÇ y and as a crutch.  The key is to understand the student's motivation and th ‚îÇ\n",
            "‚îÇ eir level of academic agency.                                                ‚îÇ\n",
            "‚îÇ     *   **\"Recursive Engagement with Artificial Intelligence Systems ‚Üî Instr ‚îÇ\n",
            "‚îÇ umental and Detached AI Adoption\":** This suggests two distinct approaches.  ‚îÇ\n",
            "‚îÇ The model should explore the factors that lead students to adopt one approac ‚îÇ\n",
            "‚îÇ h over the other. Is it their prior experience with AI, their learning style ‚îÇ\n",
            "‚îÇ , or the specific task at hand?                                              ‚îÇ\n",
            "‚îÇ     *   **\"AI Response Validation and Verification Processes ‚Üî AI-Generated  ‚îÇ\n",
            "‚îÇ Content Adaptation and Appropriation\":** This reinforces the importance of c ‚îÇ\n",
            "‚îÇ ritical evaluation. The model should emphasize that validation and verificat ‚îÇ\n",
            "‚îÇ ion are essential components of high academic agency.                        ‚îÇ\n",
            "‚îÇ     *   **\"Strategic Concealment of AI Application ‚Üî Instrumental and Detach ‚îÇ\n",
            "‚îÇ ed AI Adoption\":** This suggests that students who are strategically conceal ‚îÇ\n",
            "‚îÇ ing their AI use may be doing so because they lack confidence in their own a ‚îÇ\n",
            "‚îÇ bilities or because they fear negative consequences. This relates to both Ac ‚îÇ\n",
            "‚îÇ ademic Agency and the social context.                                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 3.  **Refine Hypotheses:**  Refine the hypotheses to be more specific and te ‚îÇ\n",
            "‚îÇ stable, incorporating the insights from the codes and interrelationships.  F ‚îÇ\n",
            "‚îÇ or example:                                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ     *   \"Students who engage in *Deep Symbiosis* with AI and exhibit *low ac ‚îÇ\n",
            "‚îÇ ademic agency*, as evidenced by a reliance on AI for procrastination and a l ‚îÇ\n",
            "‚îÇ ack of critical evaluation of AI-generated content, are more likely to exper ‚îÇ\n",
            "‚îÇ ience a decline in critical thinking skills and a diminished sense of owners ‚îÇ\n",
            "‚îÇ hip over their learning, *particularly in tasks requiring higher-order cogni ‚îÇ\n",
            "‚îÇ tive skills*.\"                                                               ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 4.  **Visual Representation:** Create a 2x2 matrix with \"Cognitive Symbiosis ‚îÇ\n",
            "‚îÇ \" on one axis and \"Academic Agency\" on the other.  Place the codes within th ‚îÇ\n",
            "‚îÇ e appropriate quadrants to visually represent the model.                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 5.  **Address Limitations:** Acknowledge the limitations of the model. For e ‚îÇ\n",
            "‚îÇ xample, the model may not fully capture the emotional or affective dimension ‚îÇ\n",
            "‚îÇ s of the student-AI relationship. It may also be difficult to accurately mea ‚îÇ\n",
            "‚îÇ sure cognitive symbiosis and academic agency.                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ By incorporating these suggestions, the CSAA model can become a more robust, ‚îÇ\n",
            "‚îÇ  nuanced, and practically relevant framework for understanding the complex r ‚îÇ\n",
            "‚îÇ elationship between students and generative AI. Remember to clearly articula ‚îÇ\n",
            "‚îÇ te the *new* insights that the model provides beyond existing theories. Good ‚îÇ\n",
            "‚îÇ  luck!                                                                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "‚è∏  It√©ration 1 termin√©e. ENTR√âE pour it. 2...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                                üîÑ IT√âRATION 2/2                                 \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                   √âTAPE 4d: THEORETICAL MODEL (It√©ration 2)                    \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour g√©n√©rer mod√®le (it. 2)...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Construct a theoretical model.                                               ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The model should be:                                                         ‚îÇ\n",
            "‚îÇ 1. Well-defined and novel                                                    ‚îÇ\n",
            "‚îÇ 2. Related to aggregate dimensions                                           ‚îÇ\n",
            "‚îÇ 3. Original                                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Emphasize relationships between dimensions.                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Give distinctive name to model.                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Write in clear academic style.                                               ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Research Question: L'enqu√™te exploratoire a r√©v√©l√© que les usages des IA g√©n ‚îÇ\n",
            "‚îÇ √©ratives par les √©tudiants se structurent selon deux configurations distinct ‚îÇ\n",
            "‚îÇ es. La premi√®re configuration correspond √† des usages qui prolongent des pra ‚îÇ\n",
            "‚îÇ tiques scolaires classiques (quiz, organisation de notes, corrections) sans  ‚îÇ\n",
            "‚îÇ modifier substantiellement les conditions d'exercice du m√©tier d'√©tudiant. L ‚îÇ\n",
            "‚îÇ a seconde configuration concerne des √©tudiants qui se livrent intimement √† c ‚îÇ\n",
            "‚îÇ es machines, que ce soit pour exposer leurs difficult√©s d'apprentissage, dem ‚îÇ\n",
            "‚îÇ ander des conseils personnalis√©s, ou co-produire des contenus en interaction ‚îÇ\n",
            "‚îÇ  √©troite avec l'outil. Cette intimit√© artificielle cr√©e un espace sans frict ‚îÇ\n",
            "‚îÇ ion sociale qui procure un ¬´ gain ¬ª (absence de jugement, possibilit√© d'expo ‚îÇ\n",
            "‚îÇ ser ses limites), mais elle g√©n√®re √©gale...                                  ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                             üìä MOD√àLE (It√©ration 2)                             \n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Model - Iteration 2                                                          ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ ## The \"Adaptive Cognitive Integration and Scholarly Ownership\" (ACISO) Mode ‚îÇ\n",
            "‚îÇ l                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ This model, termed the \"Adaptive Cognitive Integration and Scholarly Ownersh ‚îÇ\n",
            "‚îÇ ip\" (ACISO) model, builds upon the \"Cognitive Symbiosis and Academic Agency\" ‚îÇ\n",
            "‚îÇ  (CSAA) model, addressing its limitations and incorporating the provided dim ‚îÇ\n",
            "‚îÇ ensions and codes to offer a more nuanced and practically relevant framework ‚îÇ\n",
            "‚îÇ  for understanding student engagement with generative AI. The ACISO model em ‚îÇ\n",
            "‚îÇ phasizes the *dynamic* and *adaptive* nature of this engagement, highlightin ‚îÇ\n",
            "‚îÇ g the importance of scholarly ownership in navigating the evolving landscape ‚îÇ\n",
            "‚îÇ  of AI-assisted learning.                                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Core Tenets:**                                                             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model posits that student engagement with generative AI tools exis ‚îÇ\n",
            "‚îÇ ts on a spectrum defined by two primary, interacting axes:                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  **Cognitive Integration:** This axis represents the degree to which AI i ‚îÇ\n",
            "‚îÇ s integrated into the student's cognitive processes, ranging from *Periphera ‚îÇ\n",
            "‚îÇ l Integration* to *Deep Integration*. *Peripheral Integration* involves usin ‚îÇ\n",
            "‚îÇ g AI for discrete, well-defined tasks with minimal impact on core cognitive  ‚îÇ\n",
            "‚îÇ processes (e.g., grammar checking, basic information retrieval). *Deep Integ ‚îÇ\n",
            "‚îÇ ration*, on the other hand, involves a more profound intertwining of AI with ‚îÇ\n",
            "‚îÇ  the student's thinking, where AI assists in complex problem-solving, idea g ‚îÇ\n",
            "‚îÇ eneration, and knowledge construction. Crucially, *Deep Integration* is not  ‚îÇ\n",
            "‚îÇ inherently positive; it can lead to dependence and a decline in critical thi ‚îÇ\n",
            "‚îÇ nking if not managed effectively.                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  **Scholarly Ownership:** This axis reflects the student's sense of respo ‚îÇ\n",
            "‚îÇ nsibility, control, and critical engagement with their learning process and  ‚îÇ\n",
            "‚îÇ the AI tools they use. It ranges from *Delegated Ownership* to *Assertive Ow ‚îÇ\n",
            "‚îÇ nership*. *Delegated Ownership* is characterized by a passive acceptance of  ‚îÇ\n",
            "‚îÇ AI-generated content and a diminished sense of responsibility for the learni ‚îÇ\n",
            "‚îÇ ng outcome. Students with *Delegated Ownership* may rely heavily on AI to co ‚îÇ\n",
            "‚îÇ mplete tasks without critically evaluating the output or understanding the u ‚îÇ\n",
            "‚îÇ nderlying concepts. *Assertive Ownership*, conversely, is marked by a proact ‚îÇ\n",
            "‚îÇ ive and critical approach to learning, where students actively evaluate AI-g ‚îÇ\n",
            "‚îÇ enerated content, integrate it into their own understanding, and take respon ‚îÇ\n",
            "‚îÇ sibility for the final product. Students with *Assertive Ownership* use AI s ‚îÇ\n",
            "‚îÇ trategically to enhance their learning, while maintaining intellectual indep ‚îÇ\n",
            "‚îÇ endence and ensuring the AI's output aligns with their own goals.            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Novelty and Theoretical Contribution:**                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model's novelty lies in its emphasis on *adaptive* cognitive integ ‚îÇ\n",
            "‚îÇ ration and the concept of *scholarly ownership*. While the CSAA model introd ‚îÇ\n",
            "‚îÇ uced the idea of cognitive symbiosis and academic agency, the ACISO model re ‚îÇ\n",
            "‚îÇ fines these concepts and provides a more nuanced understanding of their inte ‚îÇ\n",
            "‚îÇ rplay. Specifically:                                                         ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Adaptive Integration:** The ACISO model recognizes that the optimal le ‚îÇ\n",
            "‚îÇ vel of cognitive integration is not fixed but depends on the specific task,  ‚îÇ\n",
            "‚îÇ the student's prior knowledge, and the learning context. Students must *adap ‚îÇ\n",
            "‚îÇ t* their use of AI to maximize its benefits while minimizing its potential d ‚îÇ\n",
            "‚îÇ rawbacks. This adaptive approach is crucial for fostering deep learning and  ‚îÇ\n",
            "‚îÇ preventing over-reliance on AI.                                              ‚îÇ\n",
            "‚îÇ *   **Scholarly Ownership:** The ACISO model introduces the concept of *scho ‚îÇ\n",
            "‚îÇ larly ownership* to emphasize the importance of responsibility, critical thi ‚îÇ\n",
            "‚îÇ nking, and intellectual independence in the age of AI. This concept goes bey ‚îÇ\n",
            "‚îÇ ond simple \"agency\" to encompass a broader sense of ethical and intellectual ‚îÇ\n",
            "‚îÇ  responsibility for one's learning. It highlights the need for students to a ‚îÇ\n",
            "‚îÇ ctively engage with AI-generated content, critically evaluate its validity,  ‚îÇ\n",
            "‚îÇ and integrate it into their own understanding.                               ‚îÇ\n",
            "‚îÇ *   **Addressing Negative Symbiosis:** The ACISO model explicitly addresses  ‚îÇ\n",
            "‚îÇ the potential for *negative* cognitive integration, where AI hinders learnin ‚îÇ\n",
            "‚îÇ g or promotes dependence. This is a crucial addition, as it acknowledges tha ‚îÇ\n",
            "‚îÇ t AI is not always a beneficial tool and that its use must be carefully mana ‚îÇ\n",
            "‚îÇ ged.                                                                         ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Model Components and Relationships:**                                      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model integrates the following key components, drawing upon and ad ‚îÇ\n",
            "‚îÇ apting established theories:                                                 ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Perceived Usefulness and Ease of Use (TAM):** As in the CSAA model, th ‚îÇ\n",
            "‚îÇ ese factors influence initial adoption. However, the ACISO model emphasizes  ‚îÇ\n",
            "‚îÇ that perceived usefulness is not solely based on efficiency but also on the  ‚îÇ\n",
            "‚îÇ *quality* of the learning experience and the development of scholarly owners ‚îÇ\n",
            "‚îÇ hip.                                                                         ‚îÇ\n",
            "‚îÇ *   **Cognitive Load (CLT):** The ACISO model builds on CLT by suggesting th ‚îÇ\n",
            "‚îÇ at AI can both reduce and increase cognitive load, but the *type* of cogniti ‚îÇ\n",
            "‚îÇ ve load is crucial. AI can reduce extraneous cognitive load (e.g., tedious t ‚îÇ\n",
            "‚îÇ asks) but should not eliminate intrinsic cognitive load (e.g., effortful lea ‚îÇ\n",
            "‚îÇ rning). Furthermore, the ACISO model highlights the importance of managing g ‚îÇ\n",
            "‚îÇ ermane cognitive load (e.g., integrating new information with existing knowl ‚îÇ\n",
            "‚îÇ edge) when using AI.                                                         ‚îÇ\n",
            "‚îÇ *   **Self-Determination (SDT):** The ACISO model emphasizes the importance  ‚îÇ\n",
            "‚îÇ of autonomy, competence, and relatedness in shaping student engagement with  ‚îÇ\n",
            "‚îÇ AI. Students with high scholarly ownership are more likely to use AI in ways ‚îÇ\n",
            "‚îÇ  that support their autonomy and competence, while students with delegated o ‚îÇ\n",
            "‚îÇ wnership may feel pressured to rely on AI, undermining their sense of contro ‚îÇ\n",
            "‚îÇ l and mastery.                                                               ‚îÇ\n",
            "‚îÇ *   **Activity System (Activity Theory):** The ACISO model views the student ‚îÇ\n",
            "‚îÇ -AI interaction as an activity system, with the student as the subject, the  ‚îÇ\n",
            "‚îÇ learning material as the object, and the AI tool as the mediating artifact.  ‚îÇ\n",
            "‚îÇ The model emphasizes the importance of understanding the social context (e.g ‚îÇ\n",
            "‚îÇ ., institutional policies, peer norms) in shaping the student's engagement w ‚îÇ\n",
            "‚îÇ ith AI. The ACISO model adds to this by emphasizing the *rules* and *communi ‚îÇ\n",
            "‚îÇ ty* aspects of the activity system. Institutional policies and peer norms ca ‚îÇ\n",
            "‚îÇ n either encourage or discourage scholarly ownership.                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Mapping Dimensions and Codes:**                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The following table illustrates how the provided dimensions and codes map on ‚îÇ\n",
            "‚îÇ to the ACISO model:                                                          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ | Dimension                       | Code                                     ‚îÇ\n",
            "‚îÇ                              | Cognitive Integration | Scholarly Ownership | ‚îÇ\n",
            "‚îÇ |---------------------------------|----------------------------------------- ‚îÇ\n",
            "‚îÇ -----------------------------|-----------------------|---------------------- ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ | AI Impact on Pedagogy           | Artificial intelligence reshaping educat ‚îÇ\n",
            "‚îÇ ional paradigms              | High                  | Variable              ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ | AI Impact on Pedagogy           | AI-Augmented Learning Material Developme ‚îÇ\n",
            "‚îÇ nt and Enhancement           | High                  | High (if adaptive)    ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ | AI Impact on Pedagogy           | AI Integration in Higher Education Traje ‚îÇ\n",
            "‚îÇ ctories                     | Variable              | Variable             | ‚îÇ\n",
            "‚îÇ | AI Limitations and Challenges   | Perceived Constraints and Limitations of ‚îÇ\n",
            "‚îÇ  Artificial Intelligence     | Low                   | High                  ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ | AI Limitations and Challenges   | AI Response Validation and Verification  ‚îÇ\n",
            "‚îÇ Processes                    | Variable              | High                  ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ | AI as Productivity Tool         | AI as a Productivity and Efficiency Enha ‚îÇ\n",
            "‚îÇ ncer                        | Low to Medium         | Variable             | ‚îÇ\n",
            "‚îÇ | AI as Productivity Tool         | AI as a Procrastination and Blockage Mit ‚îÇ\n",
            "‚îÇ igation Tool                | High                  | Low                  | ‚îÇ\n",
            "‚îÇ | Strategic AI Implementation   | Strategic Concealment of AI Application    ‚îÇ\n",
            "‚îÇ                           | Variable              | Low                  |   ‚îÇ\n",
            "‚îÇ | Strategic AI Implementation   | Strategic AI Deployment Aligned with Stake ‚îÇ\n",
            "‚îÇ s                          | Variable              | High                 |  ‚îÇ\n",
            "‚îÇ | User Engagement with AI         | Recursive Engagement with Artificial Int ‚îÇ\n",
            "‚îÇ elligence Systems             | High                  | Variable             ‚îÇ\n",
            "‚îÇ  |                                                                           ‚îÇ\n",
            "‚îÇ | User Engagement with AI         | Instrumental and Detached AI Adoption    ‚îÇ\n",
            "‚îÇ                             | Low                   | Low                  | ‚îÇ\n",
            "‚îÇ | Content Adaptation with AI      | AI-Generated Content Adaptation and Appr ‚îÇ\n",
            "‚îÇ opriation                    | High                  | High (if critical)    ‚îÇ\n",
            "‚îÇ |                                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Hypotheses:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Based on the ACISO model, we can formulate the following hypotheses:         ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  Students who engage in *Deep Integration* with AI and exhibit *Delegated ‚îÇ\n",
            "‚îÇ  Ownership*, as evidenced by a reliance on AI for procrastination and a lack ‚îÇ\n",
            "‚îÇ  of critical evaluation of AI-generated content, are more likely to experien ‚îÇ\n",
            "‚îÇ ce a decline in critical thinking skills and a diminished sense of responsib ‚îÇ\n",
            "‚îÇ ility for their learning outcomes.                                           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  Students who engage in *Adaptive Integration* with AI and exhibit *Asser ‚îÇ\n",
            "‚îÇ tive Ownership*, as evidenced by strategic use of AI to enhance learning and ‚îÇ\n",
            "‚îÇ  a proactive approach to validating and verifying AI-generated content, are  ‚îÇ\n",
            "‚îÇ more likely to achieve deeper understanding and improved academic performanc ‚îÇ\n",
            "‚îÇ e.                                                                           ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 3.  The perceived usefulness of AI is positively correlated with the degree  ‚îÇ\n",
            "‚îÇ of cognitive integration, but this relationship is moderated by scholarly ow ‚îÇ\n",
            "‚îÇ nership. Students with high scholarly ownership are more likely to criticall ‚îÇ\n",
            "‚îÇ y evaluate the usefulness of AI and adapt their use accordingly.             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 4.  Institutional policies and peer norms that promote critical thinking, in ‚îÇ\n",
            "‚îÇ tellectual independence, and ethical use of AI will foster scholarly ownersh ‚îÇ\n",
            "‚îÇ ip and adaptive cognitive integration.                                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 5.  Students who strategically conceal their AI use are more likely to exhib ‚îÇ\n",
            "‚îÇ it delegated ownership and a lack of confidence in their own abilities.      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Implications:**                                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model has several implications for educators and policymakers:     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   It highlights the need for educational interventions that promote critic ‚îÇ\n",
            "‚îÇ al thinking skills, intellectual independence, and ethical use of AI.        ‚îÇ\n",
            "‚îÇ *   It suggests that institutions should develop clear policies and guidelin ‚îÇ\n",
            "‚îÇ es regarding the use of AI in education, emphasizing the importance of schol ‚îÇ\n",
            "‚îÇ arly ownership and responsible use.                                          ‚îÇ\n",
            "‚îÇ *   It underscores the need for ongoing research to understand the long-term ‚îÇ\n",
            "‚îÇ  impact of AI on student learning and academic performance, focusing on the  ‚îÇ\n",
            "‚îÇ development of adaptive cognitive integration skills and scholarly ownership ‚îÇ\n",
            "‚îÇ .                                                                            ‚îÇ\n",
            "‚îÇ *   It suggests that educators should design learning activities that encour ‚îÇ\n",
            "‚îÇ age students to critically evaluate AI-generated content and integrate it in ‚îÇ\n",
            "‚îÇ to their own understanding.                                                  ‚îÇ\n",
            "‚îÇ *   It highlights the importance of creating a supportive learning environme ‚îÇ\n",
            "‚îÇ nt where students feel comfortable discussing their use of AI and seeking gu ‚îÇ\n",
            "‚îÇ idance from instructors.                                                     ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Visual Representation:**                                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ A 2x2 matrix can be used to visually represent the ACISO model, with \"Cognit ‚îÇ\n",
            "‚îÇ ive Integration\" on one axis (Peripheral to Deep) and \"Scholarly Ownership\"  ‚îÇ\n",
            "‚îÇ on the other axis (Delegated to Assertive). The codes can be placed within t ‚îÇ\n",
            "‚îÇ he appropriate quadrants to illustrate the model's application.              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Limitations:**                                                             ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model, like any theoretical model, has limitations. It may not ful ‚îÇ\n",
            "‚îÇ ly capture the emotional or affective dimensions of the student-AI relations ‚îÇ\n",
            "‚îÇ hip. It may also be difficult to accurately measure cognitive integration an ‚îÇ\n",
            "‚îÇ d scholarly ownership. Furthermore, the model is based on the assumption tha ‚îÇ\n",
            "‚îÇ t students have access to AI tools and the necessary skills to use them effe ‚îÇ\n",
            "‚îÇ ctively. Future research should address these limitations and explore the mo ‚îÇ\n",
            "‚îÇ del's applicability in diverse educational contexts.                         ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ By emphasizing adaptive cognitive integration and scholarly ownership, the A ‚îÇ\n",
            "‚îÇ CISO model provides a more nuanced and practically relevant framework for un ‚îÇ\n",
            "‚îÇ derstanding the complex relationship between students and generative AI. It  ‚îÇ\n",
            "‚îÇ offers valuable insights for educators and policymakers seeking to harness t ‚îÇ\n",
            "‚îÇ he potential of AI while mitigating its risks.                               ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "================================================================================\n",
            "                        √âTAPE 4e: CRITIQUE (It√©ration 2)                        \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour critique...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Critique a theoretical model.                                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Comment on:                                                                  ‚îÇ\n",
            "‚îÇ 1. Novelty                                                                   ‚îÇ\n",
            "‚îÇ 2. Conciseness                                                               ‚îÇ\n",
            "‚îÇ 3. Clarity                                                                   ‚îÇ\n",
            "‚îÇ 4. Theoretical insight                                                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Suggest improvements.                                                        ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Codes sample:                                                                ‚îÇ\n",
            "‚îÇ [\"It√©ration et ajustement des requ√™tes √† l'IA\", \"Usage strat√©gique de l'IA s ‚îÇ\n",
            "‚îÇ elon l'enjeu\", \"IA : outil d'optimisation et de gain de temps\", \"M√©fiance et ‚îÇ\n",
            "‚îÇ  limites per√ßues de l'IA\", \"Cr√©ation et am√©lioration de supports de r√©vision ‚îÇ\n",
            "‚îÇ  via IA\", \"IA comme palliatif √† la procrastination et au blocage\", \"Adaptati ‚îÇ\n",
            "‚îÇ on et appropriation du contenu g√©n√©r√© par l'IA\", \"R√©flexe de consultation au ‚îÇ\n",
            "‚îÇ tomatis√©e de l'IA\", \"Conscience des enjeux et limites de l'IA\", \"Influence d ‚îÇ\n",
            "‚îÇ e l'IA sur les dynamiques d'apprentissage\", \"Dissimulation de l'usage de l'I ‚îÇ\n",
            "‚îÇ A par crainte\", \"V√©rification et validation des r√©ponses de l'IA\", \"IA : out ‚îÇ\n",
            "‚îÇ il pragmatique sans attachement √©motionnel\", \"Impact de l'IA sur l'enseignem ‚îÇ\n",
            "‚îÇ ent et l'√©valuation\", \"Adaptation et int√©gration de l'IA dans le parcours un ‚îÇ\n",
            "‚îÇ iversitaire\"]                                                                ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Interrelati...                                                               ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                            üìä CRITIQUE (It√©ration 2)                            \n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Critique - Iteration 2                                                       ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Okay, here's a critique of the \"Adaptive Cognitive Integration and Scholarly ‚îÇ\n",
            "‚îÇ  Ownership\" (ACISO) model, addressing novelty, conciseness, clarity, theoret ‚îÇ\n",
            "‚îÇ ical insight, and suggesting improvements.                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **1. Novelty:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The ACISO model builds upon existing frameworks (like TAM ‚îÇ\n",
            "‚îÇ , CLT, SDT, and Activity Theory) but introduces the specific concepts of *ad ‚îÇ\n",
            "‚îÇ aptive* cognitive integration and *scholarly ownership*. This is a significa ‚îÇ\n",
            "‚îÇ nt step forward. The emphasis on *adaptive* use, rather than simply *more* o ‚îÇ\n",
            "‚îÇ r *less* integration, is a valuable nuance. The concept of *scholarly owners ‚îÇ\n",
            "‚îÇ hip* is also a strong contribution, moving beyond simple agency to encompass ‚îÇ\n",
            "‚îÇ  responsibility and critical engagement. The explicit acknowledgement of *ne ‚îÇ\n",
            "‚îÇ gative* cognitive integration is also a novel and important addition.        ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** While the *combination* of these elements is novel, some ‚îÇ\n",
            "‚îÇ  individual components are less so.  The idea of adapting technology use to  ‚îÇ\n",
            "‚îÇ context is not entirely new in educational technology research.  The challen ‚îÇ\n",
            "‚îÇ ge is to demonstrate how *this specific* adaptation, within the context of g ‚îÇ\n",
            "‚îÇ enerative AI, is unique and impactful.  The model also needs to clearly diff ‚îÇ\n",
            "‚îÇ erentiate itself from other models that address student agency and self-regu ‚îÇ\n",
            "‚îÇ lation in technology-rich environments.                                      ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **2. Conciseness:**                                                          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The core tenets of the model (the two axes) are presented ‚îÇ\n",
            "‚îÇ  relatively concisely. The 2x2 matrix visualization is a good way to summari ‚îÇ\n",
            "‚îÇ ze the model's core components.                                              ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** The overall description is quite lengthy. The sections o ‚îÇ\n",
            "‚îÇ n model components and relationships, while informative, could be more strea ‚îÇ\n",
            "‚îÇ mlined.  The model could benefit from a more succinct definition of each axi ‚îÇ\n",
            "‚îÇ s and its endpoints. The mapping of dimensions and codes is helpful but coul ‚îÇ\n",
            "‚îÇ d be integrated more seamlessly into the main text. The model could be more  ‚îÇ\n",
            "‚îÇ concise by focusing on the unique contributions of ACISO and reducing the di ‚îÇ\n",
            "‚îÇ scussion of established theories.                                            ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **3. Clarity:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The model is generally well-written and uses clear langua ‚îÇ\n",
            "‚îÇ ge. The definitions of the axes and their endpoints are relatively easy to u ‚îÇ\n",
            "‚îÇ nderstand. The use of examples helps to illustrate the concepts.             ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** Some of the terminology could be further refined. For ex ‚îÇ\n",
            "‚îÇ ample, \"Deep Integration\" could be misinterpreted as inherently positive, ev ‚îÇ\n",
            "‚îÇ en though the model acknowledges its potential downsides.  The distinction b ‚îÇ\n",
            "‚îÇ etween \"Peripheral Integration\" and \"Deep Integration\" could be made more co ‚îÇ\n",
            "‚îÇ ncrete with specific examples related to the provided codes. The mapping of  ‚îÇ\n",
            "‚îÇ codes to the model could be more explicit in its justification. Why is \"Stra ‚îÇ\n",
            "‚îÇ tegic Concealment of AI Application\" mapped to low scholarly ownership? The  ‚îÇ\n",
            "‚îÇ reasoning should be clearly stated.                                          ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **4. Theoretical Insight:**                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ *   **Strengths:** The model provides a valuable framework for understanding ‚îÇ\n",
            "‚îÇ  the complex interplay between students, AI, and learning. It offers a nuanc ‚îÇ\n",
            "‚îÇ ed perspective on the potential benefits and risks of AI in education. The h ‚îÇ\n",
            "‚îÇ ypotheses are well-formulated and testable. The implications for educators a ‚îÇ\n",
            "‚îÇ nd policymakers are practical and relevant.                                  ‚îÇ\n",
            "‚îÇ *   **Weaknesses:** The model could benefit from a stronger connection to ex ‚îÇ\n",
            "‚îÇ isting theories of learning and motivation. While it mentions TAM, CLT, SDT, ‚îÇ\n",
            "‚îÇ  and Activity Theory, it doesn't fully integrate these theories into the cor ‚îÇ\n",
            "‚îÇ e framework. For example, how does scholarly ownership relate to self-effica ‚îÇ\n",
            "‚îÇ cy or intrinsic motivation? How does adaptive integration affect cognitive l ‚îÇ\n",
            "‚îÇ oad and learning outcomes? The model could also benefit from a more in-depth ‚îÇ\n",
            "‚îÇ  discussion of the ethical implications of AI use in education.              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **Suggested Improvements:**                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 1.  **Sharpen the Novelty:**                                                 ‚îÇ\n",
            "‚îÇ     *   Explicitly state what makes ACISO different from existing models of  ‚îÇ\n",
            "‚îÇ student agency, self-regulation, and technology integration.                 ‚îÇ\n",
            "‚îÇ     *   Provide empirical evidence (even hypothetical) to support the claim  ‚îÇ\n",
            "‚îÇ that *adaptive* integration is more effective than simply *more* or *less* i ‚îÇ\n",
            "‚îÇ ntegration.                                                                  ‚îÇ\n",
            "‚îÇ     *   Elaborate on the unique ethical considerations that arise from the u ‚îÇ\n",
            "‚îÇ se of generative AI in education and how scholarly ownership addresses these ‚îÇ\n",
            "‚îÇ  concerns.                                                                   ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 2.  **Increase Conciseness:**                                                ‚îÇ\n",
            "‚îÇ     *   Streamline the descriptions of the model components and relationship ‚îÇ\n",
            "‚îÇ s. Focus on the key elements and avoid unnecessary detail.                   ‚îÇ\n",
            "‚îÇ     *   Consider using a visual diagram to illustrate the relationships betw ‚îÇ\n",
            "‚îÇ een the different components of the model.                                   ‚îÇ\n",
            "‚îÇ     *   Condense the mapping of dimensions and codes into a more concise tab ‚îÇ\n",
            "‚îÇ le or integrate it more seamlessly into the main text.                       ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 3.  **Enhance Clarity:**                                                     ‚îÇ\n",
            "‚îÇ     *   Refine the terminology to avoid ambiguity. Consider alternative term ‚îÇ\n",
            "‚îÇ s for \"Deep Integration\" that better reflect its potential downsides.        ‚îÇ\n",
            "‚îÇ     *   Provide more concrete examples of each axis and its endpoints, using ‚îÇ\n",
            "‚îÇ  the provided codes as illustrations.                                        ‚îÇ\n",
            "‚îÇ     *   Clearly justify the mapping of codes to the model. Explain the reaso ‚îÇ\n",
            "‚îÇ ning behind each mapping and address any potential ambiguities.              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 4.  **Deepen Theoretical Insight:**                                          ‚îÇ\n",
            "‚îÇ     *   More fully integrate existing theories of learning and motivation in ‚îÇ\n",
            "‚îÇ to the core framework. Explain how scholarly ownership relates to self-effic ‚îÇ\n",
            "‚îÇ acy, intrinsic motivation, and other relevant constructs.                    ‚îÇ\n",
            "‚îÇ     *   Discuss the ethical implications of AI use in education in more deta ‚îÇ\n",
            "‚îÇ il. Consider issues such as bias, fairness, and privacy.                     ‚îÇ\n",
            "‚îÇ     *   Explore the potential for the model to be applied in different educa ‚îÇ\n",
            "‚îÇ tional contexts and with different types of AI tools.                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ 5.  **Strengthen the Empirical Grounding:**                                  ‚îÇ\n",
            "‚îÇ     *   While the hypotheses are well-formulated, provide more specific exam ‚îÇ\n",
            "‚îÇ ples of how they could be tested empirically.                                ‚îÇ\n",
            "‚îÇ     *   Discuss the limitations of the model in more detail and suggest dire ‚îÇ\n",
            "‚îÇ ctions for future research.                                                  ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ **In summary:**                                                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ The ACISO model is a promising framework for understanding student engagemen ‚îÇ\n",
            "‚îÇ t with generative AI. Its emphasis on adaptive cognitive integration and sch ‚îÇ\n",
            "‚îÇ olarly ownership is a valuable contribution to the field. By addressing the  ‚îÇ\n",
            "‚îÇ weaknesses outlined above and implementing the suggested improvements, the m ‚îÇ\n",
            "‚îÇ odel can be further refined and strengthened. The model has the potential to ‚îÇ\n",
            "‚îÇ  be a valuable tool for educators and policymakers seeking to harness the po ‚îÇ\n",
            "‚îÇ tential of AI while mitigating its risks.                                    ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "‚è∏  It√©rations termin√©es. ENTR√âE pour diagramme...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "                          G√âN√âRATION DIAGRAMME MERMAID                          \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour diagramme...\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üîß SYSTEM PROMPT UTILIS√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ System Message                                                               ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Create Mermaid flowchart showing relationships.                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Syntax:                                                                      ‚îÇ\n",
            "‚îÇ graph TD                                                                     ‚îÇ\n",
            "‚îÇ     A[Dimension] -->|relationship| B[Dimension]                              ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Return ONLY valid Mermaid code.                                              ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üí¨ USER PROMPT ENVOY√â\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ User Prompt                                                                  ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Dimensions:                                                                  ‚îÇ\n",
            "‚îÇ [\"AI Impact on Pedagogy\", \"AI Limitations and Challenges\", \"AI as Productivi ‚îÇ\n",
            "‚îÇ ty Tool\", \"Strategic AI Implementation\", \"User Engagement with AI\", \"Content ‚îÇ\n",
            "‚îÇ  Adaptation with AI\"]                                                        ‚îÇ\n",
            "‚îÇ                                                                              ‚îÇ\n",
            "‚îÇ Relationships:                                                               ‚îÇ\n",
            "‚îÇ Artificial intelligence reshaping educational paradigms ‚Üî Perceived Constrai ‚îÇ\n",
            "‚îÇ nts and Limitations of Artificial Intelligence: While AI is recognized as a  ‚îÇ\n",
            "‚îÇ potentially useful tool for tasks like grammar correction, some individuals  ‚îÇ\n",
            "‚îÇ are discouraged from using it due to perceptions of its limited utility or p ‚îÇ\n",
            "‚îÇ otential for generating inaccurate responses.                                ‚îÇ\n",
            "‚îÇ AI-Augmented Learning Material Development and Enhancement ‚Üî AI-Generated Co ‚îÇ\n",
            "‚îÇ ntent Adaptation and Appropriation: Based on the provided passages, AI is us ‚îÇ\n",
            "‚îÇ ed to generate summaries and plans from existing material, which are then ad ‚îÇ\n",
            "‚îÇ apted and used by st...                                                      ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "üîÑ Envoi √† l'API... ‚úì\n",
            "\n",
            "================================================================================\n",
            "                              üìä DIAGRAMME MERMAID                               \n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ Mermaid Code                                                                 ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ graph TD                                                                     ‚îÇ\n",
            "‚îÇ     A[\"AI Impact on Pedagogy\"] -->|Artificial intelligence reshaping educati ‚îÇ\n",
            "‚îÇ onal paradigms ‚Üî Perceived Constraints and Limitations of Artificial Intelli ‚îÇ\n",
            "‚îÇ gence| B[\"AI Limitations and Challenges\"]                                    ‚îÇ\n",
            "‚îÇ     C[\"AI as Productivity Tool\"] -->|AI-Augmented Learning Material Developm ‚îÇ\n",
            "‚îÇ ent and Enhancement ‚Üî AI-Generated Content Adaptation and Appropriation| D[\" ‚îÇ\n",
            "‚îÇ Content Adaptation with AI\"]                                                 ‚îÇ\n",
            "‚îÇ     E[\"Strategic AI Implementation\"] -->|AI Integration in Higher Education  ‚îÇ\n",
            "‚îÇ Trajectories ‚Üî Strategic AI Deployment Aligned with Stakes| F[\"Strategic AI  ‚îÇ\n",
            "‚îÇ Implementation\"]                                                             ‚îÇ\n",
            "‚îÇ     C[\"AI as Productivity Tool\"] -->|AI as a Productivity and Efficiency Enh ‚îÇ\n",
            "‚îÇ ancer ‚Üî AI as a Procrastination and Blockage Mitigation Tool| G[\"AI as Produ ‚îÇ\n",
            "‚îÇ ctivity Tool\"]                                                               ‚îÇ\n",
            "‚îÇ     H[\"User Engagement with AI\"] -->|Recursive Engagement with Artificial In ‚îÇ\n",
            "‚îÇ telligence Systems ‚Üî Instrumental and Detached AI Adoption| H[\"User Engageme ‚îÇ\n",
            "‚îÇ nt with AI\"]                                                                 ‚îÇ\n",
            "‚îÇ     I[\"AI Response Validation and Verification Processes\"] -->|AI Response V ‚îÇ\n",
            "‚îÇ alidation and Verification Processes ‚Üî AI-Generated Content Adaptation and A ‚îÇ\n",
            "‚îÇ ppropriation| D[\"Content Adaptation with AI\"]                                ‚îÇ\n",
            "‚îÇ     A[\"AI Impact on Pedagogy\"] -->|Artificial intelligence reshaping educati ‚îÇ\n",
            "‚îÇ onal paradigms ‚Üî AI-Augmented Learning Material Development and Enhancement| ‚îÇ\n",
            "‚îÇ  C[\"AI as Productivity Tool\"]                                                ‚îÇ\n",
            "‚îÇ     C[\"AI as Productivity Tool\"] -->|AI as a Productivity and Efficiency Enh ‚îÇ\n",
            "‚îÇ ancer ‚Üî Strategic AI Deployment Aligned with Stakes| F[\"Strategic AI Impleme ‚îÇ\n",
            "‚îÇ ntation\"]                                                                    ‚îÇ\n",
            "‚îÇ     H[\"User Engagement with AI\"] -->|Recursive Engagement with Artificial In ‚îÇ\n",
            "‚îÇ telligence Systems ‚Üî AI-Generated Content Adaptation and Appropriation| D[\"C ‚îÇ\n",
            "‚îÇ ontent Adaptation with AI\"]                                                  ‚îÇ\n",
            "‚îÇ     E[\"Strategic AI Implementation\"] -->|AI Integration in Higher Education  ‚îÇ\n",
            "‚îÇ Trajectories ‚Üî Perceived Constraints and Limitations of Artificial Intellige ‚îÇ\n",
            "‚îÇ nce| B[\"AI Limitations and Challenges\"]                                      ‚îÇ\n",
            "‚îÇ     G[\"AI as Productivity Tool\"] -->|AI as a Procrastination and Blockage Mi ‚îÇ\n",
            "‚îÇ tigation Tool ‚Üî Strategic Concealment of AI Application| F[\"Strategic AI Imp ‚îÇ\n",
            "‚îÇ lementation\"]                                                                ‚îÇ\n",
            "‚îÇ     C[\"AI as Productivity Tool\"] -->|AI-Augmented Learning Material Developm ‚îÇ\n",
            "‚îÇ ent and Enhancement ‚Üî AI Response Validation and Verification Processes| I[\" ‚îÇ\n",
            "‚îÇ AI Response Validation and Verification Processes\"]                          ‚îÇ\n",
            "‚îÇ     A[\"AI Impact on Pedagogy\"] -->|Artificial intelligence reshaping educati ‚îÇ\n",
            "‚îÇ onal paradigms ‚Üî Recursive Engagement with Artificial Intelligence Systems|  ‚îÇ\n",
            "‚îÇ H[\"User Engagement with AI\"]                                                 ‚îÇ\n",
            "‚îÇ     E[\"Strategic AI Implementation\"] -->|AI Integration in Higher Education  ‚îÇ\n",
            "‚îÇ Trajectories ‚Üî AI as a Productivity and Efficiency Enhancer| C[\"AI as Produc ‚îÇ\n",
            "‚îÇ tivity Tool\"]                                                                ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n",
            "================================================================================\n",
            "                             üíæ EXPORT DES R√âSULTATS                             \n",
            "================================================================================\n",
            "\n",
            "‚è∏  ENTR√âE pour g√©n√©rer fichiers...\n",
            "\n",
            "‚úì Excel: ACADEMIAOS_IMPROVED_RESULTS.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_08a57a3b-e09d-4883-8a49-4e239b87265e\", \"ACADEMIAOS_IMPROVED_RESULTS.xlsx\", 23842)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Evidence: EVIDENCE_CHUNKS_TUPLES.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f75692f-0953-48bd-8aed-3cdc7e4e5826\", \"EVIDENCE_CHUNKS_TUPLES.txt\", 625911)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Mod√®le 1: MODELE_ITERATION_1.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3df9e151-6cfe-449b-bd2d-5cf4cfb9b23c\", \"MODELE_ITERATION_1.txt\", 14615)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Mod√®le 2: MODELE_ITERATION_2.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_04514d28-4bd5-4e8a-98ef-c1056bbc8c3c\", \"MODELE_ITERATION_2.txt\", 18494)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Diagramme: DIAGRAM_MERMAID.mmd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_edda8295-a17c-413a-bdc1-786ee598878e\", \"DIAGRAM_MERMAID.mmd\", 2543)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Statistiques: STATISTIQUES_ANALYSIS.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_91ebaf21-32eb-436c-98bd-debe6261508c\", \"STATISTIQUES_ANALYSIS.txt\", 1106)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Cache embeddings disponible\n",
            "   T√©l√©charger cache embeddings pour r√©utilisation? (o/N): \n",
            "\n",
            "================================================================================\n",
            "                                ‚úÖ EXPORT TERMIN√â                                \n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "                               üéâ ANALYSE TERMIN√âE                               \n",
            "================================================================================\n",
            "\n",
            "Tous les fichiers ont √©t√© g√©n√©r√©s.\n",
            "\n",
            "Fichiers export√©s:\n",
            "  ‚Ä¢ ACADEMIAOS_IMPROVED_RESULTS.xlsx\n",
            "  ‚Ä¢ EVIDENCE_CHUNKS_TUPLES.txt\n",
            "  ‚Ä¢ MODELE_ITERATION_1.txt\n",
            "  ‚Ä¢ MODELE_ITERATION_2.txt\n",
            "  ‚Ä¢ DIAGRAM_MERMAID.mmd\n",
            "  ‚Ä¢ STATISTIQUES_ANALYSIS.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FN9qKhX7WFWi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}